{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_Bootcamp ML Modellwahl Train Test Optimize ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuronohana/my_datascience/blob/master/6_DS_Bootcamp_ML_Modell_Train_Test_Optimize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyxBmxgRxnMS",
        "colab_type": "text"
      },
      "source": [
        "# DS Bootcamp Teil 4 - Machine Learning - Modell Training, Testing & Optimierung #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzg8_V-3-pOb",
        "colab_type": "text"
      },
      "source": [
        "## DS Bootcamp Verzeichnis ##\n",
        "\n",
        "[**Teil 1 - Data Science - Prozesse & Grundlagen**](https://github.com/sakuronohana/my_datascience/blob/master/1_DS_Bootcamp_Prozesse_%26_Grundlagen.ipynb)\n",
        "\n",
        "[**Teil 1a - Data Science - Python Basic & Advanced**](https://github.com/sakuronohana/my_datascience/blob/master/2_DS_Bootcamp_Python_Basic_%26_Advanced.ipynb)\n",
        "\n",
        "[**Teil 1b - Data Science - R Basic & Advanced**](https://github.com/sakuronohana/my_datascience/blob/master/3_DS_Bootcamp_R_Basic_%26_Advanced.ipynb)\n",
        "\n",
        "[**Teil 2 - Data Science - ML - Datenbeschaffung & Datenaufbereitung**](https://github.com/sakuronohana/my_datascience/blob/master/4_DS_Bootcamp_ML_Datenbeschaffung_Datenaufbereitung.ipynb)\n",
        "\n",
        "[**Teil 3 - Data Science - ML - Modellwahl**](https://github.com/sakuronohana/my_datascience/blob/master/5_DS_Bootcamp_ML_Modellwahl.ipynb)\n",
        "\n",
        "[**Teil 4 - Data Science - ML - Modell Training, Testing & Optimierung**](https://github.com/sakuronohana/my_datascience/blob/master/6_DS_Bootcamp_ML_Modell_Train_Test_Optimize.ipynb)\n",
        "\n",
        "[**Teil 5 - Data Science - ML - Modell Produktivsetzung, Überwachung & Pflege**](https://github.com/sakuronohana/my_datascience/blob/master/7_DS_Bootcamp_ML_Modell_Deploy_Monitor_Maintain.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELtCrIcWJ7DP",
        "colab_type": "text"
      },
      "source": [
        "##Modelltraining (Train Model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCdQlsIV9kHn",
        "colab_type": "text"
      },
      "source": [
        "### Qualitätsmasse eines ML-Modells\n",
        "\n",
        "Idealerweise stellen wir bereits während des Trainings eines Modells sicher, dass wir beim Testing keine bösen Überraschungen erleben. Hierfür stehen uns die folgenden verschiedenen Methoden und Techniken zur Verfügung. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLRRtH_Y_Y3O",
        "colab_type": "text"
      },
      "source": [
        "####Kreuzvalidierung (Cross-Validation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_97ZE6hWFN3",
        "colab_type": "text"
      },
      "source": [
        "####Konfusionsmatrix (Confusion matrix)\n",
        "Eine gute Möglichkeit zur Auswertung der Performance eines Klassifikators bietet die Konfusionsmatrix. Mittels der Matrix lässt sich die Zuverlässigkeit der Vorhersage (Prediction) eines Klassifikationsmodells feststellen. Die Konfusionsmatrix wird wie folgt dargestellt:\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/712/1*Z54JgbS4DUwWSknhDCvNTQ.png\" width=400/>\n",
        "\n",
        "Quelle: Towards Data Science (Autor: [Sarang Narkhede](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62))\n",
        "\n",
        "Die Performace wird mittels den folgenden vier Werten gemacht:\n",
        "\n",
        "* **True Positive** (TP) - richtig Vorhersage. Beispiel: Anzahl Patienten bei welchen **korrekterweise** Krebs diagnostiziert wurde. \n",
        "* **True Negative** (TN) - richtig Vorhersage. Beispiel: Anzahl Patienten bei welchen **korrekterweise** kein Krebs diagnostiziert wurde. \n",
        "* **False Positive** (FP) - falsche Vorhersage. Beispiel: Anzahl Patienten bei welchen **fälschlicherweise** Krebs diagnostiziert wurde. \n",
        "* **False Negative** (FN) - falsche Vorhersage. Beispiel: Anzahl Patienten bei welchen **fälschlicherweise** kein Krebs diagnostiziert wurde. \n",
        "\n",
        "Nachfolgend eine bildliche Darstellung:\n",
        "<img src=\"https://miro.medium.com/max/924/1*7EYylA6XlXSGBCF77j_rOA.png\" width=400/>\n",
        "\n",
        "Quelle: Towards Data Science (Autor: [Sarang Narkhede](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq195ln1kWlg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "d77fbefa-fa53-443b-c123-dd888bb331e1"
      },
      "source": [
        "# Nachfolgend importieren wir den MNIST Datensatz.\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(X_train, y_train),(X_test,y_test) = mnist.load_data()\n",
        "X_train, X_test = x_train / 255.0, x_train / 255.0\n",
        "\n",
        "print (X_train.shape, X_train.ndim)\n",
        "\n",
        "# Wir werden uns nun davon überzeugen, dass es sich um den MNIST Datensatz handelt.\n",
        "one_digit = X_train[36000]\n",
        "one_digit_image = one_digit.reshape(28,28)\n",
        "\n",
        "\n",
        "plt.imshow(one_digit, cmap = plt.cm.binary, interpolation=\"nearest\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print ('Der Datenpunkt 36000 hat das Label', y_train[36000])\n",
        "\n",
        "# Wir wollen in diesem Beispiel den Klassifikator nur auf die Zahl 9 fokusieren\n",
        "y_train_9 = (y_train == 9) # Nur korrekt bei allen Zahlen mit 9\n",
        "y_test_9 = (y_test == 9)\n",
        "\n",
        "# Nun trainieren wird einen Klassifier\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "sgd_clf.fit(X_train, y_train_9)\n",
        "\n",
        "#sgd_clf.predict([one_digit])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Der Datenpunkt 36000 hat das Label 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-a0a21327951e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Nun trainieren wird einen Klassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0msgd_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0msgd_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#sgd_clf.predict([one_digit])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    711\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         X, y = check_X_y(X, y, 'csr', dtype=np.float64, order=\"C\",\n\u001b[0;32m--> 529\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m# labels can be encoded as float, int, or string literals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 539\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX2C72wS8pQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nachfolgend importieren wir den MNIST Datensatz.\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "mnist = tf.keras.datasets.mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTeWxo86J-Di",
        "colab_type": "text"
      },
      "source": [
        "##Modelltesting (Test Model)##\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxxlwT_XKEKZ",
        "colab_type": "text"
      },
      "source": [
        "##Modelloptimierung (Tune Model)##\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhDGAgE9KIYJ",
        "colab_type": "text"
      },
      "source": [
        "##Modellproduktivsetzung (Prediction)##"
      ]
    }
  ]
}