{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS-Glossar.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuronohana/my_datascience/blob/master/DS_Glossar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "L8UD6-z7J8Y9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6jUrFBzk0JBn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#A#"
      ]
    },
    {
      "metadata": {
        "id": "rd8A7QCaNyh3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#B#"
      ]
    },
    {
      "metadata": {
        "id": "ow8qEoeN0KuZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "test"
      ]
    },
    {
      "metadata": {
        "id": "M36HCk7EnuKC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Batch##\n",
        "It is not possible ot pass the entire dataset (Epoch) into the neural net at once. So, you divide dataset into Number of Batches or sets or parts."
      ]
    },
    {
      "metadata": {
        "id": "OwxlgK6Aova-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Batch Size##\n",
        "A batch size representing a total number of training examples in a single batch (see Batch)"
      ]
    },
    {
      "metadata": {
        "id": "q_zL8aN0N2Ug",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Bias##\n",
        "The bias sometimes also called y-intercept, is a value which defines the threshold withhin a neuron. It belongs to the so called transfer function which sums all inputs (x) and weights for a neuron and finally adds the bias.\n",
        "\n",
        "$ f(x)  = (x_i * w_i) + b$\n"
      ]
    },
    {
      "metadata": {
        "id": "isb2boDgMbq_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#C#"
      ]
    },
    {
      "metadata": {
        "id": "8mgCKxaTMgVb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Cost function## \n",
        "Also called **Loss function**\n",
        "Is an algorithm which lets us find weights and biases so that the output from the network approximates y(x) for all training inputs x. To quantify how well we're achieving this goal we define a cost function. We need a function that will minimize the parameters over our dataset. One common function that is often used is **mean squared error** (MSE), which measure the difference between the estimator (the dataset) and the estimated value (the prediction)\n",
        "\n",
        "MSE Notation:\n",
        "\n",
        "$MSE = \\frac{1}{n} \\displaystyle\\sum_{i=1}^{n} (x_i - \\hat{x}_i)^2$\n"
      ]
    },
    {
      "metadata": {
        "id": "y8them1n0Mev",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#D#"
      ]
    },
    {
      "metadata": {
        "id": "lnv14Q1h7omR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Distributed Training##\n",
        "\n",
        "Due to performance issues on a single machine, the training of a neural network model can take hours until days depending on the size of the epoch (trainig data). An option to speed up the training is the use of GPU/TBU but if this is still not fast enough there is another way called Distributed Training. With this technic you will be able to use one machine with multiple devices (GPU/TBU) or multiple machines with multiple devices.\n",
        "The most commen used DT architecture is called **Data parallelism** \n",
        "\n",
        "\n",
        "\n",
        "For more Details watch Google Video [Distributed TensorFlow training ](https://www.youtube.com/watch?v=bRMGoPqsn20)\n"
      ]
    },
    {
      "metadata": {
        "id": "nTbdR3OrcNUw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#E#"
      ]
    },
    {
      "metadata": {
        "id": "yJi62gKrcT-D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Epoch##\n",
        "The term epoch describes one complete presentation of the data set. A large dataset has to be split in several small batches.\n",
        "\n",
        "As the number of epochs increases, more number of times the weight are changed in the neural network and the curve goes from underfitting to optimal to overfitting curve.\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*i_lp_hUFyUD_Sq4pLer28g.png)"
      ]
    },
    {
      "metadata": {
        "id": "WIQxA74d0PeE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#F#"
      ]
    },
    {
      "metadata": {
        "id": "XNdGa53OKFnL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#G#"
      ]
    },
    {
      "metadata": {
        "id": "bS5bQMbQKihe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Gradient Desent##\n",
        "It is an iterative optimization algorithm used in machine learning to find the best results.\n",
        "Gradient means the rate of inclination or declination of a slope. Descent means the instance of descending.\n",
        "\n",
        "The algorithm is iterative means that we need to get the results multiple times to get the most optimal result. The iterative quality of the gradient descent helps a under-fitted graph to make the graph fit optimally to the data.\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*pwPIG-GWHyaPVMVGG5OhAQ.gif)\n"
      ]
    },
    {
      "metadata": {
        "id": "pSDvgT_h0ShH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#H#"
      ]
    },
    {
      "metadata": {
        "id": "jOHpGpzjqAvF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#I#"
      ]
    },
    {
      "metadata": {
        "id": "NomuayfdqEv7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Iterations##\n",
        "Iterations is the number of batches (see Batch) needed to complete one epoch (see Epoch). The number of batches is equal to number of iterations for one epoch.\n",
        "\n",
        "Letâ€™s say we have 2000 training examples that we are going to use . We can divide the dataset of **2000** examples into **batches of 500** then it will take **4 iterations** to complete **1 epoch.**"
      ]
    },
    {
      "metadata": {
        "id": "MQhyFtdl0Ybh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#K#"
      ]
    },
    {
      "metadata": {
        "id": "fWwywo3o0Vly",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "a7VzzwGmLod2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#L#"
      ]
    },
    {
      "metadata": {
        "id": "-OcPnjFkL1Qb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Learning rate##\n",
        "The Gradient descent has a parameter called learning rate. As you can see below (left), initially the steps are bigger that means the learning rate is higher and as the point goes down the learning rate becomes more smaller by the shorter size of steps.\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*pwPIG-GWHyaPVMVGG5OhAQ.gif)"
      ]
    },
    {
      "metadata": {
        "id": "iH0Q8boA0fRv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#M#"
      ]
    },
    {
      "metadata": {
        "id": "IxvNShVk0imx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#N#"
      ]
    },
    {
      "metadata": {
        "id": "H-I4zcQ50ntv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#O#"
      ]
    },
    {
      "metadata": {
        "id": "U1y_nrB10rnQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Overfitting##\n",
        "\n",
        "Overfitting is a term which is used, wenn a model is good in classifiying or predicting on a Dataset which was used for Training but not on a Dataset which it was not trained on.\n",
        "This is a common problem and comes mostly from a lack of sufficient and differsed datas. Means the more and differsed data you have the more the model fits. For example wen your datasets contains jus images of big dogs of less then 3 kinds, the model will not be able to recognize a smaller dog.\n",
        "\n",
        "Another way to prevent overfitting is to augmenting datas means to flip, rotate, zoom etc. images."
      ]
    },
    {
      "metadata": {
        "id": "CIqC-g9urLKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#P#"
      ]
    },
    {
      "metadata": {
        "id": "aQwn2QT1rPhy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Perceptrons##\n",
        "Is a type of artificial neuron. Perceptrons were developed in the 1950s and 1960s by the scientist Frank Rosenblatt, inspired by earlier work by Warren McCulloch and Walter Pitts. \n",
        "\n",
        "![alt text](http://neuralnetworksanddeeplearning.com/images/tikz0.png)\n",
        "\n",
        "The formula of the perceptrons is like this:\n",
        "\n",
        "$output =\n",
        "  \\begin{cases}\n",
        "   0       & \\quad \\text{if } w * x + b \\leq{ 0}\\\\\n",
        "   1  & \\quad \\text{if } w * x + b \\text{ < 0}\n",
        "  \\end{cases}$\n",
        "  \n",
        "As the perceptrons implements a NAND gate the output can be 0 or 1. Small changes to the weight to adjust the output have a big impact to the whole neural network.\n",
        "\n",
        "Because of that fact, Today, it's more common to use other models of artificial neurons like sigmoid, ReLU, TanH, etc."
      ]
    },
    {
      "metadata": {
        "id": "bCJll2MnnJiF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#S#"
      ]
    },
    {
      "metadata": {
        "id": "zNd7fxacnPM6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Sigmoid neurons##\n",
        "The sigmoid neuron ist a perceptron using sigmoid as a activation function. In contrast to the simple NAND Gate used in the original perceptron this function, like a lot other similar functions, can pick a value between 0 and 1 (i.e. 0.666 etc) and make it possible to apply smaller changes to the Network.\n",
        "\n",
        "Sigmoid Notation:\n",
        "\n",
        "$f(x) = \\frac{1}{1 + exp- ^x}$\n",
        "\n",
        "Note: x is the $\\sum$ of $w_i \\cdot x_i + b$ means all weights (w) and inputs (x) of a neuron added with the bias (b)."
      ]
    },
    {
      "metadata": {
        "id": "tU1Xde40ZMSf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#W#"
      ]
    },
    {
      "metadata": {
        "id": "I8FpYYHBZRi-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Weights##\n",
        "Weights are values expressing the importance of the respective inputs to the output for a neuron. Together with the input value (x) and the bias (see Bias) it belogs to the transfer function of a neuron.  "
      ]
    }
  ]
}