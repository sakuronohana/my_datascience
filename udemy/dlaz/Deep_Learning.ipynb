{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuronohana/my_datascience/blob/master/udemy/dlaz/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyxBmxgRxnMS"
      },
      "source": [
        "# Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OMRqL-5eaqu"
      },
      "source": [
        "## Was ist Deep Learning?\n",
        "\n",
        "Deep Learning ist ein Teilgebiet des Machine Learning und unterscheidet sich vom „klassischen“ maschinellen Lernen, indem es Maschinen in die Lage versetzt, über die verfügbaren Daten hinaus zu lernen. Das beinhaltet die Fähigkeit, Informationen zu analysieren und zu bewerten, um logische Schlüsse zu ziehen, Lösungswege auszuwählen und aus Fehlern zu lernen. Je mehr Daten eine Maschine also empfängt, desto grösser ist ihre Lernfähigkeit und desto \"intelligenter\" kann sie werden. Obwohl es die künstlichen neuronalen Netze, die die Grundlage dieser Technologien bilden, bereits seit den 1950er Jahren gibt, haben erst die bahnbrechenden Entwicklungen des letzten Jahrzehnts die Lernkurve stark verbessert. Die am meisten verbreiteten modernen Applikationen sind Stimm- und Bilderkennung. Das Niveau der Datenanalyse ermöglicht jedoch viele vorausschauende Applikationen, wie enorme Verbesserungen in der vorausschauenden Wartung, sicherere autonome Fahrzeuge, die Vorhersage von Krankheiten oder Rückfällen. Künstliche neuronale Netzwerke können sowohl für Klassifikation (Binary/Mulit-Class) wie auch Regression verwendet werden. \n",
        "\n",
        "Einer der Pioniere in diesem Gebiet ist [Geoffrey Hinton](https://de.wikipedia.org/wiki/Geoffrey_Hinton). Hinton ist ein britischer Informatiker und Kognitionspsychologe der als Professor an der Universität Toronto und bei Google arbeitet. Er hat massgeblich den Begriff Deep Learning kreiert.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzVwJdUyh8zn"
      },
      "source": [
        "## Was sind Künstlich Neuronale Netzwerke (KNN)?\n",
        "\n",
        "Ein künstliches neuronales Netzwerk (KNN), im englischen Artificial neural networks (ANN) genannt,  ist einen Art Abbildung des menschlichen neuronalen Netzwerks. Diese Netzwerk besteht aus vernetzten Neuronen. In einem KNN ist ein Neuron nichts anderes als eine Element welche eine Nummer zwischen 0 - 1, speichert. In einem KNN gibt es drei Arten von Neuronen - Input Neuron, Hidden Neuron und Output Neuron.\n",
        "\n",
        "Beispiel ein Bild mit einer handschriftlichen Zahl 9 besteht aus 28 x 28 Pixel was somit 784 Neuronen darstellt. Jeder dieser Neuronen enthält einen Graustufenwert von 0.01 (Schwarz) zu 1.00 (Weiss). Diese Werte werden „Activation“ genannt. Dies 784 Neuronen stellen die erste Schicht unsere Netzwerks dar. Die letze Schicht wird nur noch aus 10 Neuronen welche die Nummern 0 - 9 darstellen. Die Schichten dazwischen werden „Hidden Layers“ genannt. Sämtliche Neuronen in den verschiedenen Layers sind miteinander verbunden. Die Verbindungen zwischen den Neuronen haben eigene Gewichtungen. Diese Gewichtung wird mit dem Input-Wert multipliziert. Hat also beispielsweise ein Input-Neuron einen Wert von 0,7 und die Gewichtung der Verbindung einen Wert von 2 werden diese zwei Werte multipliziert und ergeben einen Wert von 1.4, welcher an das nächste Neuron weitergegeben werden. Würden wir aber nun immer so rechnen, würde das Resultat immer durch null gehen. Damit wir das verhindern können benutzen wir den Bias. Der Bias ist nichts anderes als der y-Intercept in der linearen Algebra mit dem Unterschied, dass er nur 1 sein kann. Nehmen wir nun also den Bias noch dazu dann bekommen wir folgenden Formel f(x) = mx + b.\n",
        "\n",
        "In einem künstlich neuronalen Netzwerk bestimmen die Aktivitäten in einem Layer die Aktivitäten im nächsten Layer. Die grosse Frage ist dabei WIE Aktivitäten in einem Layer die des nächsten beeinflusst. Grundsätzlich funktioniert es in der gleichen Art wie das biologische Vorbild. Feuert ein Neuron beeinflusst es ein anderes Neuron.\n",
        "\n",
        "Hier eine Abbildung eines typischen KNN:\n",
        "\n",
        "<img src='https://www.researchgate.net/publication/329216193/figure/fig3/AS:697582816870406@1543328112943/Architecture-of-multilayer-artificial-neural-network-with-error-backpropagation.png' width=450>\n",
        "\n",
        "Quelle: [ResearchGate](https://www.researchgate.net/publication/329216193_Predicting_Roof_Pressures_on_a_Low-Rise_Structure_From_Freestream_Turbulence_Using_Artificial_Neural_Networks)\n",
        "\n",
        "\n",
        "Hier noch eine sehr empfehlenswerte Lektüre von Superdatascience.com \n",
        "\n",
        "[The Ultimate Guide to Artificial Neural Networks (ANN)](https://www.superdatascience.com/blogs/the-ultimate-guide-to-artificial-neural-networks-ann)\n",
        "oder [Deep Learning A-Z](https://www.superdatascience.com/pages/deep-learning)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLA0iCN7kHVC"
      },
      "source": [
        "### Anatomie eines KNN\n",
        "\n",
        "Nachfolgenden werden wir die verschiedenen Bestandteile (inkl. Math) eines KNN erläutern"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9C6y4I-skn8"
      },
      "source": [
        "#### Künstliches Neuron (Unit)\n",
        "\n",
        "Ein künstliche Neuron stellt ein vereinfachtes Modell eines biologischen Neurons dar.  Ein künstliches Neuron wird auch oft McCulloch-Pittsburgh-Zelle genannt. \n",
        "Bei der Definition des künstlichen Neurons wurden die wesentlichen Eigenschaften eines biologischen Neurons erhalten:\n",
        "\n",
        "Synapsen der Nervenzellen = Addition gewichteter EIngaben\n",
        "Aktivierung Zellkerns = Aktivierungsfunktion mit Schwellwerten\n",
        "\n",
        "Ein künstliches Neuron (j) wird durch folgende Bestandteile beschrieben:\n",
        "\n",
        "1. Wichtung (wij - Die Gewichtung den Einfluss der die Eingabe des Neurons in die Berechnung der Aktivierung einnimmt. D.h. Je höher die Gewichtung desto erregender (exzitatorisch) ist der Input. Je geringer desto hemmender (inhibitorisch) ist die Verbindung zwischen zwei Knoten (0 = nicht existent). \n",
        "2. Übertragungsfunktion - Diese Funktion (∑) berechnet anhand der Wichtung der Eingabe die Netzeingabe des Neurons. Meist ist es die Summe der Eingaben.  Es wird \n",
        "3. Aktivierungsfunktion (ρ) - Diese Funktion bestimmt die Ausgabe des Neurons. Sie wird durch die Netzeingabe und den Schwellwert beeinflusst. -> Siehe Activation Functions\n",
        "4. Schwellwert (θj) - Das Addieren eines Schwellwerts zur Netzeingabe verschiebt die gewichtete Eingabe.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oZb3hJ4YOIv"
      },
      "source": [
        "#### Perzeptron\n",
        "\n",
        "Ausgehen von dieser Idee hat Frank Rosenblatt 1957 das Perzepton entwickelt. Dieses Perzeptron stellt das einfachste KNN dar, da es aus einer Eingabeschicht (Input) und einer Ausgabeschicht (Output) besteht:\n",
        "\n",
        "<img src='https://images.deepai.org/glossary-terms/perceptron-6168423.jpg' width=450>\n",
        "\n",
        "Das Perzeptron besteht aus folgenden Teilen:\n",
        "\n",
        "* **Input-Layer**. Der Input-Layer beinhaltet einerseits die Daten (x) und eine Bias-Unit (1)\n",
        "* **Wichtung (w)**. Die Gewichtung wird pro Verbindung zwischen dem Input und Output dargestellt und beinhaltet irgend einen Wert. \n",
        "* **Output-Layer** Die Ausgabeschicht besteht im wesentlichen aus der **Linear Threshold Unit (LTU)** welche folgende Funktionen beinhaltet: \n",
        "* **Übertragungsfunktion**. Diese Funktion (∑) berechnet die Wichtung mal Input plus Bias:\n",
        " \n",
        " $\\displaystyle \\sum_{i=1}^{n} =  (w_1 * x_1 + w_2 * x_2 + w_n * x_n) + Bias$\n",
        "\n",
        "* **Aktivierungsfunktion (ρ)**. Diese Funktion bestimmt die Ausgabe des Neurons. Sie wird durch die Netzeingabe und den Schwellwert beeinflusst. -> Siehe Activation Functions\n",
        "* **Schwellwert (θj)**. Das Addieren eines Schwellwerts zur Netzeingabe verschiebt die gewichtete Eingabe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL3SY6Urqo9O"
      },
      "source": [
        "#### Input Layer\n",
        "\n",
        "Die Daten werden über den Input Layer in das KNN übergeben. Im ersten Layer finden somit noch keine eigentlichen mathematischen Operationen statt und es gibt dort auch keine eigentlichen Knoten wie es in manchen Darstellungen suggeriert wird. Die Daten werden mittels eines 1D-Arrays in die Input-Schicht "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzCYdyxQ0KHx"
      },
      "source": [
        "#### Aktivierungsfunktion (engl. activation function)\n",
        "\n",
        "Die Aktivierungsfunktion ist der Teil eines künstlichen Neurons, welche die Summe aus der Übertragungsfunktion mittels einer definierten mathematischen Funktion modifiziert. Im wesentlichen geht es bei der AF in einem herkömmlichen neuralen Netzwerk mit Perceptrons Neuronen nur darum zu sagen ob etwas 0 oder 1 ist. Es gibt so gesehen zwei verschiedene AF-Typen Lineare AF und Not-Lineare AF.  Wobei die lineare Aktivierungsfunktion beim Deep Learning so gut wie nicht zur Anwendung kommen. Der Grund dafür ist, dass die reale Welt nicht lineare ist. \n",
        "\n",
        "Bei der nicht-linearen Aktivierungsfunktion unterscheidet man in der Regel zwischen der Derivative - oder Differential- Funktion und der Monotonic- Funktion.\n",
        "\n",
        "Damit eine kleiner Change bei den Gewichtungen (w) und dem Schwellwerten (b=Bias) nicht eine zu starke Auswirkung auf das ganze Neuronale Netzwerk hat, werden Aktivierungsfunktionen verwende, welche Werte zwischen 0 und 1 zu lassen bsp. 0.6669.\n",
        "\n",
        "Meist kommen in eine neuronalen Netzwerk verschiedene AFs vor. So wird beispielsweise bei den Hidden Layers de ReLU und bei den Output Layer Sigmoid verwendet.\n",
        "\n",
        "Die bekanntesten solcher in einem KNN verwendeten Aktivierungsfunktionen sind:\n",
        "\n",
        "* **Threshold - f(x)=(1 if x >= 0)(0 if x < 0)**\n",
        "\n",
        "  Hierbei handelt es sich um die einfachste Aktivierungsfunktion, weil sie lediglich prüft, ob ein Wert grösser oder kleinen als 0 ist. Diese Fuktion wird dann verwendet, wenn der Input binär ist also nur 0 oder 1 annehmen kann.\n",
        "\n",
        "* **Sigmoid - f(x) = 1 / (1 + exp(-x))**\n",
        "\n",
        "  Mit der Sigmoid-Funktion wird eine für diese Funktion typische S-Grafik erstellt. Dabei wird nicht nur der ein eindeutiger Wert (Bsp. 0 oder 1) ermittelt, sondern auch wie wahrscheinlich es ist den Wert 0 oder 1 zu erreichen. Diese Funktion ist somit Ideal, wenn es sich um binäre Werte handelt. Da diese Funktionen ihr Limiten hat bzw für das Deep Learning etwas zu langsam ist, wurden die folgenden Alternativen eingesetzt.\n",
        "\n",
        "* **Hyperbolic Tangent (tanh) - f(x) = sinh(x) / cosh(x)**\n",
        "\n",
        "  Die tanh-Funktion ist eine direkte alternative zu Sigmoid bzw. arbeitet ebenfalls mit der S-Grafik. Der wesentliche Unterschied ist, dass tanh Über einen Zahlenbereich von -1 bis 1 verfügt. \n",
        "\n",
        "  Die non-lineare AF Sigmoid und Hyperbolic Tangent werden bei Feed-forward KNNs eingesetzt. \n",
        "\n",
        "* **Rectified Linear Unit (ReLU) - f(x) = max(0,x)**\n",
        "Diese Funktion gehört zu den am meisten angewendeten Aktivierungsfunktionen in einem KNN bzw. Deep Learning. Sie ersetzte die Sigmoid-Funktionen am besten. Bei der ReLU werden sämtliche Werte welche negativ sind nur als 0 bezeichnet und die Werte welche postiv sind werden als diese übernohmen.\n",
        "\n",
        "Nachfolgend alle bekanntesten Aktivierungsfunktionen auf einen Blick:\n",
        "\n",
        "<img src='https://miro.medium.com/max/875/1*ZafDv3VUm60Eh10OeJu1vw.png' width=600>\n",
        "\n",
        "Quelle: [Medium.com](https://medium.com/@shrutijadon10104776/survey-on-activation-functions-for-deep-learning-9689331ba092)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvaSu_Ivf9bf"
      },
      "source": [
        "## Wie lernt eine KNN?\n",
        "Im einem KNN gibt es zwei Hauptmechanismen das **Forward Propagation** (auch Feedforward genannt) und **Back Propagation**.\n",
        "\n",
        "### Forward Propagation (Feedforward)\n",
        "\n",
        "Beim FP werden die einzelnen Datenwerte ($x_1, x_2, x_3$ usw.) mit einer gewichteten Verbindung ($w_1,w_2;w_3$ usw.) je einzel multipliziert und miteinander mittels Addition aufsummiert. Dieser Summe wird noch ein Bias hinzuaddiert. Das daraus entstandene Resultat wird dann in die Aktivierungsfunktion überträgen welche darüber entscheidet ob das Neuron sich aktiviert bzw. essentiell für die weitere Verarbeitung ist oder nicht. Dieser Prozess wiederholt sich jenachdem wieviele Hidden layers verwendet werden. Am Ende werden die Resultate in den Output Layer überführt und mittels der Cost Function gegenüber dem korrekten Resultat verglichen.  \n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/KNN_Cost_function_1.png?raw=true' width=600>\n",
        "\n",
        "### Backward Propagation (Backpropagation)\n",
        "\n",
        "Backpropagation ist nichts anderes als der Prozess in welchem die Gewichtungen der einzelnen Verbindungen angepasst werden bzw. das KNN optimiert wird. In der Optimierung geht es im Grundsatz darum die Cost function bzw. die Fehler zu minimieren. Dieser Prozess wird auch **Gradient descent** genannt.\n",
        "\n",
        "In der folgenden Grafik sehen wir unten rechts die sogenannte **Cost function (C)**. Die Cost function zeigt uns nichts anderes als die Differenz zwischen dem Output-Werten und den korrekten Werten. Diese Differenz wird als Fehler (Error) bezeichnet. Auf Basis des Resultats (Error) fängt das KNN seine gewichteten Verbindungen zu aktualisieren d.h. das KNN fängt sich an zu optimieren.\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/KNN_Cost_function_2.png?raw=true' width=600>\n",
        "\n",
        "Die in der obigen Grafik dargestellen Input Values sind die von lediglicher einer Zeile eines Datensatzes d.h jedes Feature (unabhängige Variable) stellt einen Input dar. Ein Datensatz mit 15 Merkmalen (Features) würde also 15 Input values bedeutet. \n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/KNN_Cost_function_3.png?raw=true' width=600>\n",
        "\n",
        "#### Gradient Descent\n",
        "\n",
        "Der Gradient Descent (Gradientverfahren) stellt einer der elementarsten Bestandteile eines KNNs dar. Aus diesem Grund wollen wir uns dieses Verfahren mal etwas genauer ansehen.\n",
        "\n",
        "Quelle: [Wikipedia](https://de.wikipedia.org/wiki/Gradientenverfahren)\n",
        "\n",
        "Das Gradientenverfahren wird in der Numerik eingesetzt, um allgemeine Optimierungsprobleme zu lösen. Dabei schreitet man (am Beispiel eines Minimierungsproblems) von einem Startpunkt aus entlang einer Abstiegsrichtung, bis keine numerische Verbesserung mehr erzielt wird. Wählt man als Abstiegsrichtung den negativen Gradienten, also die Richtung des lokal steilsten Abstiegs, erhält man das Verfahren des steilsten Abstiegs. Manchmal werden die Begriffe Gradientenverfahren und Verfahren des steilsten Abstiegs synonym verwendet. Im Allgemeinen bezeichnet Gradientenverfahren eine Optimierungsmethode, bei der die Abstiegsrichtung durch Gradienteninformation gewonnen wird, also nicht notwendigerweise auf den negativen Gradienten beschränkt ist.\n",
        "\n",
        "Das Verfahren des steilsten Abstiegs konvergiert oftmals sehr langsam, da es sich dem stationären Punkt mit einem starken Zickzack-Kurs nähert. Andere Verfahren für die Berechnung der Abstiegsrichtung erreichen teils deutlich bessere Konvergenzgeschwindigkeiten, so bietet sich für die Lösung von symmetrisch positiv definiten linearen Gleichungssystemen beispielsweise das Verfahren der konjugierten Gradienten an. Der Gradientenabstieg ist mit dem Bergsteigeralgorithmus (hill climbing) verwandt.\n",
        "\n",
        "In einer 2D grafischen Darstellung sieht Gradient Descent wie folgt aus:\n",
        "\n",
        "<img src='https://cdn-images-1.medium.com/max/600/1*iNPHcCxIvcm7RwkRaMTx1g.jpeg' width=500>\n",
        "\n",
        "Quelle: [MC.AI](https://mc.ai/an-introduction-to-gradient-descent-2/)\n",
        "\n",
        "Und in 3D so:\n",
        "\n",
        "<img src='https://miro.medium.com/max/875/1*yasmQ5kvlmbYMe8eDkyl6w.png' width=500>\n",
        "\n",
        "Quelle: [Medium.com](https://medium.com/@DBCerigoon-why-gradient-descent-is-even-needed-25160197a635)\n",
        "\n",
        "##### **Batch Gradient Descent (BGD)**\n",
        "\n",
        "Ist ein Gradientverfahren in welchem die ganzen Daten in einem grossen oder mehreren kleinen Batches (Einheiten) in das KNN eingespiesen werden. \n",
        "\n",
        "##### **Stochastic Gradient Descent (SGD)**\n",
        "\n",
        "In der vorletzten Grafik sehen wir wie Gradient Descent in einer gleichmässig nach aussen gebeugte Kurve (auch Convex genannt) aussieht. Nun ist aber so, dass in der realen Welt eine solche Gleichmässigkeit eher selten ist. In Wahrheit haben wir es mit unterschiedlichen Kurven mit mehreren tiefen Stellen zu tun. Damit die Funktion nun nicht einfach das Beste lokale Minimum sondern das globale Minimum (Best) der Cost funkton findet, ist ein stochastischer Ansatz notwendig. \n",
        "\n",
        "<img src='https://www.mltut.com/wp-content/uploads/2020/04/Untitled-document-3.png' width=550>\n",
        "\n",
        "Quelle: [MLTUT](https://www.mltut.com/stochastic-gradient-descent-a-super-easy-complete-guide/)\n",
        "\n",
        "##### **Batch vs. Stochastic Gradient Descent**\n",
        "\n",
        "SGD hat gegenüber dem BGD Verfahren mehrere Vorteile. Nicht nur das SGD mit nicht konvexen Funktionen umgehen kann bzw. das lokale Minimum Problem verhindert. Es ist auch noch schneller als das BGD Verfahren. Was in Anbetracht der zeilenweisen Einfütterung in ein KNN erstaunen mag aber so ist es :-).\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/KNN_Diff_Gradient_Descent.png?raw=true' width=600>\n",
        "\n",
        "Mehr zum Thema Gradient Descent ist unter diesem [Link](https://iamtrask.github.io/2015/07/27/python-network-part2/) oder diesem [Link](https://www.mltut.com/stochastic-gradient-descent-a-super-easy-complete-guide/) zu finden.\n",
        "\n",
        "Abschliessen noch ein kurzer Ablauf, wie eine KNN mit SGD trainiert wird:\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/Section%2039%20-%20Artificial%20Neural%20Networks%20(ANN)/Stochastic_Gradient_Descent.png?raw=true' width=600>\n",
        "\n",
        "In einem von Google entwickelten Tool kann man eine KNN simulieren:\n",
        "\n",
        "https://playground.tensorflow.org/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBGpU5Zptkbk"
      },
      "source": [
        "### Vanishing & Exploding Gradient Problems\n",
        "\n",
        "Im Zusammenhang mit der Backpropagation muss noch ein wichtiges Thema belichtet werden, welches unter anderem den Siegenszug von DL gebremst hat. \n",
        "\n",
        "Ein Problem bei Trainingsnetzwerken mit vielen Layers besteht darin, dass der Gradient dramatisch abnimmt, wenn er sich rückwärts durch das Netzwerk ausbreitet. Der Fehler kann zu dem Zeitpunkt, zu dem er Ebenen nahe der Eingabe des Modells erreicht, so gering sein, dass er möglicherweise nur sehr geringe Auswirkungen hat. Einfach gesagt heisst das, dass geringe Anpassungen an den Gewichtungen der Verbindungen zu einer Art Stagnierung führt bzw. das NN verringert den Error nur sehr minimal und dass NN hat Mühe sich an den optimalen Fehlerminimierung anzunähern. \n",
        "\n",
        "Anstelle der verschwindenden Gradients gibt es aber auch das Gegenteil. Die Gewicht habe zu hohe Werte und dies wiederum führt zum Exploding Gradient Problem, was das NN ebenfalls daran hindert zu einer optimalen Fehlerminimierung zu kommen.\n",
        "\n",
        "<img src='https://www.analyticsindiamag.com/wp-content/uploads/2019/08/afrnn.png' width=600>\n",
        "\n",
        "Die oben beschriebenen zwei Probleme sind vor allem bei RNNs und im Zusammenhang mit der Sigmoid-Funktion zu finden. Es gibt verschiedene Lösungen um mit dem Vanishing & Exploding Gradient Problem umzugehen.\n",
        "\n",
        "1.   Anstelle von Sigmoid einfach die ReLu Aktivierungsfunktion verwenden.\n",
        "2.   Batch normalization im NN integrieren.\n",
        "\n",
        "\n",
        "\n",
        "Hier noch ein gutes [Video](https://www.youtube.com/watch?v=SKMpmAOUa2Q), welche diese Problem genauer erklärt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR8AqwrmRl_2"
      },
      "source": [
        "## Fully Connected Neural Network (FCNN) - Klassifikation\n",
        "\n",
        "Eines der klassischen KNNs ist das Fully Connected Neural Network. Es wird so genannt, weil alle Units miteinander verbunden sind. Damit sind wir auch schon beim Haupproblem dieser Art KNNs angekommen. Fully Connected hat einen Einfluss auf die Performance.\n",
        "\n",
        "<img src='https://cdn-images-1.medium.com/max/720/1*VHOUViL8dHGfvxCsswPv-Q.png' width=500>\n",
        "\n",
        "Im nachfolgenden Beispiel bauen wir ein solches KNN um ein Klassifikationsproblem zu lösen. Für den Aufbau verwenden wird das Framework Tensorflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o58FN6eCyTBN"
      },
      "source": [
        "### Ausgangslage\n",
        "\n",
        "Eine Bank verliert innerhalb kurzer Zeit sehr viele Kunden. Sie möchte nun gerne Wissen, welche der noch bestehenden Kunden evtl. die Bank in den nächsten 6 Monaten abwandern (engl. churn) könnten. Für die Erstellung eins KNN-Regressionsmodells stellt sie einen Datensatz von 10000 Kunden zur Verfügung, welche noch bei der Bank sind oder diese bereits verlassen haben. Neben 13 Features (unabhängige Variablen) beinhaltet der Datensatz auch eine Spalte mit Labels (abhängige Variable).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7wEUUJrw0s_"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aMy3FaVWJJc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-dPtRXaL6aL",
        "outputId": "33684f52-0e70-4bb3-8f35-c42d9b13e51a"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrPhog7uxHYL"
      },
      "source": [
        "### Teil 1 - Datenaufbereitung (Data Preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pRyhRL_1tzr"
      },
      "source": [
        "#### Datenimport\n",
        "\n",
        "Nach dem wir die Daten importiert haben, werden wir sie, wie immer im Supervised Learning, in einen Datensatz mit unabhängigen und abhängigen Variablen aufteilen. Bevor wir aber die Datenwerte (Values) in zwei Datensätze teilen, schauen wir uns mal den importierten Datensatz an. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INjwpXRYxOV9"
      },
      "source": [
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/Section%2039%20-%20Artificial%20Neural%20Networks%20(ANN)/Python/Churn_Modelling.csv'\n",
        "\n",
        "dataset = pd.read_csv(datloc)\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6HlzPOOU1gh"
      },
      "source": [
        "Prüfen wir doch auch noch gleich, ob wir fehlende Daten haben. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cerT8oa-TuMW"
      },
      "source": [
        "dataset.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCSy935pPKSW"
      },
      "source": [
        "Beim betrachten des Datensatzes müssen wir uns überlegen, welche Features für das Modell überhaupt relevant sind bzw. welche Features eine Einfluss auf das Label (abhängige Variable) haben. Wir könnten natürlich alle Spalten bestehen lassen aber dann müssten wir auch die nicht relevanten kategorischen Merkmale in nummerische Wert umwandeln. Diese Arbeit können wir uns sparen in dem wir eine Vorselektion machen.\n",
        "\n",
        "Wenn wir nun also den orginal Datensatz betrachten, dann können wir mit Sicherheit sagen, dass die Merkmale RowNumber, CustomerId und Surname keinen Einfluss auf das Label Exited haben werden. Somit müssen wir nur alle Features ab Spalte 4 (in Python 3, da es bei 0 anfängt) bis minus der letzen Spalte (Label) in X importieren."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu3WhSETPELd"
      },
      "source": [
        "X = dataset.iloc[:,3:-1].values\n",
        "y = dataset.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS9XOEOHQ8RM"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEb19jLOSW6Z"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2KjKpVX16O0"
      },
      "source": [
        "#### Encoding von kategorischen Daten\n",
        "\n",
        "Wie wir im Datensatz unschwer erkennen können, beinhaltet diese auch kategorische Daten wie Geography (Land) und Gender (Geschlecht). Mit diesen kann eine KNN nichts anfangen. \n",
        "Während Geography drei unterschiedliche Werte enthält sind beim Feature Gender nur zwei Zustände zu beaobachten Female oder Male. Auf Basis dieser Erkenntnisse setzen wir nun folgende Encoding ein:\n",
        "\n",
        "Geography = One Hot Encoding\n",
        "\n",
        "Gender = Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10FHtoB5cpxA"
      },
      "source": [
        "# Prüfen wir noch kurz wieviele Werte das Feature Geography hat.\n",
        "dataset.groupby(by=['Geography'], axis=0).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZSAHCIhXGOj"
      },
      "source": [
        "##### LabelEncoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_c5bgQ615eY"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "# Gender ist die Spalte 2\n",
        "X[:,2] = le.fit_transform(X[:,2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgRHovrDXRdu"
      },
      "source": [
        "##### OneHotEncoding\n",
        "\n",
        "Die Anwendung von Datentransformationen wie Skalierung oder Codierung kategorischer Variablen ist einfach, wenn alle Eingabevariablen vom gleichen Typ sind. Es kann eine Herausforderung sein, wenn man einen Datensatz mit gemischten Typen haben und man Datentransformationen selektiv auf einige, aber nicht alle Eingabefunktionen anwenden möchten.\n",
        "\n",
        "Dankenswerterweise stellt die Scikit-Learn-Bibliothek für maschinelles Lernen in Python den **ColumnTransformer** zur Verfügung, mit dem man Datentransformationen selektiv auf verschiedene Spalten in Ihrem Dataset anwenden können.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uF9_PVvWQm-"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "# Nun bauen wir uns die benötigte Funktion zusammen wobei wir der Funktion die \n",
        "# Encoding Methode und die Spaltennummer mitgeben.\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(),[1])], remainder='passthrough')\n",
        "# Jetzt können wir die erstellte Funktion nutzen. Wichtig dabei ist, dass wir die Daten nach dem\n",
        "# Encoding wieder in die richtige Form bzw. einen Array bringen.\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnKwNVPKcA50"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-fzWIkJKSRp"
      },
      "source": [
        "#### Splitting des Datensatzes (Training/Testing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6ms3BrOxbBo"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTjAkNEeKmnS"
      },
      "source": [
        "#### Feature Scaling\n",
        "\n",
        "Wen man ein KNN baut, dann ist das Scaling der Daten ein **MUSS**. Scaling ist im Zusammenhang mit DL so wichtig, dass wir jeweils alle Features, auch wenn sie nur Werte wie 0 oder 1 beinhalten skalieren. Kurz gesagt wir skalieren immer den ganzen Datensatz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlH9JEV11EUx"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6JoNPSljQ0e"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFXDsqqojZoh"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9Jgswm_K9ED"
      },
      "source": [
        "### Teil 2 - Aufbau des KNN\n",
        "\n",
        "Kommen wir nun zum Aufbau unseres Fully connected neuronal networks. Wir werden das KNN mittels [TensorFlow](https://de.wikipedia.org/wiki/TensorFlow#2.0:_TensorFlow_2.0) bauen. Wobei wir strenggenommen das im TF 2.0 integierten Deep-Learning-Bibliothek [Keras](https://de.wikipedia.org/wiki/Keras) verwenden.\n",
        "\n",
        "Um es vielleicht etwas bildlich darzustellen ... wir bauen uns im Teil 2 das eigentliche Hirn unseres KNNs.\n",
        "\n",
        "<img src='https://www.simplyscience.ch/assets/images/5/Titelbild_Unser%20Gehirn-60f8bf65.jpg' width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtP4ouT1kkPl"
      },
      "source": [
        "#### KNN Initialisierung \n",
        "\n",
        "Der Aufbau eines KNN ist nichts anderes als die Aneinanderreihung (Sequenzierung) von Layers (Schichten). Wir müssen deshalb zuerst einmal das Rahmenkonstrukt unseres KNNs bauen und teilen diesem Konstrukt mit, dass es alles was wir darin einbauen sequenziell abarbeiten soll. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4hI7yCflQWe"
      },
      "source": [
        "knnk = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzr6xtYlkxMq"
      },
      "source": [
        "#### Hinzufügen des Input Layers und ersten Hidden Layers\n",
        "\n",
        "Nachfolgend bauen wir nun den ersten Hidden Layer. Den Input Layer müssen wir nicht explizit definieren, da dieser ja aus der Anzahl Features besteht, welche wir ins KNN einspeisen. \n",
        "\n",
        "Da wir das einfachste Basic KNN (FKNN) bauen benötigen wir lediglich die Keras- Klasse Dense. Dense (dt. dicht) definiert nichts anderes als, dass jede Unit mit jeder Unit in der nächsten Schicht verbunden ist (Fully connected).\n",
        "\n",
        "Ein wichtig Fragen im Zusammenhang mit dem Hidden Layers ist immer die Anzahl Units (Neuronen) die man in diesem Layer definiert. Um es kurz zu halten ... es gibt hier keine wirklich Richtwert ... hier gilt einfach Try and Error :-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLmhZ16ypfeX"
      },
      "source": [
        "# Unser Hidden Layer wird mit 6 Units definiert und die Aktivierungsfunktion wird \n",
        "# mit der ReLu Funktion gemacht. \n",
        "knnk.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0KBctYzk_YM"
      },
      "source": [
        "#### Hinzufügen des zweiten Hidden Layers\n",
        "\n",
        "Den zweiten Hidden Layer hinzuzufügen ist sehr einfach. Einfach die vorhergehende Codezeile kopieren :-). Es steht aber jedem frei in der zweiten Schicht die Anzahl der Units zu erhöhen. Dies kann aber während des Trainings immer noch gemacht werden, um eine verbesserte Performance zu erreichen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWdJFjjCrt25"
      },
      "source": [
        "knnk.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEeUA2EOlI9T"
      },
      "source": [
        "#### Hinzufügen des Output Layers\n",
        "\n",
        "Nun fügen wir noch einen Output Layer hinzu. Auch hier können wir natürlich die Codezeile von oben kopieren, müssen aber zwei Parameter anpassen.\n",
        "\n",
        "Die Anzahl der Units im Output Layer hängen davon ab, wieviele mögliche Werte wir predicten können. Bei diesem Datensatz haben wir es mit einem binären Resultat d.h. 0 oder 1 zu tun. Weshalb wir im Output also nur eine Unit definieren. Würden wir einen Klassifikator bauen mit welche wir handgeschiebene Zahlen von 0 - 9 erkennen wollten, dann würden wir also 10 Units (Pro Zahl eine Unit) definieren. \n",
        "\n",
        "Wir müssen auch noch die Aktivierungsfunktion im Output Layer ändern und zwar auf Sigmoid, Softmax, tanh usw. Der Grund ist ganz einfach. Das Ziel unseres KNNs ist es, die Wahscheinlichkeit (Probability) zu berechnen, mit der wir bei einem Kunden mit einer Abwanderung zu rechnen haben. Die Wahrscheinlichkeit kann uns eine Funktion wie ReLu nicht geben, da diese Funktion nur 0 oder nicht 0 kennt. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wfd1p1Ivegk"
      },
      "source": [
        "knnk.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJmuZXfNLHRr"
      },
      "source": [
        "### Teil 3 - Training des KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIEf4j4d4kBB"
      },
      "source": [
        "#### Kompilierung des KNN\n",
        "\n",
        "Nachdem wir nun sozusagen das Hirn (KNN) gebaut haben, müssen wir noch definieren wie es funktionieren soll. Für ein funktionierendes KNN müssen wir noch folgenden Funktionen definieren:\n",
        "\n",
        "**Optimizer** \n",
        "\n",
        "Damit die gewichteten Verbindungen im KNN optimiert werden, benötigen wir ein Gradient descent Verfahren. Wie wir ja mittlerweilen Wissen, eigenet sich ein stochastischen Gradientverfahren am Besten um nicht nur ein lokales Minimum sondern das globale Minimum herauszufinden. Eines der bekanntesten SGD-Verfahren ist der Adam Optimisierungsalgoritmus. Mehr dazu unter dem folgenden [Link](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/). Es gibt aber noch eine Vielzahl weiterer Opimizer im Keras ([Link](https://keras.io/api/optimizers/))\n",
        "\n",
        "**Cost-Function**\n",
        "\n",
        "Mittels der Cost function (auch Loss function) genannt wird die Fehlerrate des Outputs ermittelt. Auf Basis des ermittelten Fehlers wird das KNN mittels Optimizer optimiert. Je nach dem welche Art von Problem man mit dem KNN lösen möchte wird eine andere Cost function verwendet. Nachfolgend eine Auflistung der im Keras verfügbaren Loss Functions:\n",
        "\n",
        "* **Regressions**\n",
        "  * Mean Squared Error Loss\n",
        "  * Mean Squared Logarithmic Error Loss\n",
        "  * Mean Absolute Error Loss\n",
        "* **Binary Classification**\n",
        "  * Binary Cross-Entropy\n",
        "  * Hinge Loss\n",
        "  * Squared Hinge Loss\n",
        "* **Multi-Class Classification**\n",
        "  * Multi-Class Cross-Entropy Loss\n",
        "  * Sparse Multiclass Cross-Entropy Loss\n",
        "  * Kullback Leibler Divergence Loss\n",
        "\n",
        "Da wir in unserem Beispiel eine binäre Klassifikation durchführen können wir unter drei verschiedenen Loss functions auswählen. Mehr darüber auf diesem [Link](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/).\n",
        "\n",
        "**Metriken**\n",
        "\n",
        "Um die Performance der KNN zu messen, bedienen wir uns verschiedener Metriken.\n",
        "Die verwendete Metrik ist ebenfalls davon abhängig, welches Problem wir mittels DL lösen wollen. Nachfolgend eine Auflistung der im Keras verfügbaren Metriken:\n",
        "\n",
        "* **Regression**\n",
        "  * Mean Squared Error: mean_squared_error, MSE or mse\n",
        "  * Mean Absolute Error: mean_absolute_error, MAE, mae\n",
        "  * Mean Absolute Percentage Error: mean_absolute_percentage_error, MAPE, mape\n",
        "  * Cosine Proximity: cosine_proximity, cosine\n",
        "* **Classification**\n",
        "  * Binary Accuracy: binary_accuracy, acc\n",
        "  * Categorical Accuracy: categorical_accuracy, acc\n",
        "  * Sparse Categorical Accuracy: sparse_categorical_accuracy\n",
        "  * Top k Categorical Accuracy: top_k_categorical_accuracy (requires you specify a k parameter)\n",
        "  * Sparse Top k Categorical Accuracy: sparse_top_k_categorical_accuracy (requires you specify a k parameter\n",
        "\n",
        "Mehr darüber auf diesem [Link](https://machinelearningmastery.com/custom-metrics-deep-learning-keras-python/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDnSuCLS4s_-"
      },
      "source": [
        "knnk.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZNdu51445FR"
      },
      "source": [
        "#### Training mit dem Trainingset\n",
        "\n",
        "Kommen wir nun eigentlichen Training des KNNs. Hier für benötigen wir neben der Fit-Funktion und den Trainingsdaten auch noch weitere Hyperparameter:\n",
        "\n",
        "**Batch Size** \n",
        "\n",
        "Im Grundsatz geht es bei der Batch Size lediglich darum, wieviele Samples (Zeilen) pro Durchgang ins KNN eingespiesen werden bevor das KNN optimiert wird.\n",
        "\n",
        "**Epoch**\n",
        "\n",
        "Epoch ist ein Hyperparameter, der die Anzahl der Druchgänge definiert, die der Lernalgorithmus den gesamten Trainingsdatensatz durcharbeitet. Eine Epoche bedeutet, dass jedes Sample im Trainingsdatensatz die Möglichkeit hatte, die internen Modellparameter zu aktualisieren. Eine Epoche besteht aus einem oder mehreren Batches. Zum Beispiel wird eine Epoche, die aus einer Batch besteht, wie oben beschrieben, als Batch Gradient Desent-Lernalgorithmus bezeichnet.\n",
        "\n",
        "Hier ein Beispiel:\n",
        "\n",
        "Angenommen, man hat einen Datensatz mit 200 Stichproben (Zeilen) und man wählen eine Batch-Grösse von 5 und 1000 Epochen.\n",
        "\n",
        "Dies bedeutet, dass der Datensatz in 40 Batches mit jeweils fünf Stichproben aufgeteilt wird. Die Modellgewichte werden nach jedem Batch mit fünf Stichproben aktualisiert.\n",
        "\n",
        "Das bedeutet auch, dass eine Epoche 40 Batches oder 40 Aktualisierungen des Modells umfasst.\n",
        "\n",
        "Bei 1000 Epochen wird das Modell den gesamten Datensatz 1000 Mal durchlaufen. Das sind insgesamt 40.000 Batches während des gesamten Trainings.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an2qoiUrSMqB"
      },
      "source": [
        "# Wir definieren hier eine Batch-Grösse von 32 Samples über 100 Epochen.\n",
        "# Das bedeutet, dass auf 8000 Samples (Zeilen) 250 Batches kommen welche bei jeder\n",
        "# Epoche durch das KNN geschleust werden. Während des ganzen Training wird das KNN somit\n",
        "# 250 Mal aktualisiert und es laufen 25000 Batches durch das KNN durchlaufen.\n",
        "knnk.fit(X_train, y_train, batch_size= 32, epochs = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHnGI-fZLS8P"
      },
      "source": [
        "### Teil 4 - Durchführung der Prediction und evaluieren des Modells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JULHWzXeqm6"
      },
      "source": [
        "#### Vorhersagen eines Resultats einer einzelnen Beobachtung\n",
        "\n",
        "Anschliessend wollen wir mittels den folgenden Informationen eine Vorhersage tätigten, ob diese Kunde ebenfalls von der Bank abwandern wird.\n",
        "\n",
        "Geography: France\n",
        "\n",
        "Credit Score: 600\n",
        "\n",
        "Gender: Male\n",
        "\n",
        "Age: 40 years old\n",
        "\n",
        "Tenure: 3 years\n",
        "\n",
        "Balance: \\$ 60000\n",
        "\n",
        "Number of Products: 2\n",
        "\n",
        "Does this customer have a credit card ? Yes\n",
        "\n",
        "Is this customer an Active Member: Yes\n",
        "\n",
        "Estimated Salary: \\$ 50000\n",
        "\n",
        "Wichtig bei der Prediction eines einzelnen Resultats ist,\n",
        "\n",
        "1. Die Werte müssen in eine doppelten eckigen Klammer [[]] stehen, da wir die Daten in einem 2D Array ins KNN einfliessen lassen.\n",
        "2. Die Werte der Feartures, welche encodet wurden müssen auch in dieser Form eingegeben werden. Bspw. France hat codiert den Wert 1,0,0 \n",
        "3. Die Werte müssen mit der gleichen Skalierung transformiert werden wie die Wert im Trainings und Testdatensatz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGX61KuPf13X"
      },
      "source": [
        "print('Die Wahrscheinlichkeit, dass der Kunde die Bank verlassen wird liegt bei:', knnk.predict(sc.transform([[1,0,0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\n",
        "\n",
        "# Nachfolgend werden wir den Wert in eine True oder False umwandeln. Hier können wir den Wert > 0.5\n",
        "# definieren. Ist also der vorhergesagte Wert grösser als 0.5 (50%) besteht eine höhere Wahrscheinlichkeit\n",
        "# dass der Kunde bleiben wird. Wünscht das Management eine genauere Analyse kann der Wert auch erhöht werden.\n",
        "if (knnk.predict(sc.transform([[1,0,0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5) == False:\n",
        "  print ('Der Kunde wir die Bank nicht verlassen')\n",
        "else:\n",
        "  print ('Der Kunde wird die Bank verlassen')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4peSlDduo5MD"
      },
      "source": [
        "#### Vorhersage der Testdatenresultate\n",
        "\n",
        "Nun wollen wir mal schauen wie gut das Modell auf dem Testdatensatz funktioniert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL5gsY98idBD"
      },
      "source": [
        "y_pred = knnk.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjg5Lwf2qX4t"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_pred, y_test)\n",
        "print('True Positiv, heisst:',cm[0][0],'Kunden werden gemäss Vorhersage bleiben und sind in Wirklickeit auch geblieben.')\n",
        "print('True Negativ, heisst:',cm[1][1],'Kunden werden gemäss Vorhersage gehen und sind in Wirklichkeit auch gegangen.')\n",
        "print('False Negativ, heisst:',cm[0][1],'Kunden werden gemäss Vorhersage gehen, sind in Wirklichkeit aber geblieben.')\n",
        "print('False Positiv, heisst:',cm[1][0],'Kunden werden gemäss Vorhersage bleiben, sind in Wirklichkeit aber gegangen.')\n",
        "print()\n",
        "print('Das Modell machte in',accuracy_score(y_pred, y_test)*100,'Prozent der Fälle eine korrekte Vorhersagen d.h. bei 86 von 100 Kunden stimmte die Vorhersage.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO0-lJBK79y_"
      },
      "source": [
        "## Fully Connected Neural Network (FCNN) - Regression\n",
        "\n",
        "Nachfolgend werden wir noch ein Beispiel eines KNN für ein Regressionsprobleme erstelle. Es werden nicht mehr so detailierte Erklärungen wie beim vorherigen Beispiel folgen, da einiges gleich bleibt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1aC35WADci2"
      },
      "source": [
        "### Ausgangslage\n",
        "\n",
        "Für dieses Beispiel werden wir einen Datensatz aus dem [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table) nehmen. Der Datensatz  beinhaltet Daten eines [Gas-und Dampf-Kombikraftwerks](https://de.wikipedia.org/wiki/Gas-und-Dampf-Kombikraftwerk) (engl. Combined Cycle Power Plant).\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/ISK_Knapsack_GuD_2007.jpg/1920px-ISK_Knapsack_GuD_2007.jpg' width=500>\n",
        "\n",
        "1.Bild: Gas- und Dampf-Kraftwerk Knapsack des Unternehmens Statkraft mit zwei Gasturbinen\n",
        "\n",
        "\n",
        "\n",
        "##### **Beschreibung des Datensatzes**\n",
        "\n",
        "Der [Datensatz](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant) beinhaltet 9568 Datenpunkte (Zeilen) welche über eine Zeitraum von 6 Jahren (2006-2011) gesammelt wurden. Der Datensatz verfügt über vier unabhängige Variablen und einer abhängigen Variable (Label).\n",
        "Die Merkmale bestehen aus stündlich gemittelten Umgebungsvariablen\n",
        "* Temperatur (T) im Bereich von 1,81°C und 37,11°C,\n",
        "* Umgebungsdruck (AP) im Bereich von 992,89-1033,30 milibar,\n",
        "* Relative Luftfeuchtigkeit (RH) im Bereich von 25,56% bis 100,16%\n",
        "* Auslass-Unterdruck (V) im Bereich 25,36-81,56 cm Hg (Zentimeter Quecksilbersäule)\n",
        "\n",
        "Das Label besteht aus der Netto-Stundenleistung an elektrischer Energie (EP) 420,26-495,76 MegaWatt (MW).\n",
        "\n",
        "Die Mittelwerte werden von verschiedenen Sensoren genommen, die sich um die Anlage herum befinden und die Umgebungsvariablen jede Sekunde aufzeichnen. Die Variablen werden ohne Normalisierung angegeben.\n",
        "\n",
        "Ein Kombikraftwerk (CCPP) besteht aus Gasturbinen (GT), Dampfturbinen (ST) und Dampferzeugern mit Wärmerückgewinnung. In einem GuD-Kraftwerk wird der Strom durch Gas- und Dampfturbinen erzeugt, die in einem Zyklus kombiniert und von einer Turbine auf eine andere übertragen werden. Während das Vakuum von der Dampfturbine gesammelt wird und sich auf die Dampfturbine auswirkt, beeinflussen die anderen drei Umgebungsvariablen die Leistung der GT.\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Prinzip_Gas-und-Dampf-Kombikraftwerk.svg/1920px-Prinzip_Gas-und-Dampf-Kombikraftwerk.svg.png' width=500>\n",
        "\n",
        "2.Bild: Funktionsweise eines GuD-Kraftwerks\n",
        "\n",
        "##### **Ziel**\n",
        "\n",
        "Es soll mittels Regression der stündliche Netto-Stundenertrag an elektrischer Energie (EP) welches das Kraftwerks erzeugt vorhergesagt werden.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHLB_-8oVr2N"
      },
      "source": [
        "### Teil 1 - Datenaufbereitung (Data Preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gocbCIizJjnv"
      },
      "source": [
        "#### Datenimport"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKXzepZoWNb4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABML0Cs1KVcB",
        "outputId": "c2518312-90d2-46ec-fcd3-15bc593fbe2d"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSG9FAuSWXuE"
      },
      "source": [
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/Section%2039%20-%20Artificial%20Neural%20Networks%20(ANN)/Python/CCPP_Data_Set.xlsx'\n",
        "dataset = pd.read_excel(datloc)\n",
        "\n",
        "X = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPrwArjPJnPG"
      },
      "source": [
        "#### Datensatz in Trainings- und Testdaten aufteilen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl6R_kG0J2DX",
        "outputId": "bf8f57fd-110f-400d-ccf6-b5cc4bec72d0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=0)\n",
        "\n",
        "print('In unserem Trainingsdatenset befinden sich',X_train.shape[0],'Zeilen.')\n",
        "print('Im Testdatenset befinden sich',X_test.shape[0],'Zeilen')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In unserem Trainingsdatenset befinden sich 7654 Zeilen.\n",
            "Im Testdatenset befinden sich 1914 Zeilen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o05cyLEbhL_y"
      },
      "source": [
        "#### Skalierung der Daten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY_eYeNBhSFZ"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VdjISgghI73"
      },
      "source": [
        "### Teil 2 - Aufbau des KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai7HAznEjklk"
      },
      "source": [
        "#### Initialisierung des KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC1OjIcihwIy"
      },
      "source": [
        "knnr = tf.keras.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YZPcX5ajrLp"
      },
      "source": [
        "#### Hinzufügen des Input Layers und des ersten Hidden Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sBT2599ky3t"
      },
      "source": [
        "knnr.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bYLmM1Tj3zT"
      },
      "source": [
        "#### Hinzufügen des zweiten Hidden Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97ZlrMTvlvvN"
      },
      "source": [
        "knnr.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YqxCrHFletX"
      },
      "source": [
        "#### Hinzufügen des Output Layer\n",
        "\n",
        "Im Gegensatz zu KNN für Klassifikation müssen wir bei der Regression keine Aktivierungsfunktion hinzufügen (Default activation = none), da wir ja den eigentlichen Wert möchten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLIkYQROlyfN"
      },
      "source": [
        "knnr.add(tf.keras.layers.Dense(units=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxZUVdsXjNcb"
      },
      "source": [
        "### Teil 3 - Training des KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHDJ2tQqoF6e"
      },
      "source": [
        "#### Kompilierung des KNN\n",
        "\n",
        "Hier kommt noch eine Unterschied gegenüber einem KNN für Klassifikation. Die Cost function ist bei Regression natürlich die mittlere quadratische Abweichunng (Mean squared error)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU7qwzXkn83v"
      },
      "source": [
        "knnr.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYMlsWtrpaCn"
      },
      "source": [
        "#### Training des KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ajLY0EmpfG4",
        "outputId": "9ea0aca2-0f82-4433-d0de-29cda820640b"
      },
      "source": [
        "knnr.fit(X_train, y_train, batch_size=32, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 204587.6094\n",
            "Epoch 2/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 191595.4375\n",
            "Epoch 3/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 153640.0781\n",
            "Epoch 4/100\n",
            "240/240 [==============================] - 0s 989us/step - loss: 93902.4922\n",
            "Epoch 5/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 44891.5195\n",
            "Epoch 6/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25667.0605\n",
            "Epoch 7/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20528.8418\n",
            "Epoch 8/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 17263.1699\n",
            "Epoch 9/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 14014.3926\n",
            "Epoch 10/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 10809.6699\n",
            "Epoch 11/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 7899.3140\n",
            "Epoch 12/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 5543.3428\n",
            "Epoch 13/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 3764.4941\n",
            "Epoch 14/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 2460.3867\n",
            "Epoch 15/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 1561.5304\n",
            "Epoch 16/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 988.9929\n",
            "Epoch 17/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 635.4805\n",
            "Epoch 18/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 422.0427\n",
            "Epoch 19/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 289.6678\n",
            "Epoch 20/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 204.5656\n",
            "Epoch 21/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 146.7824\n",
            "Epoch 22/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 107.9543\n",
            "Epoch 23/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 82.3116\n",
            "Epoch 24/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 64.6839\n",
            "Epoch 25/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 52.3700\n",
            "Epoch 26/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 43.5312\n",
            "Epoch 27/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 37.1718\n",
            "Epoch 28/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 32.7967\n",
            "Epoch 29/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 29.6894\n",
            "Epoch 30/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.5946\n",
            "Epoch 31/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25.8952\n",
            "Epoch 32/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 24.7997\n",
            "Epoch 33/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 23.9294\n",
            "Epoch 34/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 23.4062\n",
            "Epoch 35/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 22.8591\n",
            "Epoch 36/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 22.5169\n",
            "Epoch 37/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 22.3309\n",
            "Epoch 38/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 22.0014\n",
            "Epoch 39/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.8746\n",
            "Epoch 40/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.7364\n",
            "Epoch 41/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 21.6902\n",
            "Epoch 42/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.4845\n",
            "Epoch 43/100\n",
            "240/240 [==============================] - 0s 989us/step - loss: 21.3997\n",
            "Epoch 44/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.3631\n",
            "Epoch 45/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.3632\n",
            "Epoch 46/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.3386\n",
            "Epoch 47/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.2606\n",
            "Epoch 48/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 21.3292\n",
            "Epoch 49/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.3208\n",
            "Epoch 50/100\n",
            "240/240 [==============================] - 0s 972us/step - loss: 21.3516\n",
            "Epoch 51/100\n",
            "240/240 [==============================] - 0s 989us/step - loss: 21.1262\n",
            "Epoch 52/100\n",
            "240/240 [==============================] - 0s 981us/step - loss: 21.1598\n",
            "Epoch 53/100\n",
            "240/240 [==============================] - 0s 972us/step - loss: 21.1195\n",
            "Epoch 54/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.2343\n",
            "Epoch 55/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.1948\n",
            "Epoch 56/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 21.0269\n",
            "Epoch 57/100\n",
            "240/240 [==============================] - 0s 977us/step - loss: 20.9578\n",
            "Epoch 58/100\n",
            "240/240 [==============================] - 0s 972us/step - loss: 21.0652\n",
            "Epoch 59/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.9997\n",
            "Epoch 60/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 21.1095\n",
            "Epoch 61/100\n",
            "240/240 [==============================] - 0s 985us/step - loss: 21.1294\n",
            "Epoch 62/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 21.0450\n",
            "Epoch 63/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.8655\n",
            "Epoch 64/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.8956\n",
            "Epoch 65/100\n",
            "240/240 [==============================] - 0s 972us/step - loss: 21.0903\n",
            "Epoch 66/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.7834\n",
            "Epoch 67/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.8403\n",
            "Epoch 68/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.7892\n",
            "Epoch 69/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.8075\n",
            "Epoch 70/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.7897\n",
            "Epoch 71/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.7009\n",
            "Epoch 72/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.8499\n",
            "Epoch 73/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.7484\n",
            "Epoch 74/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.6743\n",
            "Epoch 75/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.6382\n",
            "Epoch 76/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.7297\n",
            "Epoch 77/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.8052\n",
            "Epoch 78/100\n",
            "240/240 [==============================] - 0s 985us/step - loss: 20.6867\n",
            "Epoch 79/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.8579\n",
            "Epoch 80/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.8045\n",
            "Epoch 81/100\n",
            "240/240 [==============================] - 0s 985us/step - loss: 20.7920\n",
            "Epoch 82/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.7600\n",
            "Epoch 83/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.6023\n",
            "Epoch 84/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.7738\n",
            "Epoch 85/100\n",
            "240/240 [==============================] - 0s 968us/step - loss: 20.8130\n",
            "Epoch 86/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.5807\n",
            "Epoch 87/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.6797\n",
            "Epoch 88/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.5995\n",
            "Epoch 89/100\n",
            "240/240 [==============================] - 0s 981us/step - loss: 20.7089\n",
            "Epoch 90/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.7518\n",
            "Epoch 91/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.5908\n",
            "Epoch 92/100\n",
            "240/240 [==============================] - 0s 985us/step - loss: 20.7109\n",
            "Epoch 93/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.6903\n",
            "Epoch 94/100\n",
            "240/240 [==============================] - 0s 987us/step - loss: 20.7018\n",
            "Epoch 95/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.6662\n",
            "Epoch 96/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.5568\n",
            "Epoch 97/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.8178\n",
            "Epoch 98/100\n",
            "240/240 [==============================] - 0s 989us/step - loss: 20.6235\n",
            "Epoch 99/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.6174\n",
            "Epoch 100/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.6274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x258264dc070>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrHNTLRLjO88"
      },
      "source": [
        "### Teil 4 - Durchführung der Prediction und evaluieren des Modells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWJRIgL1rq9K",
        "outputId": "0298bbdb-8e8f-4bc0-f717-26c5919680c8"
      },
      "source": [
        "y_pred = knnr.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[432.4  431.23]\n",
            " [457.71 460.01]\n",
            " [461.35 461.14]\n",
            " ...\n",
            " [468.24 473.26]\n",
            " [442.72 438.  ]\n",
            " [461.18 463.28]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF7_tN87uBgx",
        "outputId": "df6e8110-3fe6-44d1-e21b-17fedbb25a43"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "score = r2_score(y_test,y_pred, multioutput='variance_weighted')\n",
        "print('Der r2 Score ohne Skalierung ist 0.9159165151046462')\n",
        "print('Der r2 Score mit Skalierung ist',score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Der r2 Score ohne Skalierung ist 0.9159165151046462\n",
            "Der r2 Score mit Skalierung ist 0.9320946784214379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX-ICYbywWLH"
      },
      "source": [
        "Wir sehen mittels des Bestimmtheitsmaß (r2 Scores), dass das Resultat mit Skalierung der Daten um 0.02 Prozent besser ausfällt als ohne Skalierung. Es lohnt sich also in einen KNN die Daten zu skalieren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq9MIqn4Rlnn"
      },
      "source": [
        "## Convolutional Neural Networks (CNN)\n",
        "\n",
        "Quelle: [Wikipedia](https://de.wikipedia.org/wiki/Convolutional_Neural_Network)\n",
        "\n",
        "Ein Convolutional Neural Network (CNN oder ConvNet), zu Deutsch \"faltendes neuronales Netzwerk“, ist ein künstliches neuronales Netz. Es handelt sich um ein von biologischen Prozessen inspiriertes Konzept im Bereich des maschinellen Lernens[1]. Convolutional Neural Networks finden Anwendung in zahlreichen Technologien der künstlichen Intelligenz, vornehmlich bei der maschinellen Verarbeitung von Bild- oder Audiodaten.\n",
        "\n",
        "Grundsätzlich besteht die Struktur eines klassischen Convolutional Neural Networks aus einem oder mehreren **Convolutional Layer**, gefolgt von einem **Pooling Layer**. Diese Einheit kann sich prinzipiell beliebig oft wiederholen, bei ausreichend Wiederholungen spricht man dann von Deep Convolutional Neural Networks, die in den Bereich Deep Learning fallen. Nach den genannten Layers folgt ein **Flattening** und danach werden die Resultate aus dem Conv-Net in ein **Fully-Connected Neural Network** übertragen in welchem die eigentliche Klassifkation stattfindet.\n",
        "\n",
        "<img src='https://miro.medium.com/max/758/1*-Bo5d1RCDWu9MeHluC5hfw.png' \n",
        "width=600>\n",
        "\n",
        "Die Daten durchlaufen das CNN in folgenden Schritten:\n",
        "\n",
        "<img src='https://miro.medium.com/max/411/1*XFLitGL4Q54PjXqx2pFztg.png' width=200>\n",
        "\n",
        "Innerhalb der Conv- und Polling-Layer besteht ein **Feature Detector** (auch Kernel oder Filter genannt) der Schrittweise durch die Matrix ders Input Images schreitet und seine Resultate in eine sogenannte **Feature Map** schreibt. \n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/CNN_function_1.jpg?raw=true' width=500>\n",
        "\n",
        "Wichtig ist hierbei noch zu erwähnen, dass es noch einen **ReLu Layer** gibt.\n",
        "ReLU wird mit einer elementweise Operation (pro Pixel angewendet) und ersetzt alle negativen Pixelwerte in der Feature Map durch Null. Der Zweck von ReLU besteht darin, Nichtlinearität in unser ConvNet einzuführen, da die meisten Daten der realen Welt, die unser ConvNet lernen soll, nichtlinear sind (Faltung ist eine lineare Operation - elementweise Matrixmultiplikation und -addition, so dass wir die Nichtlinearität durch Einführung einer nichtlinearen Funktion wie ReLU berücksichtigen).\n",
        "\n",
        "**Pooling**\n",
        "\n",
        "Im folgenden Schritt, dem Pooling, werden überflüssige Informationen verworfen. Zur Objekterkennung in Bildern etwa ist die exakte Position einer Kante im Bild von vernachlässigbarem Interesse – die ungefähre Lokalisierung eines Features ist hinreichend. Es gibt verschiedene Arten des Poolings. Mit Abstand am stärksten verbreitet ist das Max-Pooling, wobei aus jedem 2 × 2 Quadrat aus Neuronen des Convolutional Layers nur die Aktivität des aktivsten (daher \"Max\") Neurons für die weiteren Berechnungsschritte beibehalten wird; die Aktivität der übrigen Neuronen wird verworfen. Trotz der Datenreduktion (im Beispiel 75 %) verringert sich in der Regel die Performance des Netzwerks nicht durch das Pooling. Im Gegenteil, es bietet einige signifikante Vorteile:\n",
        "\n",
        "* Verringerter Platzbedarf und erhöhte Berechnungsgeschwindigkeit\n",
        "* Daraus resultierende Möglichkeit zur Erzeugung tieferer Netzwerke, die komplexere Aufgaben lösen können\n",
        "* Automatisches Wachstum der Größe der rezeptiven Felder in tieferen Convolutional Layers (ohne dass dafür explizit die Größe der Faltungsmatrizen erhöht werden müsste)\n",
        "* Präventionsmaßnahme gegen Overfitting\n",
        "\n",
        "Das nachfolgende Bild zeigt ein Max pooling mit 2x2 Filter und Schrittgrösse = 2. Die Schrittgrösse gibt an, wie viele Pixel der Filter pro Operation verschiebt.\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png' width=450>\n",
        "\n",
        "Wir können bei obigen Beispiel gut erkennen, dass der Filter lediglich die grösste Pixelzahl überträgt. Nachfolgenden eine kurze Animation dieser Operation:\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/1/19/2D_Convolution_Animation.gif'>\n",
        "\n",
        "**Flattening**\n",
        "\n",
        "Ist die Operation, welche durchgeführt werden muss um die Resultate aus dem Conv-Net ins FKNN zu übertragen. Beim Flattening werden die Resultate aus der Pooling Feature Map ins einen 1D-Array übertragen.\n",
        "\n",
        "<img src='https://miro.medium.com/max/758/1*oJSpK_KcHUTIZxniOQ_vOQ.png' width=500>\n",
        "\n",
        "Die genaue Funktionsweise eines CNN kann aus einem sehr empfehlenswerten Medium Artikel von Amir Ali entnommen werden.\n",
        "\n",
        "https://medium.com/machine-learning-researcher/convlutional-neural-network-cnn-2fc4faa7bb63"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "831ESsONXslF"
      },
      "source": [
        "### Funktionsweise eines CNN\n",
        "\n",
        "Um es schon einmal vorweg zu nehmen. Das CNN arbeitet in etwa gleich wie Menschen Bilder wahrnehmen. Schauen wir uns mal folgende Zeichnung an:\n",
        "\n",
        "<img src='https://image.freepik.com/vektoren-kostenlos/pferd-koepfe-konturen_23-2147501777.jpg' width=200>\n",
        "\n",
        "Unser Hirn regestriert auf den ersten Blick, dass es sich dabei um Pferdeköpfe handelt. Obwohl wir nur Striche sehen kann unser Hirn die Konturen sofort zuordnen. Nachchfolgend noch ein weiteres Bild:\n",
        "\n",
        "<img src='https://images.derstandard.at/img/2012/10/22/1350285669783.jpg?w=600&s=b6d88952196b9cc5f92b0c5df03bece9' width=300>\n",
        "\n",
        "Auch wenn wir nur das linke sehr unscharfe Bild betrachten würden, würde unser Hirn sofort ein Gebäude identifizieren. Diese Beispiele zeigen ungefähr wie unser Hirn bei der Erkennung von Bildern vorgeht. Anstelle sich auf Details zu fokussieren beschränkt es sich auf die Wahrnehmung der Konturen. So ähnlich arbeitet der CNN-Algorithmus auch. \n",
        "\n",
        "Eine Maschine betrachtet ein Bild nur mittels Zahlenwerte.\n",
        "\n",
        "\n",
        "Ein wirklich coole Art ein CNN zu verstehen ist mittels des Tools auf der folgenden Seite:\n",
        "\n",
        "https://www.cs.ryerson.ca/~aharley/vis/conv/flat.html\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oKCtgli493R"
      },
      "source": [
        "### Teil 1 - Datenaufbereitung (Data-Preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gdpDGRR-Lst"
      },
      "source": [
        "#### Datenimport"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCYW6BKF-Qv8"
      },
      "source": [
        "import tensorflow as tf\n",
        "# ImageDataGenerator wird für Aufbereitung der Bilder benötigt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mq_D2tra_oJU",
        "scrolled": true,
        "outputId": "0954cf85-d314-49d7-cdde-f123dcbb217d"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVqRBbq7-urJ"
      },
      "source": [
        "#### GPU Support im Tensorflow\n",
        "\n",
        "Wenn man über eine Grafikkarte von NVIDIA verfügt, dann kann diese im Rahmen des Trainings eingesetzt werden. \n",
        "Im nachfolgenden Link sind die erforderlichen Schritte um die GPU für Tensorflow zu nutzen:\n",
        "\n",
        "https://www.tensorflow.org/install/gpu\n",
        "\n",
        "https://www.tensorflow.org/guide/gpu\n",
        "\n",
        "Sehr zu empfehlen ist dieser Link:\n",
        "\n",
        "https://shawnhymel.com/1961/how-to-install-tensorflow-with-gpu-support-on-windows/\n",
        "\n",
        "Hinweis: Auch noch conda install pillow durchführen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQgcyWnL-urJ",
        "outputId": "2066c1d9-ab21-4b4e-9126-56cac4fc4f9f"
      },
      "source": [
        "# Prüfen ob eine GPU verfügbar ist\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4BWNjez__gx"
      },
      "source": [
        "#### Aufbereitung Trainingdatensatz\n",
        "\n",
        "Damit wir ein Overfitting verhindern können, müssen wir die Bilder des Trainingsdatensatzes etwas transformieren. Das Ziel einer solchen Transformation ist es die Bilder etwas zu manipulieren um es dem Algorithmus nicht allzu leicht zu machen. So werden Bilder beispielweise verpixelt, verdreht, verzerrt usw. Diese Transformation wird auch **Image Augmentation** genannt. Eines der besten Tools um eine Image Augmentation durchzuführen ist das Keras Modul **ImageDataGenerator**.\n",
        "\n",
        "Ein guter Überblick über die Image Augmentation mittels ImageDataGenerator (Keras) findet man auf dem Blog [Yumi's](https://fairyonice.github.io/Learn-about-ImageDataGenerator.html).\n",
        "\n",
        "**Wichtig!** Wir führen die Transformierung nur auf den Trainingsdatensatz nicht auf dem Testdatensatz aus. Der Grund dafür ist sehr einfach. Der Testdatensatz repräsentiert die richitge Welt und in der richtigen Welt kommen die Bilder nicht immer im gleichen Format daher.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSGdRJOw-urJ",
        "outputId": "4994ce74-c1ac-44d4-bf42-c70ffb557d13"
      },
      "source": [
        "# Default Laufwerk definieren\n",
        "import os\n",
        "os.chdir('D:\\\\GithubReps\\my_datascience\\\\udemy\\mlaz\\\\Part 8 - Deep Learning\\\\')\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'D:\\\\GithubReps\\\\my_datascience\\\\udemy\\\\mlaz\\\\Part 8 - Deep Learning'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7haMMFk-v7xc",
        "outputId": "c39a8b18-ac30-4c3c-e410-844c902e2d2e"
      },
      "source": [
        "train_datagen = ImageDataGenerator( #Wir erstellen eine Funktion mit IDG\n",
        "        # Die Pixelwerte jedes einzelnen Bilds wird durch 255 geteilt bzw. zwischen 0 und 1 skaliert.\n",
        "        rescale=1./255,  \n",
        "        # Die nachfolgenden Attribute haben mit der Image Augmentation zu tun.\n",
        "        shear_range=0.2, # Verzehrt die Bilder\n",
        "        zoom_range=0.2, # Zoomed in die Bilder\n",
        "        horizontal_flip=True) # Dreht Bilder\n",
        "\n",
        "# Diese Klasse verbindet train_datagen mit dem Datensatz.\n",
        "training_set = train_datagen.flow_from_directory( \n",
        "        'Section 40 - Convolutional Neural Networks (CNN)/Python/dataset/training_set',\n",
        "        target_size=(64, 64), # Grösse der Bilder welche ins CNN gefeedet werden\n",
        "        batch_size=32,\n",
        "        class_mode='binary') # Wir haben nur zwei Werte Dog oder Cat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gz0IuR8AKuZ"
      },
      "source": [
        "#### Aufbereitung Testdatensatz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR58g62-votp",
        "outputId": "75a3a8c1-cd13-4791-ce33-e4344cda3f5f"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        'Section 40 - Convolutional Neural Networks (CNN)/Python/dataset/test_set',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PmR1sBrAQAR"
      },
      "source": [
        "### Teil 2 - Aufbau des CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_SQuvOiAXzV"
      },
      "source": [
        "#### Initialisierung des CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SVvjEpuw_Kz"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZx1moJaAg1h"
      },
      "source": [
        "##### Schritt 1 - Convolution (Falten)\n",
        "\n",
        "Wir bauen in diese Schritt den ersten ConvLayer aus dem gleichen Keras Objekt Layers. Diese Klasse heisst Conv2D und lässt grundsätzlich bereits erwähnen welche Art von Input in diesen CNN verarbeitet werden. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHain8J7xUcS"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(\n",
        "    filters=32, # Output Filters im CNN bzw. Anzhal Feature Detectors\n",
        "    kernel_size=3, # Hier definieren wir die Grösse des Feature Detectors 3x3\n",
        "    activation='relu', # Wie auch bereits im KNN verwenden wir auch hier ReLu\n",
        "    # Input Format wie oben spezifiziert. Da es sich um Farbfotos handelt definieren wir 3 (RGB)\n",
        "    # bei Schwarz-Weiss Fotos wären es 1\n",
        "    input_shape=[64,64,3])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXGTHgQAAvlm"
      },
      "source": [
        "##### Schritt 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlrsLvk1yjKk"
      },
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(\n",
        "    pool_size=2, # Die Pooling Grösse ist 2 x 2\n",
        "    strides=2)) # Hier definieren wir wieviel Slides das Pooling-Frame nach rechts macht."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkjLoIaYAyuq"
      },
      "source": [
        "###### Hinzufügen eines zweiten Conv-Layers\n",
        "\n",
        "Im zweiten Layer definieren wir die gleichen Attribute wie auch schon im Ersten mit Ausnahme mit dem Input-Shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xJdWxCpzhCQ"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R02CHTewBBqi"
      },
      "source": [
        "##### Schritt 3 - Flattening\n",
        "\n",
        "Hier transponieren wird die Resultate aus den Conv- und Polling Schichten in einen 1D Array, damit wir ihn dem NN übergeben können"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt_094D6zw70"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5AgKuBDBJzp"
      },
      "source": [
        "##### Schritt 4 - Full Connection\n",
        "\n",
        "Hier definieren wir das FKNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mba-ZvwO0AsM"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(\n",
        "    units=128, # Da wir eine Input Shape von 64x64 haben nehmen wir 128 \n",
        "    activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VMmHy6ZBS6n"
      },
      "source": [
        "##### Schritt 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8DiQy5Z0uH4"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(\n",
        "    units=1, # In einem Binary Classifier benötigen wir nur ein Output\n",
        "    activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDz5-aUVBaTl"
      },
      "source": [
        "### Teil 3 - Trainieren des CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ_ob8VgBrDl"
      },
      "source": [
        "#### Kompilieren des CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij7cD_-X1eHZ"
      },
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9bh8SbJBzB0"
      },
      "source": [
        "#### Trainieren des CNN und Evaluation mittels Testdatensatzes\n",
        "\n",
        "Im Unterschied zum KNN trainieren wir hier zuerst den Trainingsdatensatz und validieren diesen direkt gegenüber den Testdatensatz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxT9MNUO1xzZ",
        "scrolled": true
      },
      "source": [
        "cnn.fit(\n",
        "    x = training_set, \n",
        "    validation_data=test_set, \n",
        "    epochs = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvKTgCpACR5g"
      },
      "source": [
        "### Teil 4 - Erstellung einer Vorhersage auf Basis einer einzelnen Beobachtung"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmfXWTz22lAd"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "test_image = image.load_img('Section 40 - Convolutional Neural Networks (CNN)/Python/dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64,64))\n",
        "test_image = image.img_to_array(test_image) # Hier wandeln wir das Bild in einen Array um\n",
        "test_image = np.expand_dims(test_image, axis=0) # Wir müssen das Image noch in die richtige Dimension bringen.\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices \n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvrA5-cI6LEk"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvQvBZWMo2g3"
      },
      "source": [
        "## Recurrent Neural Networks (RNN)\n",
        "\n",
        "Quelle: [Wikipedia](https://de.wikipedia.org/wiki/Rekurrentes_neuronales_Netz)\n",
        "\n",
        "Als rekurrente bzw. rückgekoppelte neuronale Netze bezeichnet man neuronale Netze, die sich im Gegensatz zu den Feedforward-Netzen durch Verbindungen von Neuronen einer Schicht zu Neuronen derselben oder einer vorangegangenen Schicht auszeichnen. Im Gehirn ist dies die bevorzugte Verschaltungsweise neuronaler Netze, insbesondere im Neocortex. In künstlichen neuronalen Netzen wird die rekurrente Verschaltung von Modellneuronen benutzt, um zeitlich codierte Informationen in den Daten zu entdecken. Beispiele für solche rekurrenten neuronalen Netze sind das Elman-Netz, das Jordan-Netz, das Hopfield-Netz sowie das vollständig verschaltete neuronale Netz.\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/4/4c/Neuronal-Networks-Feedback.png' width=400>\n",
        "\n",
        "Rekurrente Netze lassen sich folgendermaßen unterteilen:\n",
        "\n",
        "* Bei einer direkten Rückkopplung (englisch direct feedback) wird der eigene Ausgang eines Neurons als weiterer Eingang genutzt.\n",
        "* Die indirekte Rückkopplung (englisch indirect feedback) verbindet den Ausgang eines Neurons mit einem Neuron der vorhergehenden Schichten.\n",
        "* Die seitliche Rückkopplung (englisch lateral feedback) verbindet den Ausgang eines Neurons mit einem anderen Neuron derselben Schicht.\n",
        "* Bei einer vollständigen Verbindung hat jeder Neuronenausgang eine Verbindung zu jedem anderen Neuron\n",
        "\n",
        "### Long Short Term Memory (LSTM) \n",
        "\n",
        "Eine der bekanntesten RNN Architekturen ist das Long Short Term Memory (LSTM) Netzwerk. Hierbei werden zusätzliche Parameter darauf trainiert, den Input und Output des Netzes für die nächste Iteration zu speichern oder zu verwerfen, um auf diese Weise zusätzliche Informationen zur Vorhersage für den nächsten Sequenzabschnitt zur Verfügung zu stellen. So können zuvor aufgetretene Signale über die zeitliche Dimension der Daten gespeichert und später verwendet werden. LSTMs werden aktuell sehr erfolgreich im NLP (Natural Language Processing) angewendet, um Übersetzungen von Texten anzufertigen oder Chat-Bots zu trainieren. Weiterhin eignen sich RNNs für die Modellierung von Sequenzen im Allgemeinen, bspw. bei der Zeitreihenprognose oder aber auch für Next Best Action Empfehlungen.\n",
        "\n",
        "Empfehlenswerte Beiträge zur Vertiefung von LSTM sind auf [Cola's Blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) und [Andrej Karpathy blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) zu finden.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWpOQYXg6Qol"
      },
      "source": [
        "### Teil 1 - Datenaufbereitung (Data-Preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axkozIG67ITT"
      },
      "source": [
        "#### Import der Python Libs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4R7Vq5J7TjT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1y2SWHz73VS"
      },
      "source": [
        "#### Datenimport"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_3YODYU7iTr"
      },
      "source": [
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%201%20-%20Supervised%20Deep%20Learning/Part%203%20-%20Recurrent%20Neural%20Networks/Google_Stock_Price_Train.csv'\n",
        "dataset_train = pd.read_csv (datloc)\n",
        "training_set = dataset_train.iloc[:,1:2].values"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "QwCF5C488M6H",
        "outputId": "686ac389-d2ed-4218-aeb0-512ee2de3405"
      },
      "source": [
        "dataset_train"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/3/2012</td>\n",
              "      <td>325.25</td>\n",
              "      <td>332.83</td>\n",
              "      <td>324.97</td>\n",
              "      <td>663.59</td>\n",
              "      <td>7,380,500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/4/2012</td>\n",
              "      <td>331.27</td>\n",
              "      <td>333.87</td>\n",
              "      <td>329.08</td>\n",
              "      <td>666.45</td>\n",
              "      <td>5,749,400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/5/2012</td>\n",
              "      <td>329.83</td>\n",
              "      <td>330.75</td>\n",
              "      <td>326.89</td>\n",
              "      <td>657.21</td>\n",
              "      <td>6,590,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/6/2012</td>\n",
              "      <td>328.34</td>\n",
              "      <td>328.77</td>\n",
              "      <td>323.68</td>\n",
              "      <td>648.24</td>\n",
              "      <td>5,405,900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/9/2012</td>\n",
              "      <td>322.04</td>\n",
              "      <td>322.29</td>\n",
              "      <td>309.46</td>\n",
              "      <td>620.76</td>\n",
              "      <td>11,688,800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>12/23/2016</td>\n",
              "      <td>790.90</td>\n",
              "      <td>792.74</td>\n",
              "      <td>787.28</td>\n",
              "      <td>789.91</td>\n",
              "      <td>623,400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>12/27/2016</td>\n",
              "      <td>790.68</td>\n",
              "      <td>797.86</td>\n",
              "      <td>787.66</td>\n",
              "      <td>791.55</td>\n",
              "      <td>789,100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>12/28/2016</td>\n",
              "      <td>793.70</td>\n",
              "      <td>794.23</td>\n",
              "      <td>783.20</td>\n",
              "      <td>785.05</td>\n",
              "      <td>1,153,800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>12/29/2016</td>\n",
              "      <td>783.33</td>\n",
              "      <td>785.93</td>\n",
              "      <td>778.92</td>\n",
              "      <td>782.79</td>\n",
              "      <td>744,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>12/30/2016</td>\n",
              "      <td>782.75</td>\n",
              "      <td>782.78</td>\n",
              "      <td>770.41</td>\n",
              "      <td>771.82</td>\n",
              "      <td>1,770,000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1258 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date    Open    High     Low   Close      Volume\n",
              "0       1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
              "1       1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
              "2       1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
              "3       1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
              "4       1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n",
              "...          ...     ...     ...     ...     ...         ...\n",
              "1253  12/23/2016  790.90  792.74  787.28  789.91     623,400\n",
              "1254  12/27/2016  790.68  797.86  787.66  791.55     789,100\n",
              "1255  12/28/2016  793.70  794.23  783.20  785.05   1,153,800\n",
              "1256  12/29/2016  783.33  785.93  778.92  782.79     744,300\n",
              "1257  12/30/2016  782.75  782.78  770.41  771.82   1,770,000\n",
              "\n",
              "[1258 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cohLCZ_49c_h"
      },
      "source": [
        "#### Skaliering der Features\n",
        "\n",
        "Der Datensatz den wir in diesem Beispiel verwenden beinhaltet den Google Aktienkurs von 2012 - 2016 genauer gesagt der jeweilige Kurs bei Eröffnung des Börsentags. Das Feature \"Open\" verfügt über einen minimalen und maximalen Wert. Nun stellt sich die Frage welche Skalierung wir für unser RNN verwendet sollen:\n",
        "\n",
        "**MinMax Scaling**\n",
        "\n",
        "<img src='https://chrisalbon.com/images/machine_learning_flashcards/MinMax_Scaling_print.png' width='500'>\n",
        "\n",
        "Quelle: Chris Albon\n",
        "\n",
        "**Standard Scaling**\n",
        "\n",
        "<img src='https://chrisalbon.com/images/machine_learning_flashcards/Standardization_print.png' width='500'>\n",
        "\n",
        "Quelle: Chris Albon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e4PEYdg9kzN"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sc = MinMaxScaler(feature_range = (0,1)) \n",
        "training_set_scaled = sc.fit_transform(training_set)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2gPT8Ts_78d"
      },
      "source": [
        "# Erstellung einer Datenstruktur mit 60 Zeitschritten und 1 Output\r\n",
        "X_train = []\r\n",
        "y_train = []\r\n",
        "\r\n",
        "# Wir wollen die 60 Aktienkurse der letzen 60 Tag voraussagen, weshalb wir erst bei 60 Anfangen \r\n",
        "for i in range (60, 1258):\r\n",
        "  X_train.append(training_set_scaled[i-60:i, 0])\r\n",
        "  y_train.append(training_set_scaled[i, 0])\r\n",
        "\r\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl_LR8EqCdYF"
      },
      "source": [
        "# RNN erwartet eine 3D Shape der Daten\r\n",
        "# Reshaping die Daten\r\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzS_YSuXH603",
        "outputId": "1399b09b-6f97-4e59-b762-57618f7798c4"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1198, 60, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDE7L3tq6T1O"
      },
      "source": [
        "### Teil 2 - Aufbau des RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax5H8MqyIXAX"
      },
      "source": [
        "# Initialisierung RNN\r\n",
        "regressor = tf.keras.models.Sequential()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4ZhVctiKcWM"
      },
      "source": [
        "# Hinzufügen des ersten LSTM layers mit Dropout regularisation\r\n",
        "regressor.add(tf.keras.layers.LSTM(units = 50, return_sequences=True, input_shape = (X_train.shape[1], 1)))\r\n",
        "regressor.add(tf.keras.layers.Dropout(0.2)) # 20% der Neuronen werden ignoriert"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOec_i7IN426"
      },
      "source": [
        "# Hinzufügen des zweiten LSTM layers mit Dropout regularisation\r\n",
        "regressor.add(tf.keras.layers.LSTM(units = 50, return_sequences=True)) # Wir brauchen hier die Input Form nicht mehr zu definieren.\r\n",
        "regressor.add(tf.keras.layers.Dropout(0.2)) # 20% der Neuronen werden ignoriert"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bl8A8KPO9aG"
      },
      "source": [
        "# Hinzufügen des dritten LSTM layers mit Dropout regularisation\r\n",
        "regressor.add(tf.keras.layers.LSTM(units = 50, return_sequences=True)) # Wir brauchen hier die Input Form nicht mehr zu definieren.\r\n",
        "regressor.add(tf.keras.layers.Dropout(0.2)) # 20% der Neuronen werden ignoriert"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BH-aREGPAoK"
      },
      "source": [
        "# Hinzufügen des vierten LSTM layers mit Dropout regularisation\r\n",
        "regressor.add(tf.keras.layers.LSTM(units = 50)) # Da wir im letzten Layer kein Return der Sequenz mehr machen müssen können wir diese Funtion weglassen.\r\n",
        "regressor.add(tf.keras.layers.Dropout(0.2)) # 20% der Neuronen werden ignoriert"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIwPU0sRPmk-"
      },
      "source": [
        "# Hinzufügen des Output Layers\r\n",
        "regressor.add(tf.keras.layers.Dense(units=1)) # Wir haben nur ein Wert der ausgegeben werden kann deshalb nur ein Unit"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFIo50vLQgnZ"
      },
      "source": [
        "# Kompilierung des RNNs\r\n",
        "regressor.compile(optimizer='adam', loss='mean_squared_error') # Für RNNs kann auch RMSprop verwendet werden"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UBNn1stRzJP"
      },
      "source": [
        "# Fitting RNN zum Trainigssatz\r\n",
        "regressor.fit(X_train,y_train, epochs = 100, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_av3gBbs6hYg"
      },
      "source": [
        "### Teil 3 - Predictions erstellen und Visualisierung der Resultate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xU1UV_UV6hJ"
      },
      "source": [
        "# Download des echten Google Aktienkurses 2017\r\n",
        "\r\n",
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%201%20-%20Supervised%20Deep%20Learning/Part%203%20-%20Recurrent%20Neural%20Networks/Google_Stock_Price_Test.csv'\r\n",
        "dataset_test = pd.read_csv (datloc)\r\n",
        "real_stock_price = dataset_test.iloc[:,1:2].values"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gEL1qIfW3fF"
      },
      "source": [
        "# Getting the predicted stock price of 2017\r\n",
        "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']),axis=0)\r\n",
        "inputs = dataset_total[len(dataset_total)-len(dataset_test)-60:].values\r\n",
        "inputs = inputs.reshape(-1,1)\r\n",
        "inputs = sc.transform(inputs)\r\n",
        "\r\n",
        "# Erstellung einer Datenstruktur mit 60 Zeitschritten und 1 Output\r\n",
        "X_test = []\r\n",
        "\r\n",
        "# Wir wollen die 60 Aktienkurse der letzen 60 Tag voraussagen, weshalb wir erst bei 60 Anfangen \r\n",
        "for i in range (60, 80):\r\n",
        "  X_test.append(inputs[i-60:i, 0])\r\n",
        "\r\n",
        "X_test = np.array(X_test)\r\n",
        "\r\n",
        "# RNN erwartet eine 3D Shape der Daten\r\n",
        "# Reshaping die Daten\r\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\r\n",
        "\r\n",
        "predicted_stock_price = regressor.predict(X_test)\r\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Yjp-dIpx9OiZ",
        "outputId": "9969067c-4ee8-48cd-c11a-2a26ebedfd02"
      },
      "source": [
        "# Visualisieurung der Resultate\r\n",
        "\r\n",
        "plt.plot(real_stock_price, color='red', label = 'Real Google Stock Price')\r\n",
        "plt.plot(predicted_stock_price, color='blue', label = 'Predicted Google Stock Price')\r\n",
        "plt.title('Google Stock Price Prediction')\r\n",
        "plt.xlabel('Time')\r\n",
        "plt.ylabel('Google Stock Price')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}