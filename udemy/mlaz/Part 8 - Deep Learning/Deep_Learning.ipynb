{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyxBmxgRxnMS"
      },
      "source": [
        "# Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OMRqL-5eaqu"
      },
      "source": [
        "## Was ist Deep Learning?###\n",
        "\n",
        "Deep Learning ist ein Teilgebiet des Machine Learning und unterscheidet sich vom „klassischen“ maschinellen Lernen, indem es Maschinen in die Lage versetzt, über die verfügbaren Daten hinaus zu lernen. Das beinhaltet die Fähigkeit, Informationen zu analysieren und zu bewerten, um logische Schlüsse zu ziehen, Lösungswege auszuwählen und aus Fehlern zu lernen. Je mehr Daten eine Maschine also empfängt, desto grösser ist ihre Lernfähigkeit und desto \"intelligenter\" kann sie werden. Obwohl es die künstlichen neuronalen Netze, die die Grundlage dieser Technologien bilden, bereits seit den 1950er Jahren gibt, haben erst die bahnbrechenden Entwicklungen des letzten Jahrzehnts die Lernkurve stark verbessert. Die am meisten verbreiteten modernen Applikationen sind Stimm- und Bilderkennung. Das Niveau der Datenanalyse ermöglicht jedoch viele vorausschauende Applikationen, wie enorme Verbesserungen in der vorausschauenden Wartung, sicherere autonome Fahrzeuge, die Vorhersage von Krankheiten oder Rückfällen. Künstliche neuronale Netzwerke können sowohl für Klassifikation wie auch Regression verwendet werden. \n",
        "\n",
        "Einer der Pioniere in diesem Gebiet ist [Geoffrey Hinton](https://de.wikipedia.org/wiki/Geoffrey_Hinton). Hinton ist ein britischer Informatiker und Kognitionspsychologe der als Professor an der Universität Toronto und bei Google arbeitet. Er hat massgeblich den Begriff Deep Learning kreiert.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzVwJdUyh8zn"
      },
      "source": [
        "## Was sind Künstlich Neuronale Netzwerke (KNN)?\n",
        "\n",
        "Ein künstliches neuronales Netzwerk (KNN), im englischen Artificial neural networks (ANN) genannt,  ist einen Art Abbildung des menschlichen neuronalen Netzwerks. Diese Netzwerk besteht aus vernetzten Neuronen. In einem KNN ist ein Neuron nichts anderes als eine Element welche eine Nummer zwischen 0 - 1, speichert. In einem KNN gibt es drei Arten von Neuronen - Input Neuron, Hidden Neuron und Output Neuron.\n",
        "\n",
        "Beispiel ein Bild mit einer handschriftlichen Zahl 9 besteht aus 28 x 28 Pixel was somit 784 Neuronen darstellt. Jeder dieser Neuronen enthält einen Graustufenwert von 0.01 (Schwarz) zu 1.00 (Weiss). Diese Werte werden „Activation“ genannt. Dies 784 Neuronen stellen die erste Schicht unsere Netzwerks dar. Die letze Schicht wird nur noch aus 10 Neuronen welche die Nummern 0 - 9 darstellen. Die Schichten dazwischen werden „Hidden Layers“ genannt. Sämtliche Neuronen in den verschiedenen Layers sind miteinander verbunden. Die Verbindungen zwischen den Neuronen haben eigene Gewichtungen. Diese Gewichtung wird mit dem Input-Wert multipliziert. Hat also beispielsweise ein Input-Neuron einen Wert von 0,7 und die Gewichtung der Verbindung einen Wert von 2 werden diese zwei Werte multipliziert und ergeben einen Wert von 1.4, welcher an das nächste Neuron weitergegeben werden. Würden wir aber nun immer so rechnen, würde das Resultat immer durch null gehen. Damit wir das verhindern können benutzen wir den Bias. Der Bias ist nichts anderes als der y-Intercept in der linearen Algebra mit dem Unterschied, dass er nur 1 sein kann. Nehmen wir nun also den Bias noch dazu dann bekommen wir folgenden Formel f(x) = mx + b.\n",
        "\n",
        "In einem künstlich neuronalen Netzwerk bestimmen die Aktivitäten in einem Layer die Aktivitäten im nächsten Layer. Die grosse Frage ist dabei WIE Aktivitäten in einem Layer die des nächsten beeinflusst. Grundsätzlich funktioniert es in der gleichen Art wie das biologische Vorbild. Feuert ein Neuron beeinflusst es ein anderes Neuron.\n",
        "\n",
        "Hier eine Abbildung eines typischen KNN:\n",
        "\n",
        "<img src='https://www.researchgate.net/publication/329216193/figure/fig3/AS:697582816870406@1543328112943/Architecture-of-multilayer-artificial-neural-network-with-error-backpropagation.png' width=450>\n",
        "\n",
        "Quelle: [ResearchGate](https://www.researchgate.net/publication/329216193_Predicting_Roof_Pressures_on_a_Low-Rise_Structure_From_Freestream_Turbulence_Using_Artificial_Neural_Networks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLA0iCN7kHVC"
      },
      "source": [
        "### Anatomie eines KNN\n",
        "\n",
        "Nachfolgenden werden wir die verschiedenen Bestandteile (inkl. Math) eines KNN erläutern"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9C6y4I-skn8"
      },
      "source": [
        "#### Künstliches Neuron (Unit)\n",
        "\n",
        "Ein künstliche Neuron stellt ein vereinfachtes Modell eines biologischen Neurons dar.  Ein künstliches Neuron wird auch oft McCulloch-Pittsburgh-Zelle genannt. \n",
        "Bei der Definition des künstlichen Neurons wurden die wesentlichen Eigenschaften eines biologischen Neurons erhalten:\n",
        "\n",
        "Synapsen der Nervenzellen = Addition gewichteter EIngaben\n",
        "Aktivierung Zellkerns = Aktivierungsfunktion mit Schwellwerten\n",
        "\n",
        "Ein künstliches Neuron (j) wird durch folgende Bestandteile beschrieben:\n",
        "\n",
        "1. Wichtung (wij - Die Gewichtung den Einfluss der die Eingabe des Neurons in die Berechnung der Aktivierung einnimmt. D.h. Je höher die Gewichtung desto erregender (exzitatorisch) ist der Input. Je geringer desto hemmender (inhibitorisch) ist die Verbindung zwischen zwei Knoten (0 = nicht existent). \n",
        "2. Übertragungsfunktion - Diese Funktion (∑) berechnet anhand der Wichtung der Eingabe die Netzeingabe des Neurons. Meist ist es die Summe der Eingaben.  Es wird \n",
        "3. Aktivierungsfunktion (ρ) - Diese Funktion bestimmt die Ausgabe des Neurons. Sie wird durch die Netzeingabe und den Schwellwert beeinflusst. -> Siehe Activation Functions\n",
        "4. Schwellwert (θj) - Das Addieren eines Schwellwerts zur Netzeingabe verschiebt die gewichtete Eingabe.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oZb3hJ4YOIv"
      },
      "source": [
        "#### Perzeptron\n",
        "\n",
        "Ausgehen von dieser Idee hat Frank Rosenblatt 1957 das Perzepton entwickelt. Dieses Perzeptron stellt das einfachste KNN dar, da es aus einer Eingabeschicht (Input) und einer Ausgabeschicht (Output) besteht:\n",
        "\n",
        "<img src='https://images.deepai.org/glossary-terms/perceptron-6168423.jpg' width=450>\n",
        "\n",
        "Das Perzeptron besteht aus folgenden Teilen:\n",
        "\n",
        "* **Input-Layer**. Der Input-Layer beinhaltet einerseits die Daten (x) und eine Bias-Unit (1)\n",
        "* **Wichtung (w)**. Die Gewichtung wird pro Verbindung zwischen dem Input und Output dargestellt und beinhaltet irgend einen Wert. \n",
        "* **Output-Layer** Die Ausgabeschicht besteht im wesentlichen aus der **Linear Threshold Unit (LTU)** welche folgende Funktionen beinhaltet: \n",
        "* **Übertragungsfunktion**. Diese Funktion (∑) berechnet die Wichtung mal Input plus Bias:\n",
        " \n",
        " $\\displaystyle \\sum_{i=1}^{n} =  (w_1 * x_1 + w_2 * x_2 + w_n * x_n) + Bias$\n",
        "\n",
        "* **Aktivierungsfunktion (ρ)**. Diese Funktion bestimmt die Ausgabe des Neurons. Sie wird durch die Netzeingabe und den Schwellwert beeinflusst. -> Siehe Activation Functions\n",
        "* **Schwellwert (θj)**. Das Addieren eines Schwellwerts zur Netzeingabe verschiebt die gewichtete Eingabe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL3SY6Urqo9O"
      },
      "source": [
        "#### Input Layer\n",
        "\n",
        "Die Daten werden über den Input Layer in das KNN übergeben. Im ersten Layer finden somit noch keine eigentlichen mathematischen Operationen statt und es gibt dort auch keine eigentlichen Knoten wie es in manchen Darstellungen suggeriert wird. Die Daten werden mittels eines 1D-Arrays in die Input-Schicht "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzCYdyxQ0KHx"
      },
      "source": [
        "#### Aktivierungsfunktion (engl. activation function)\n",
        "\n",
        "Die Aktivierungsfunktion ist der Teil eines künstlichen Neurons, welche die Summe aus der Übertragungsfunktion mittels einer definierten mathematischen Funktion modifiziert. Im wesentlichen geht es bei der AF in einem herkömmlichen neuralen Netzwerk mit Perceptrons Neuronen nur darum zu sagen ob etwas 0 oder 1 ist. Es gibt so gesehen zwei verschiedene AF-Typen Lineare AF und Not-Lineare AF.  Wobei die lineare Aktivierungsfunktion beim Deep Learning so gut wie nicht zur Anwendung kommen. Der Grund dafür ist, dass die reale Welt nicht lineare ist. \n",
        "\n",
        "Bei der nicht-linearen Aktivierungsfunktion unterscheidet man in der Regel zwischen der Derivative - oder Differential- Funktion und der Monotonic- Funktion.\n",
        "\n",
        "Damit eine kleiner Change bei den Gewichtungen (w) und dem Schwellwerten (b=Bias) nicht eine zu starke Auswirkung auf das ganze Neuronale Netzwerk hat, werden Aktivierungsfunktionen verwende, welche Werte zwischen 0 und 1 zu lassen bsp. 0.6669.\n",
        "\n",
        "Meist kommen in eine neuronalen Netzwerk verschiedene AFs vor. So wird beispielsweise bei den Hidden Layers de ReLU und bei den Output Layer Sigmoid verwendet.\n",
        "\n",
        "Die bekanntesten solcher in einem KNN verwendeten Aktivierungsfunktionen sind:\n",
        "\n",
        "* **Threshold - f(x)=(1 if x >= 0)(0 if x < 0)**\n",
        "\n",
        "  Hierbei handelt es sich um die einfachste Aktivierungsfunktion, weil sie lediglich prüft, ob ein Wert grösser oder kleinen als 0 ist. Diese Fuktion wird dann verwendet, wenn der Input binär ist also nur 0 oder 1 annehmen kann.\n",
        "\n",
        "* **Sigmoid - f(x) = 1 / (1 + exp(-x))**\n",
        "\n",
        "  Mit der Sigmoid-Funktion wird eine für diese Funktion typische S-Grafik erstellt. Dabei wird nicht nur der ein eindeutiger Wert (Bsp. 0 oder 1) ermittelt, sondern auch wie wahrscheinlich es ist den Wert 0 oder 1 zu erreichen. Diese Funktion ist somit Ideal, wenn es sich um binäre Werte handelt. Da diese Funktionen ihr Limiten hat bzw für das Deep Learning etwas zu langsam ist, wurden die folgenden Alternativen eingesetzt.\n",
        "\n",
        "* **Hyperbolic Tangent (tanh) - f(x) = sinh(x) / cosh(x)**\n",
        "\n",
        "  Die tanh-Funktion ist eine direkte alternative zu Sigmoid bzw. arbeitet ebenfalls mit der S-Grafik. Der wesentliche Unterschied ist, dass tanh Über einen Zahlenbereich von -1 bis 1 verfügt. \n",
        "\n",
        "  Die non-lineare AF Sigmoid und Hyperbolic Tangent werden bei Feed-forward KNNs eingesetzt. \n",
        "\n",
        "* **Rectified Linear Unit (ReLU) - f(x) = max(0,x)**\n",
        "Diese Funktion gehört zu den am meisten angewendeten Aktivierungsfunktionen in einem KNN bzw. Deep Learning. Sie ersetzte die Sigmoid-Funktionen am besten. Bei der ReLU werden sämtliche Werte welche negativ sind nur als 0 bezeichnet und die Werte welche postiv sind werden als diese übernohmen.\n",
        "\n",
        "Nachfolgend alle bekanntesten Aktivierungsfunktionen auf einen Blick:\n",
        "\n",
        "<img src='https://miro.medium.com/max/875/1*ZafDv3VUm60Eh10OeJu1vw.png' width=600>\n",
        "\n",
        "Quelle: [Medium.com](https://medium.com/@shrutijadon10104776/survey-on-activation-functions-for-deep-learning-9689331ba092)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvaSu_Ivf9bf"
      },
      "source": [
        "## Wie lernt eine KNN?\n",
        "Im einem KNN gibt es zwei Hauptmechanismen das **Forward Propagation** (auch Feedforward genannt) und **Back Propagation**.\n",
        "\n",
        "### Forward Propagation (Feedforward)\n",
        "\n",
        "Beim FP werden die einzelnen Datenwerte ($x_1, x_2, x_3$ usw.) mit einer gewichteten Verbindung ($w_1,w_2;w_3$ usw.) je einzel multipliziert und miteinander mittels Addition aufsummiert. Dieser Summe wird noch ein Bias hinzuaddiert. Das daraus entstandene Resultat wird dann in die Aktivierungsfunktion überträgen welche darüber entscheidet ob das Neuron sich aktiviert bzw. essentiell für die weitere Verarbeitung ist oder nicht. Dieser Prozess wiederholt sich jenachdem wieviele Hidden layers verwendet werden. Am Ende werden die Resultate in den Output Layer überführt und mittels der Cost Function gegenüber dem korrekten Resultat verglichen.  \n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/KNN_Cost_function_1.png?raw=true' width=600>\n",
        "\n",
        "### Backward Propagation (Backpropagation)\n",
        "\n",
        "Backpropagation ist nichts anderes als der Prozess in welchem die Gewichtungen der einzelnen Verbindungen angepasst werden bzw. das KNN optimiert wird. In der Optimierung geht es im Grundsatz darum die Cost function bzw. die Fehler zu minimieren. Dieser Prozess wird auch **Gradient descent** genannt.\n",
        "\n",
        "In der folgenden Grafik sehen wir unten rechts die sogenannte **Cost function (C)**. Die Cost function zeigt uns nichts anderes als die Differenz zwischen dem Output-Werten und den korrekten Werten. Diese Differenz wird als Fehler (Error) bezeichnet. Auf Basis des Resultats (Error) fängt das KNN seine gewichteten Verbindungen zu aktualisieren d.h. das KNN fängt sich an zu optimieren.\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/KNN_Cost_function_2.png?raw=true' width=600>\n",
        "\n",
        "Die in der obigen Grafik dargestellen Input Values sind die von lediglicher einer Zeile eines Datensatzes d.h jedes Feature (unabhängige Variable) stellt einen Input dar. Ein Datensatz mit 15 Merkmalen (Features) würde also 15 Input values bedeutet. \n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/KNN_Cost_function_3.png?raw=true' width=600>\n",
        "\n",
        "#### Gradient Descent\n",
        "\n",
        "Der Gradient Descent (Gradientverfahren) stellt einer der elementarsten Bestandteile eines KNNs dar. Aus diesem Grund wollen wir uns dieses Verfahren mal etwas genauer ansehen.\n",
        "\n",
        "Quelle: [Wikipedia](https://de.wikipedia.org/wiki/Gradientenverfahren)\n",
        "\n",
        "Das Gradientenverfahren wird in der Numerik eingesetzt, um allgemeine Optimierungsprobleme zu lösen. Dabei schreitet man (am Beispiel eines Minimierungsproblems) von einem Startpunkt aus entlang einer Abstiegsrichtung, bis keine numerische Verbesserung mehr erzielt wird. Wählt man als Abstiegsrichtung den negativen Gradienten, also die Richtung des lokal steilsten Abstiegs, erhält man das Verfahren des steilsten Abstiegs. Manchmal werden die Begriffe Gradientenverfahren und Verfahren des steilsten Abstiegs synonym verwendet. Im Allgemeinen bezeichnet Gradientenverfahren eine Optimierungsmethode, bei der die Abstiegsrichtung durch Gradienteninformation gewonnen wird, also nicht notwendigerweise auf den negativen Gradienten beschränkt ist.\n",
        "\n",
        "Das Verfahren des steilsten Abstiegs konvergiert oftmals sehr langsam, da es sich dem stationären Punkt mit einem starken Zickzack-Kurs nähert. Andere Verfahren für die Berechnung der Abstiegsrichtung erreichen teils deutlich bessere Konvergenzgeschwindigkeiten, so bietet sich für die Lösung von symmetrisch positiv definiten linearen Gleichungssystemen beispielsweise das Verfahren der konjugierten Gradienten an. Der Gradientenabstieg ist mit dem Bergsteigeralgorithmus (hill climbing) verwandt.\n",
        "\n",
        "In einer 2D grafischen Darstellung sieht Gradient Descent wie folgt aus:\n",
        "\n",
        "<img src='https://cdn-images-1.medium.com/max/600/1*iNPHcCxIvcm7RwkRaMTx1g.jpeg' width=500>\n",
        "\n",
        "Quelle: [MC.AI](https://mc.ai/an-introduction-to-gradient-descent-2/)\n",
        "\n",
        "Und in 3D so:\n",
        "\n",
        "<img src='https://miro.medium.com/max/875/1*yasmQ5kvlmbYMe8eDkyl6w.png' width=500>\n",
        "\n",
        "Quelle: [Medium.com](https://medium.com/@DBCerigoon-why-gradient-descent-is-even-needed-25160197a635)\n",
        "\n",
        "##### **Batch Gradient Descent (BGD)**\n",
        "\n",
        "Ist ein Gradientverfahren in welchem die ganzen Daten in einem grossen oder mehreren kleinen Batches (Einheiten) in das KNN eingespiesen werden. \n",
        "\n",
        "##### **Stochastic Gradient Descent (SGD)**\n",
        "\n",
        "In der vorletzten Grafik sehen wir wie Gradient Descent in einer gleichmässig nach aussen gebeugte Kurve (auch Convex genannt) aussieht. Nun ist aber so, dass in der realen Welt eine solche Gleichmässigkeit eher selten ist. In Wahrheit haben wir es mit unterschiedlichen Kurven mit mehreren tiefen Stellen zu tun. Damit die Funktion nun nicht einfach das Beste lokale Minimum sondern das globale Minimum (Best) der Cost funkton findet, ist ein stochastischer Ansatz notwendig. \n",
        "\n",
        "<img src='https://www.mltut.com/wp-content/uploads/2020/04/Untitled-document-3.png' width=550>\n",
        "\n",
        "Quelle: [MLTUT](https://www.mltut.com/stochastic-gradient-descent-a-super-easy-complete-guide/)\n",
        "\n",
        "##### **Batch vs. Stochastic Gradient Descent**\n",
        "\n",
        "SGD hat gegenüber dem BGD Verfahren mehrere Vorteile. Nicht nur das SGD mit nicht konvexen Funktionen umgehen kann bzw. das lokale Minimum Problem verhindert. Es ist auch noch schneller als das BGD Verfahren. Was in Anbetracht der zeilenweisen Einfütterung in ein KNN erstaunen mag aber so ist es :-).\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/KNN_Diff_Gradient_Descent.png?raw=true' width=600>\n",
        "\n",
        "Mehr zum Thema Gradient Descent ist unter diesem [Link](https://iamtrask.github.io/2015/07/27/python-network-part2/) oder diesem [Link](https://www.mltut.com/stochastic-gradient-descent-a-super-easy-complete-guide/) zu finden.\n",
        "\n",
        "Abschliessen noch ein kurzer Ablauf, wie eine KNN mit SGD trainiert wird:\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/Section%2039%20-%20Artificial%20Neural%20Networks%20(ANN)/Stochastic_Gradient_Descent.png?raw=true' width=600>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR8AqwrmRl_2"
      },
      "source": [
        "## Fully Connected Neural Network (FCNN)\n",
        "\n",
        "Eines der klassischen KNNs ist das Fully Connected Neural Network. Es wird so genannt, weil alle Units miteinander verbunden sind. Damit sind wir auch schon beim Haupproblem dieser Art KNNs angekommen. Fully Connected hat einen Einfluss auf die Performance.\n",
        "\n",
        "<img src='https://cdn-images-1.medium.com/max/720/1*VHOUViL8dHGfvxCsswPv-Q.png' width=500>\n",
        "\n",
        "Im nachfolgende Beispiel bauen wir ein solches KNN um ein Regressionsproblem zu lösen. Für den Aufbau verwenden wird das Framework Tensorflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o58FN6eCyTBN"
      },
      "source": [
        "### Ausgangslage\n",
        "\n",
        "Eine Bank verliert innerhalb kurzer Zeit sehr viele Kunden. Sie möchte nun gerne Wissen, welche der noch bestehenden Kunden evtl. die Bank in den nächsten 6 Monaten verlassen könnten. Für die Erstellung eins KNN-Regressionsmodells stellt sie einen Datensatz von 10000 Kunden zur Verfügung, welche noch bei der Bank sind oder diese bereits verlassen haben. Neben 13 Features (unabhängige Variablen) beinhaltet der Datensatz auch eine Spalte mit Labels (abhängige Variable).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7wEUUJrw0s_"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aMy3FaVWJJc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrPhog7uxHYL"
      },
      "source": [
        "### Teil 1 - Datenaufbereitung (Data Preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pRyhRL_1tzr"
      },
      "source": [
        "#### Datenimport"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INjwpXRYxOV9"
      },
      "source": [
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/Section%2039%20-%20Artificial%20Neural%20Networks%20(ANN)/Python/Churn_Modelling.csv'\n",
        "\n",
        "dataset = pd.read_csv(datloc)\n",
        "\n",
        "X = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SMH8PB62SKw",
        "outputId": "23222c7b-1b4d-4380-c32c-df88de05449a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "dataset.head()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2KjKpVX16O0"
      },
      "source": [
        "#### Encoding von kategorischen Daten\n",
        "\n",
        "Wie wir im Datensatz unschwer erkennen können, beinhaltet diese auch kategorische Daten wie Surname (Nachname), Geography (Land) und Gender (Geschlecht). Mit diesen kann eine KNN nichts anfangen. \n",
        "Da wir den Nachnamen für unser Modell nicht benötigen können wir uns auf die Features Geography und Gender fokussieren. Während Geography mehrer unterschiedliche Werte enthält sind beim Feature Gender nur zwei Zustände zu beaobachten Female oder Male. Auf Basis dieser Erkenntnisse setzen wir nun folgende Encoding ein:\n",
        "\n",
        "Geography = One Hot Encoding\n",
        "\n",
        "Gender = Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_c5bgQ615eY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6ms3BrOxbBo",
        "outputId": "91ffbe2c-a5a7-4d36-ddaa-a13356f19e20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlH9JEV11EUx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}