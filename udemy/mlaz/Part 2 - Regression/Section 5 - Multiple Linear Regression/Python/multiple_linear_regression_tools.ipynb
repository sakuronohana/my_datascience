{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiple Linear Regression",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%202%20-%20Regression/Section%205%20-%20Multiple%20Linear%20Regression/Python/multiple_linear_regression_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CazISR8X_HUG",
        "colab_type": "text"
      },
      "source": [
        "# Multiple Linear Regression\n",
        "\n",
        "Da Datensätze meist über mehrere Features verfügen macht eine Multiple Linear Regression am meisten Sinn. Grundsätzlich unterscheidet sich die Formel zur Simple Linear Regression nur dadurch, dass sie über mehrere Koeffizienten und unabhängige Variablen verfügt.\n",
        "\n",
        "$y = b_0 + b_1x_1+b_2x_2+ ... + b_nx_n$\n",
        "\n",
        "Wichtig dabei ist. Jede unhängige Variable ($x_1...x_n$) stellt ein Feature (Spalte) dar. Bspw. Ausgaben Administration, Ausgaben Marketing usw. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOyqYHTk_Q57",
        "colab_type": "text"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaBjNZRCqTMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgC61-ah_WIz",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqO28znIyCLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "daturl = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%202%20-%20Regression/Section%205%20-%20Multiple%20Linear%20Regression/Python/50_Startups.csv'\n",
        "dataset = pd.read_csv(daturl)\n",
        "\n",
        "X = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4-j_L6i3DkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VadrvE7s_lS9",
        "colab_type": "text"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLffVB4NypgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[3])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCfE8Vul1ppF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "outputId": "3da1ffae-2977-4223-c1e5-41b065e2b6dd"
      },
      "source": [
        "print (X)\n",
        "print ('Wie wir oben sehen können, wurden die kodierten kategorischen Werte an den Anfang des Datensatzes gestellt')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n",
            " [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n",
            " [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n",
            " [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n",
            " [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n",
            " [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n",
            " [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n",
            " [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n",
            " [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n",
            " [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n",
            " [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n",
            " [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n",
            " [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n",
            " [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n",
            " [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n",
            " [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n",
            " [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n",
            " [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n",
            " [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n",
            " [0.0 0.0 1.0 86419.7 153514.11 0.0]\n",
            " [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n",
            " [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n",
            " [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n",
            " [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n",
            " [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n",
            " [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n",
            " [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n",
            " [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n",
            " [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n",
            " [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n",
            " [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n",
            " [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n",
            " [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n",
            " [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n",
            " [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n",
            " [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n",
            " [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n",
            " [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n",
            " [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n",
            " [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n",
            " [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n",
            " [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n",
            " [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n",
            " [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n",
            " [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n",
            " [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n",
            " [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n",
            " [1.0 0.0 0.0 0.0 135426.92 0.0]\n",
            " [0.0 0.0 1.0 542.05 51743.15 0.0]\n",
            " [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n",
            "Wie wir oben sehen können, wurden die kodierten kategorischen Werte an den Anfang des Datensatzes gestellt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFUgWsuL4sl_",
        "colab_type": "text"
      },
      "source": [
        "## Features Scaling\n",
        "\n",
        "An dieser Stelle stellt sich nun die Frage, ob wir die nummerischen Features skalieren müssen oder nicht.\n",
        "\n",
        "Die Antwort ist ... **Nein** müssen wir nicht. \n",
        "\n",
        "Der Grund dafür ist, dass in der multiplen Linearen Regression alle unabhängigen Variablen ($x_1 ... x_n$) mit dem gleichen Koeffizienten ($b_1 ... b_n$) multipliziert werden und dieser, ungeachtet der Grösse des Wertes der unabhängigen Variablen, die Unterschiede kompensiert und jeden Wert gleich skaliert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WemVnqgeA70k",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wDtwK2K2ByF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMY-emUXD0jo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b7389c5-8c50-431f-dbbe-4a7a9bb16d46"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-McZVsQBINc",
        "colab_type": "text"
      },
      "source": [
        "## Training the Multiple Linear Regression model on the Training set\n",
        "\n",
        "An dieser Stelle gibt es noch etwas ganz wichtige zu sagen. \n",
        "Bei der Konzeption von Modellen wird oft erwähnt, dass beim Feature Engineering zuerst die Features mit der grössten statischen Signifikats ($p$) selektioniert werden müssen, bevor ein Modell erstellt werden kann.\n",
        "\n",
        "Das stimmt so nicht immmer, da die meisten ML Tools wie Scikit automatisch die signifikatesten Features auswählen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huRS1E3e3laq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "220ecd5a-dadd-40f3-c485-70c18f83bb11"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train,y_train)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNkXL1YQBiBT",
        "colab_type": "text"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHO_F16bCQbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "61783696-59b7-4380-97d6-9afe9fa07419"
      },
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Da wir relative viele Stellen nach dem Komma haben, wollen wir diese nachfolgend auf zwei Stellen einschränken.\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "'''Mit den folgenden Codezeilen werden die Resultate aus dem y_pred und die Values aus den y_test\n",
        "verkettet (Concanated) und horizontal für den Vergleich dargestellt '''\n",
        "\n",
        "print('Links ist jeweils das Resultat der Prediction und rechts die Werte der Y-Testdaten. Die meisten Resultate sind verhältnismässig Nahe bei einander, was eine gute Accuracy des Modells aufzeigt')\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Links ist jeweils das Resultat der Prediction und rechts die Werte der Y-Testdaten. Die meisten Resultate sind verhältnismässig Nahe bei einander, was eine gute Accuracy des Modells aufzeigt\n",
            "[[103015.2  103282.38]\n",
            " [132582.28 144259.4 ]\n",
            " [132447.74 146121.95]\n",
            " [ 71976.1   77798.83]\n",
            " [178537.48 191050.39]\n",
            " [116161.24 105008.31]\n",
            " [ 67851.69  81229.06]\n",
            " [ 98791.73  97483.56]\n",
            " [113969.44 110352.25]\n",
            " [167921.07 166187.94]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lGAC2FWCsJH",
        "colab_type": "text"
      },
      "source": [
        "## Visualising the Training set result\n",
        "\n",
        "Wir können uns an dieser Stelle noch daran erinnern, wie wir die Trainingsresultate der einfachen linearen Regression visualisiert haben. Leider funktioniert diese Methode hier nicht, da wir mehrer Features haben und diesbezüglich einen fünf dimensionalen Graphen erstellen müssten (schon 3D ist eine Herausforderung ;-))."
      ]
    }
  ]
}