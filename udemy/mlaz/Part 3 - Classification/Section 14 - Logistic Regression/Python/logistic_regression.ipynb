{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%203%20-%20Classification/Section%2014%20-%20Logistic%20Regression/Python/logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MRC0e0KhQ0S",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "Wenn wir von Logistic Regression im Zusammenhang mit Klassifikation reden, dann ist diese kein versehen. LogReg gehört wirklich zu den Klassifikationsalgorithmen (siehe auch [Link](https://kambria.io/blog/logistic-regression-for-machine-learning/#:~:text=Logistic%20regression%20is%20a%20classification,either%20a%200%20or%201.))\n",
        "\n",
        "Dieser Algorithmus wird vor allem dann verwendet, wenn die verwendeten Daten zwei sogenannte binäre Werte 0 oder 1 annehmen können. Die folgenden Beispiele verdeutlichen das Spektrum möglicher Anwendungen der logistischen Regression:\n",
        "\n",
        "* Conversion-Prognose: Kauft ein Kunde ein Produkt?\n",
        "* Bonität: Zahlt ein Kreditnehmer einen Kredit vollständig zurück?\n",
        "* Markenbekanntheit: Kennt jemand eine Marke?\n",
        "* Parteipräferenz: Würde eine Person Partei X wählen, wenn am kommenden Sonntag * Bundestagswahlen wären?\n",
        "* Medizinische Diagnose: Hat eine Person eine bestimmte Krankheit?\n",
        "* Qualitätskontrolle: Entspricht ein Produkt der Spezifikation?\n",
        "* Einschaltquoten: Hat eine Person eine TV-Sendung gesehen?\n",
        "* A/B-Testing: Ist Version A einer Webseite besser als eine Version B?\n",
        "\n",
        "Quelle: [INWT Statistics](https://www.inwt-statistics.de/blog-artikel-lesen/Logistische_Regression.html)\n",
        "\n",
        "Nachfolgend ein Vergleich zwischen der Linear Regression und der Logistic Regression.\n",
        "\n",
        "<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/linear-regression-vs-logistic-regression.png\">\n",
        "\n",
        "Quelle: static.javatpoint.com\n",
        "\n",
        "Im Prinzip geht es darum die Wahrscheinlichkeit (Prediction) zu ermitteln wann etwas Wahr oder Falsch ist. Je höher die Wahrscheinlichkeit desto höher besteht die Möglichkeit, dass etwas eintrifft.\n",
        "\n",
        "<img src=\"https://github.com/sakuronohana/my_datascience/blob/master/doc_images/log_reg_pic1.jpg?raw=true\" width=\"600\">\n",
        "\n",
        "Dabei wird ein Schwellwert von 0.5 definiert, dass ein Zustand eintritt.\n",
        "\n",
        "<img src=\"https://github.com/sakuronohana/my_datascience/blob/master/doc_images/log_reg_pic2.jpg?raw=true\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWd1UlMnhT2s",
        "colab_type": "text"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZAB5PCqj0il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1VMqkGvhc3-",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibz_l9IQkSKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "daturl = \"https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%203%20-%20Classification/Section%2014%20-%20Logistic%20Regression/Python/Social_Network_Ads.csv\"\n",
        "dataset = pd.read_csv(daturl)\n",
        "\n",
        "X = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvxIPVyMhmKp",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i722O-KlRc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.25, random_state=0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW3c7UYih0hT",
        "colab_type": "text"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzemLR4npfOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb6jCOCQiAmP",
        "colab_type": "text"
      },
      "source": [
        "## Training the Logistic Regression model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrrkNzaluTEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6cc786ad-2a93-4b5d-bf11-d46ab9d67a83"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(X_train,y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gF8Wljqvi2h",
        "colab_type": "text"
      },
      "source": [
        "# Predicting a new result\n",
        "\n",
        "Wichtig! Da wir die Daten skaliert haben, müssen wir dies für die Werte, welche wir in der nachfolgenden Prediction verwenden, auch machen. Hierfür verwenden wir ganz einfach den bereits gefitten Scaler **sc** und führen ganz einfachh einen Transform durch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D9aTDPYfF3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0227bc83-48cc-489a-f9b8-024d8bce1738"
      },
      "source": [
        "print(classifier.predict(sc.transform([[30,87000]])))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uO1bnqQvoKd",
        "colab_type": "text"
      },
      "source": [
        "# Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoXDIAuKoTFh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d40db40-6f6c-4bd1-db10-f1faae1b7dc9"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print (np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4Hwj34ziWQW",
        "colab_type": "text"
      },
      "source": [
        "# Making the Confusion Matrix\n",
        "\n",
        "Während wir die Performance oder auch Robustheit eines Regresssionsmodells mittels $R^2$ (R squared) prüfen tuen wir das bei eine Klassifikators bspw. mittels der Confusion Matrix.\n",
        "\n",
        "<img src=\"https://3.bp.blogspot.com/--jLXutUe5Ss/VvPIO6ZH2tI/AAAAAAAACkU/pvVL4L-a70gnFEURcfBbL_R-GnhBR6f1Q/s1600/ConfusionMatrix.png\" width=\"600\">\n",
        "\n",
        "Quelle: https://scaryscientist.blogspot.com/\n",
        "\n",
        "* Genauigkeit (**Accuracy**) misst die Gesamtgenauigkeit der Modellklassifizierung\n",
        "* Präzisionsmessgenauigkeit (**Precision**) einer Klasse, wenn \"Ja\" vorhergesagt wird, wie oft sie korrekt ist. Zum Beispiel in einem Kredit-Scoring, Klasse 1 (Gut) erhalten Kreditfazilität, Präzisionsmessgenauigkeit der Klasse-1-Zuordnung unter Verwendung des Vorhersagemodus. % der vorhergesagten 1's, die tatsächlich 1's sind (basierend auf der beobachteten Klasse).\n",
        "* Empfindlichkeit (**Sensitivity**) oder Rückruf: Wenn es tatsächlich \"Ja\" ist, wie oft es \"Ja\" vorhersagt. Von der beobachteten Klasse 1 wird durch ein Maß, das Sensitivität genannt wird, gemessen, wie viel Prozent der Fälle tatsächlich durch das Modell in die vorhergesagte Klasse 1 eingestuft werden. \n",
        "* Spezifität (**Specificity**): Die Spezifizität misst die tatsächliche negative Rate. Wenn sie tatsächlich \"Nein\" ist, wie oft ist sie \"Nein\".\n",
        "\n",
        "Es gibt natürlich noch weitere Metriken, welche man zur Messung eines Klassifikators verwenden können. (siehe [Link](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics))\n",
        "\n",
        "Nachfolgend erstellen wir mit Hilfe von Scikit-learn eine Confusion Matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exypbG63w1I1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c41f99fa-d71a-4e53-fa5b-c407afc69909"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "print ('true neg =',tn)\n",
        "print('false pos =',fp)\n",
        "print('false neg =',fn)\n",
        "print ('true pos =',tp)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[65  3]\n",
            " [ 8 24]]\n",
            "true neg = 65\n",
            "false pos = 3\n",
            "false neg = 8\n",
            "true pos = 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1Ca2pcP3vlN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8b9e9eb2-94d4-4c99-9800-20e9c7265370"
      },
      "source": [
        "print('Berechnung mittels der Scikit-learn Metric-Fuction Accuracy_score')\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "\n",
        "print('Wir können die Accurancy auch mittels der Formel (tn+tp)/(tn+fp+fn+tp) berechnen')\n",
        "(tn+tp)/(tn+fp+fn+tp)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Berechnung mittels der Scikit-learn Metric-Fuction Accuracy_score\n",
            "0.89\n",
            "Wir können die Accurancy auch mittels der Formel (tn+tp)/(tn+fp+fn+tp) berechnen\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.89"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksDKGoPoi-rl",
        "colab_type": "text"
      },
      "source": [
        "# Computing the accuracy with k-Fold Cross Validation\n",
        "\n",
        "Eine andere Methode die Accuracy eines Modells zu beurteilen ist die k-Fold Kreuzvalidierung.\n",
        "\n",
        "Bei K-fold Cross Validation wird ein bestimmter Datensatz in eine K-Anzahl von Abschnitten / Falten (Eng. Fold) aufgeteilt, wobei jede Falte irgendwann als Testsatz verwendet wird. Nehmen wir das Szenario der 5-fachen Kreuzvalidierung (K = 5). Hier wird der Datensatz in 5 Falten aufgeteilt. In der ersten Iteration wird die erste Falte zum Testen des Modells verwendet und der Rest wird zum Trainieren des Modells verwendet. In der zweiten Iteration wird die zweite Falte als Testsatz verwendet, während der Rest als Trainingssatz dient. Dieser Vorgang wird wiederholt, bis jede Falte der 5 Falten als Testsatz verwendet wurde.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/2000/1*IjKy-Zc9zVOHFzMw2GXaQw.png\">\n",
        "\n",
        "Quelle: [medium.com](https://medium.com/datadriveninvestor/k-fold-cross-validation-6b8518070833)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFQxH6OhkLfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b6b1cd8f-104d-44ea-b887-8f590f9ea4ef"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracy = cross_val_score(estimator=classifier, X = X_train, y=y_train, cv=10)\n",
        "print('Accuracy: {:.2f}%'.format(accuracy.mean()*100))\n",
        "print('Standard Deviation: {:.2f}%'.format(accuracy.std()*100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 82.33%\n",
            "Standard Deviation: 9.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz-j3NNwmujs",
        "colab_type": "text"
      },
      "source": [
        "Wir sehen ob, dass wir mittels der Logistischen Regression ein akzeptables Resultat bekommen haben."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUDNAWSlvur3",
        "colab_type": "text"
      },
      "source": [
        "# Visualising the Training set results\n",
        "\n",
        "Die nachfolgende Visiualisierung zeigt so gesehen, wie logistic regression arbeitet. \n",
        "\n",
        "Hinweis: Solche Plots werden eher selten verwendet, da man im wahren Data Science Leben oft Datensätze mit mehreren Features antrifft."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTxDsh4p8YjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "X_set, y_set = sc.inverse_transform(X_train), y_train\n",
        "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),\n",
        "                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\n",
        "plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n",
        "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "for i, j in enumerate(np.unique(y_set)):\n",
        "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\n",
        "plt.title('Logistic Regression (Training set)')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Estimated Salary')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4zcnr8HaeDG",
        "colab_type": "text"
      },
      "source": [
        "**Kurzerklärung Plot:**\n",
        "\n",
        "Der Plot mit den Trainings- (oben) und Testresultaten (unten) zeigt zwei wesentliche Bereiche:\n",
        "* Rot = keine potenziellen Kunden\n",
        "* Grün = potenzielle Kunden\n",
        "\n",
        "Was wir in den Plots gut sehen können ist, wo der LogReg-Classifier die Grenzen zwischen dem 0-Bereich und 1-Bereich zieht und zwar zwischen 30 und 50 Jahre. Der Grund dafür, dass die Kunden welche in der Vergangenheit einen SUV gekauft haben meist über 50 Jahre alt waren oder über ein hohes Jahresgehalt verfügen. Die meisten Kunden welche über einen Jahresgehalt < 100'000 verfügen kauften in der Vergangenheit eher keinen SUV. \n",
        "Der Plot verdeutlicht neben bei auch, dass mit zunehmenden Alter das Jahresgehalt im Normalfall steigt. \n",
        "\n",
        "Das die Linie gerade ist, kommt davon, dass es sich bei LogReg um einen liniearen Algorithmus handelt. Viele Classifier arbeiten mit nicht linearen Berechnungen bzw. die Line bildet dan eine Kurve.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LegLnDxv2oQ",
        "colab_type": "text"
      },
      "source": [
        "# Visualising the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1liiDkMcZJfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "X_set, y_set = sc.inverse_transform(X_test), y_test\n",
        "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),\n",
        "                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\n",
        "plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n",
        "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "for i, j in enumerate(np.unique(y_set)):\n",
        "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\n",
        "plt.title('Logistic Regression (Test set)')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Estimated Salary')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}