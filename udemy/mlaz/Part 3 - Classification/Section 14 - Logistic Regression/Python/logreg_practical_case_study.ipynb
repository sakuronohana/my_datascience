{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logreg_practical_case_study.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPn6ONNlg9zNSqPQuJAiAXR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%203%20-%20Classification/Section%2014%20-%20Logistic%20Regression/Python/logreg_practical_case_study.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqcpldFTA5qH",
        "colab_type": "text"
      },
      "source": [
        "# Praktisches Fallbeispiel - Logistic regression\n",
        "\n",
        "Im nachfolgenden Tutorial werden wir ein ML-Modell mittels der logistischen Regression aufbauen. Das das Ziel unsereres ML-Modells wird es sein, auf Basis eines Brustkrebsdatensatzen der Universität Wisconsin herauszufinden ob die Wahrscheinlichkeit für Brustkrebs besteht oder nicht.\n",
        "\n",
        "Hierfür verwenden wir einen Datensatz der auf dem bekannten [ML-Repository UCI](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29) abgelegt ist. Der Datensatz kommt aus dem 1992 ist aber für unsere Zwecke dennoch gut geeignet. Die Beschreibung des Datensatzes ist [hier](https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%203%20-%20Classification/Section%2014%20-%20Logistic%20Regression/Python/breast-cancer-wisconsin.txt) zu finden. Nachfolgend die wichtigsten Informationen über dem Datensatz.\n",
        "\n",
        "* Datensatzmerkmale:  Multivariate\n",
        "* Anzahl der Instanzen: 699\n",
        "* Attributmerkmale: Ganze Zahl\n",
        "* Anzahl der Attribute: 10 (unabhängige Variablen)\n",
        "* Fehlende Werte?: Ja (16 fehlende Werte)\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "1. Sample code number: id number\n",
        "2. Clump Thickness: 1 - 10\n",
        "3. Uniformity of Cell Size: 1 - 10\n",
        "4. Uniformity of Cell Shape: 1 - 10\n",
        "5. Marginal Adhesion: 1 - 10\n",
        "6. Single Epithelial Cell Size: 1 - 10\n",
        "7. Bare Nuclei: 1 - 10\n",
        "8. Bland Chromatin: 1 - 10\n",
        "9. Normal Nucleoli: 1 - 10\n",
        "10. Mitoses: 1 - 10\n",
        "11. Class: (2 for benign (dt. gutartig), 4 for malignant (dt. bösartig))\n",
        "\n",
        "### Beobachtungen aus Datensatzbeschreibung\n",
        "1. Das Feature Class ist die abhängige Variable uns somit unser Label.\n",
        "2. Wir müssen herausfinden ob Brustkrebs besteht oder nicht und haben es somti mit Classification und somit mit Supvervised Learning zu tun.\n",
        "3. Die Wertskala der einzelnen Features (Attribute) deutet darauf hin, dass hier bereits eine Skalierung durchgeführt wurde. Wir also kein Features Scaling machen müssen.\n",
        "4. Der Datensatz enhält 16 fehlende Werte. Wir müssen uns überlegen, ob wir damit klar kommen oder die entsprechenden Records rauslöschen oder ergänzen sollen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikHErsdQBB8c",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries\n",
        "\n",
        "Nachfolgend benötigen wir ein paar wichtige Python Bibliotheken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhVx55RF_NyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtrYEkPVPGui",
        "colab_type": "text"
      },
      "source": [
        "# Import Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToyzOnywPKdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%203%20-%20Classification/Section%2014%20-%20Logistic%20Regression/Python/dataset-breast-cancer.csv'\n",
        "dataset = pd.read_csv(datloc)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLBAbPr9a7uv",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing Dataset\n",
        "\n",
        "In diesem Datensatz fehlen uns 16 Werte. Die Ersteller des Breast-Cancer Datensatzes haben die fehlenden Wert mit '?' ersetzt. Auch wenn wir mit 16 fehlenden Werten leben könnten, müssen wir die Fragezeichen loswerden, da wir ansonsten beim Training des Datensatzes Probleme bekommen. \n",
        "\n",
        "Nachfolgend löschen wir deshalb zuerst die Zeilen mit '?' und teilen den Datensatz erst danach in die unabhängigen Variablen (X) und abhängige Variablen (y)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq8OTL8CeXoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.drop( dataset[ dataset['7'] == '?' ].index , inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlZyH2BOfXd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bei der Selektion der Featrues für die unabhängigen Variabelen (X) lassen wir die\n",
        "# erste Spalte mit den IDs und letzte Spalte mit den Labels weg\n",
        "X = dataset.iloc[:,1:-1].values \n",
        "y = dataset.iloc[:,-1].values"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsczBftBWmb7",
        "colab_type": "text"
      },
      "source": [
        "# Split in Train- & Testset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxqF-gr9Wfzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size = 0.25,random_state=0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_ocVZnxZyCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df5200ea-6636-4124-b002-c6171ca0e237"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCET9Ey6YzLT",
        "colab_type": "text"
      },
      "source": [
        "# Train the LogReg Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VRm215TYymA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4d0a267e-6742-4f02-b549-aeab566c1edf"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(X_train,y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBy-jNoxf8rg",
        "colab_type": "text"
      },
      "source": [
        "# Predict the Testset results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oCwjB0Of6iN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b67ba90-ddbe-4d37-c60d-464a2ffe06ed"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [4 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [2 4]\n",
            " [4 2]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [2 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [2 4]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]\n",
            " [2 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_DtiUUwgiio",
        "colab_type": "text"
      },
      "source": [
        "# Visualize Pred. Result in Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQAA1kZ3czUV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "0b9ad353-8d20-427d-b31a-fc518738ad8d"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "print (confusion_matrix(y_test, y_pred))\n",
        "tn,fp,fn,tp = confusion_matrix(y_test,y_pred).ravel()\n",
        "print('Zuerst mal die postiven (True) Resultate:')\n",
        "print ('true neg =',tn)\n",
        "print ('true pos =',tp)\n",
        "print('\\n')\n",
        "print('Nun noch die negativen (False) Resultate:')\n",
        "print('false pos =',fp, '(auch Fehler 1.Art genannt)')\n",
        "print('false neg =',fn, '(auch Fehler 2.Art genannt)')\n",
        "print('\\n')\n",
        "print('Zum Abschluss noch die Genauigkeit des Modells')\n",
        "print(accuracy_score(y_test,y_pred))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[103   4]\n",
            " [  5  59]]\n",
            "Zuerst mal die postiven (True) Resultate:\n",
            "true neg = 103\n",
            "true pos = 59\n",
            "\n",
            "\n",
            "Nun noch die negativen (False) Resultate:\n",
            "false pos = 4 (auch Fehler 1.Art genannt)\n",
            "false neg = 5 (auch Fehler 2.Art genannt)\n",
            "\n",
            "\n",
            "Zum Abschluss noch die Genauigkeit des Modells\n",
            "0.9473684210526315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oIWsHybgTNy",
        "colab_type": "text"
      },
      "source": [
        "# Computing the accuracy with k-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfjiJzOgnGqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e8ccd968-7f42-4526-9cf3-eb89fa9661f2"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracy = cross_val_score(estimator=classifier, X = X_train, y=y_train, cv=10)\n",
        "print('Accuracy: {:.2f}%'.format(accuracy.mean()*100))\n",
        "print('Standard Deviation: {:.2f}%'.format(accuracy.std()*100))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 96.87%\n",
            "Standard Deviation: 1.57%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iuu9OUVCnNy4",
        "colab_type": "text"
      },
      "source": [
        "Das Resultat der CV sagt nun folgendes aus:\n",
        "Die Genauigkeit der 10 durchgeführten Stichproben weicht maximal 1.57% (+/-) von der Gesamtgenauigkeit von 96.87% des Models ab.\n",
        "\n",
        "Wir haben somit eine sehr gutes Resultat bekommen bzw. die Genauigkeit der Vorhersagefähigkeit des Modells ist sehr gut. "
      ]
    }
  ]
}