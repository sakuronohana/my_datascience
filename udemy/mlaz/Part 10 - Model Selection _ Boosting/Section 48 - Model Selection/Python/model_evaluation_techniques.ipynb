{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_evaluation_techniques.ipynb.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%2010%20-%20Model%20Selection%20_%20Boosting/Section%2048%20-%20Model%20Selection/Python/model_evaluation_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taLo6Q7NxKRE"
      },
      "source": [
        "# Modellbewertungstechniken (engl. Model evaluation techniques)\n",
        "\n",
        "Mit der Erstellung eines Machine Learning Modells ist es oft nicht getan. Bevor wir ein Modell in die Wildnis entlassen, müssen wir wissen, ob es tatsächlich funktioniert und folglich, ob wir seinen Vorhersagen oder Klassifizierungen vertrauen können. \n",
        "\n",
        "Meist beginnen wir damit ein geeignetes Modell auf einem Datensatz zu trainineren. Wollen wir nun wissen wie es um die Leistung des Modells in Bezug auf die Verallgemeinerung (Generalization) geht, dann verwendet man meist die folgenden Methoden:\n",
        "\n",
        "* **Kreuzvalidierung** - Hierbei verwendet man einen Teil der Trainingsdaten um bereits während des Trainings einen guten Eindruck über die Verallgemeinerungsleistung eines Modells zu erhalten. Eine der bekanntesten Methoden ist hierbei die k-fache Kreuzvalidierung (engl. k-fold cross validation).\n",
        "* **Holdout** - Ist nichts anderes als die Messung der Leistung auf einem Testdatensatz, welche das Modell noch nicht gesehen hat. \n",
        "\n",
        "Die oben erwähnten Bewertungsmethoden messen die Verallgemeinerung eines Modells spezifisch geht es jedoch um folgende wesentliche Leistungsmetriken nach welchen ein Modell gemessen werden sollte:\n",
        "\n",
        "* **Genauigkeit** (Accuracy) - Bei dieser Metrik geht es darum in wievielen Fällen das Modell eine korrekte Klassifikation vorgenommen hat (True Positiv, True Negativ, False Positiv, False Negativ). Diese Metrik wird in vielen Lektüren als die wichtigste Masseinheit in Bezug auf die Messung der Leistung eines Modells angesehen. Aber gerade bei der Messung von Klassifikatoren mit einem stark unausgewogenen Datensatz (bspw. viele Ausreisser) kann dieses Qualitätsmass versagen. Weshalb auch andere Metrik bei der Messung in Betracht gezogen werden sollten.\n",
        "* **Relevanz** (Precision) - Hier geht es im wesentlichen um die positiven Vorhersagen. Dabei werden vor allem die True Positves angesehen. Die Formel für die Relevanz ist:\n",
        "\n",
        " $\\frac{True Positive(TP)}{True Positive (TP) + False Positive (FP)}$\n",
        "\n",
        "* **Sensitivität** (Recall) - Da wir bei der Relevanz vorwiegen das positive Resultat der Vorhersagen beachten, müssen wir in diesem Zusammenhang auch die positive Bilanz gegenüber der negativen Bilanz ziehen. Diese Qualitätsmass wird auch Sensitivität genannt. Die Formel dazu ist:\n",
        "\n",
        " $\\frac{True Positive (TP)}{True Positive (TP) + False Negative (FN)}$\n",
        "\n",
        "Bevor wir nun aber eine Bewertung eines Modells durchführen, müssen wir uns zuerst darüber im klaren sein, welche ML-Methode angewendet wurde bzw. es sich um Regression, Klassifikation oder Clustering handelt. Jeder der genannten Methoden hat eine andere Vorgehensweise und demzufolge müssen auch andere Bewertungstechniken eingesetzt werden. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlX3olTc4J29"
      },
      "source": [
        "## Build and train a regression and classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3x14CwtxcV5"
      },
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMeZ6FKbxkU6"
      },
      "source": [
        "# Importing the dataset\n",
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%203%20-%20Classification/Section%2018%20-%20Naive%20Bayes/Python/Social_Network_Ads.csv'\n",
        "daturl = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%202%20-%20Regression/Section%2010%20-%20Model%20Selection%20Regression/Data.csv'\n",
        "\n",
        "dataset = pd.read_csv(datloc)\n",
        "dataset2 = pd.read_csv(daturl)\n",
        "\n",
        "X = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values\n",
        "\n",
        "X2 = dataset2.iloc[:,:-1].values\n",
        "y2 = dataset2.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5TZ-0qSx5mX"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c60y-wPDxvY-"
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUM0MSyGyCjF"
      },
      "source": [
        "# Training a classifier model on the Training- and Testset\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred_clf = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyYtYUrz7Ewh"
      },
      "source": [
        "# Training a regressor model on the Training- and Testset\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "poly_reg = PolynomialFeatures(degree = 4)\n",
        "X_poly = poly_reg.fit_transform(X2_train)\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_poly, y2_train)\n",
        "\n",
        "y_pred_reg = regressor.predict(poly_reg.transform(X2_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IgOoFPFJ0fW"
      },
      "source": [
        "## Bewertungstechniken für Regressionsmodelle\n",
        "\n",
        "Die Regression ist ja bekanntlich eine rein zahlenbasierte Methode um Vorhersagen (Predictions) zu tätigen. Demzufolge verwenden wir hierbei auch Bewertungsmetriken die auf diesen Aspekt eingehen. \n",
        "\n",
        "Mehr Informationen zu Bewertungsmethoden der Regression sind [hier](https://towardsdatascience.com/ways-to-evaluate-regression-models-77a3ff45ba70) zu finden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oLHOpvkm9Rn"
      },
      "source": [
        "### Coefficient of Determination (R2)\n",
        "\n",
        "Das R-Quadrat (R2) ist ein statistisches Maß, das den Anteil der Varianz für eine abhängige Variable darstellt, der durch eine unabhängige Variable oder Variablen in einem Regressionsmodell erklärt wird. Während die Korrelation die Stärke der Beziehung zwischen einer unabhängigen und einer abhängigen Variablen erklärt, erklärt das R-Quadrat, inwieweit die Varianz einer Variablen die Varianz der zweiten Variablen erklärt. Wenn also R2 eines Modells 0,50 beträgt, kann ungefähr die Hälfte der beobachteten Variation durch die Eingaben des Modells erklärt werden.\n",
        "\n",
        "Nachteil dieser Bewertungsmethode ist, dass das R2 berücksichtigt keine Überanpassung"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTJ6DU0fqELk"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "print(r2_score(y2_test,y_pred_reg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSLEWWy7iWwr"
      },
      "source": [
        "## Bewertungstechniken für Klassifikationsmodelle\n",
        "\n",
        "Im Gegensatz zu den rein zahlenbasierten Modellen verwendet man bei der Klassifikation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBbur5RQyTcL"
      },
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "Die Bewertung der Leistung eines Klassifizierungsmodells basiert auf der Anzahl der vom Modell korrekt und falsch vorhergesagten Testdaten. Die Confusion Matrix liefert ein aufschlussreicheres Bild, das nicht nur die Leistung eines Vorhersagemodells darstellt, sondern auch, welche Klassen korrekt und falsch vorhergesagt werden und welche Art von Fehlern gemacht werden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1llVHNPyWkZ"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred_clf)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred_clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AARwJX1KlNUZ"
      },
      "source": [
        "### Matthews Correlation Coefficient (MCC)\n",
        "\n",
        "Information wie der MCC funktioniert findet man [hier](https://towardsdatascience.com/the-best-classification-metric-youve-never-heard-of-the-matthews-correlation-coefficient-3bf50a2f3e9a)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd4dvfdflq-x"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "print(round(matthews_corrcoef(y_test,y_pred_clf),3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-eGh0nuyabx"
      },
      "source": [
        "### k-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5puHSW9ydyi"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJyapccOmUv-"
      },
      "source": [
        "### Receiver Operating Characteristic Curve (ROC AUC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCJCI6mGmPYx"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "print(roc_auc_score(y_test,y_pred_clf))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh6Cnuuyit3C"
      },
      "source": [
        "## Bewertungstechniken für Clustering-Modelle"
      ]
    }
  ]
}