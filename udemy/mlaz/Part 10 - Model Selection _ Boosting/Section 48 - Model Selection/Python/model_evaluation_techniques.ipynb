{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_evaluation_techniques.ipynb.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%2010%20-%20Model%20Selection%20_%20Boosting/Section%2048%20-%20Model%20Selection/Python/model_evaluation_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taLo6Q7NxKRE"
      },
      "source": [
        "# Modellbewertungstechniken (engl. Model evaluation techniques)\n",
        "\n",
        "Mit der Erstellung eines Machine Learning Modells ist es oft nicht getan. Bevor wir ein Modell in die Wildnis entlassen, müssen wir wissen, ob es tatsächlich funktioniert und folglich, ob wir seinen Vorhersagen oder Klassifizierungen vertrauen können. \n",
        "\n",
        "Meist beginnen wir damit ein geeignetes Modell auf einem Datensatz zu trainineren. Wollen wir nun wissen wie es um die Leistung des Modells in Bezug auf die Verallgemeinerung (Generalization) geht, dann verwendet man meist die folgenden Methoden:\n",
        "\n",
        "* **Kreuzvalidierung** - Hierbei verwendet man einen Teil der Trainingsdaten um bereits während des Trainings einen guten Eindruck über die Verallgemeinerungsleistung eines Modells zu erhalten. Eine der bekanntesten Methoden ist hierbei die k-fache Kreuzvalidierung (engl. k-fold cross validation).\n",
        "* **Holdout** - Ist nichts anderes als die Messung der Leistung auf einem Testdatensatz, welche das Modell noch nicht gesehen hat. \n",
        "\n",
        "Die oben erwähnten Bewertungsmethoden messen die Verallgemeinerung eines Modells spezifisch geht es jedoch um folgende wesentliche Leistungsmetriken nach welchen ein Modell gemessen werden sollte:\n",
        "\n",
        "* **Genauigkeit** (Accuracy) - Bei dieser Metrik geht es darum in wievielen Fällen das Modell eine korrekte Klassifikation vorgenommen hat (True Positiv, True Negativ, False Positiv, False Negativ). Diese Metrik wird in vielen Lektüren als die wichtigste Masseinheit in Bezug auf die Messung der Leistung eines Modells angesehen. Aber gerade bei der Messung von Klassifikatoren mit einem stark unausgewogenen Datensatz (bspw. viele Ausreisser) kann dieses Qualitätsmass versagen. Weshalb auch andere Metrik bei der Messung in Betracht gezogen werden sollten.\n",
        "* **Relevanz** (Precision) - Hier geht es im wesentlichen um die positiven Vorhersagen. Dabei werden vor allem die True Positves angesehen. Die Formel für die Relevanz ist **True Postives + False Positives / True Positives** \n",
        "\n",
        "\n",
        "* **Sensitivität** (Recall) - \n",
        "\n",
        "Bevor wir nun aber eine Bewertung eines Modells durchführen, müssen wir uns zuerst darüber im klaren sein, welche ML-Methode angewendet wurde bzw. es sich um Regression, Klassifikation oder Clustering handelt. Jeder der genannten Methoden hat eine andere Vorgehensweise und demzufolge müssen auch andere Bewertungstechniken eingesetzt werden. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IgOoFPFJ0fW"
      },
      "source": [
        "## Bewertungstechniken für Regressionsmodelle\n",
        "\n",
        "Die Regression ist ja bekanntlich eine rein zahlenbasierte Methode um Vorhersagen (Predictions) zu tätigen. Demzufolge verweden wir hierbei auch Bewertungsmetriken die auf diesen Aspekt eingehen. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ1Zs9MKxXJ1"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3x14CwtxcV5"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L1wq9evxg83"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMeZ6FKbxkU6"
      },
      "source": [
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%203%20-%20Classification/Section%2018%20-%20Naive%20Bayes/Python/Social_Network_Ads.csv'\n",
        "\n",
        "dataset = pd.read_csv(datloc)\n",
        "\n",
        "X = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3FBTRwzxzl7"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5TZ-0qSx5mX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPt8zMSIxrJ7"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c60y-wPDxvY-"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29ry3GSGx9P_"
      },
      "source": [
        "## Training the Kernel SVM model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUM0MSyGyCjF",
        "outputId": "522e5a23-295b-4dce-dbba-93186f9b83c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "    kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
              "    shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBbur5RQyTcL"
      },
      "source": [
        "## Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1llVHNPyWkZ",
        "outputId": "3da5a501-f405-4c7e-de7a-aa1203a982f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[64  4]\n",
            " [ 3 29]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.93"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-eGh0nuyabx"
      },
      "source": [
        "## Applying k-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5puHSW9ydyi"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hotbzOiXV0RA"
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "y_pred_cv = cross_val_predict(classifier, X_train, y_train, cv=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2yvx48XWtZE"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred_cv))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww73ZauFWKLD"
      },
      "source": [
        "y_pred_cv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6HUu8z8ygbT"
      },
      "source": [
        "## Visualising the Training set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkjkHN6Qykw3"
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "X_set, y_set = X_train, y_train\n",
        "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
        "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
        "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
        "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "for i, j in enumerate(np.unique(y_set)):\n",
        "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
        "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
        "plt.title('Kernel SVM (Training set)')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Estimated Salary')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rLgiI19yn8m"
      },
      "source": [
        "## Visualising the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSuas5JgyrpC"
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "X_set, y_set = X_test, y_test\n",
        "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
        "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
        "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
        "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "for i, j in enumerate(np.unique(y_set)):\n",
        "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
        "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
        "plt.title('Kernel SVM (Test set)')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Estimated Salary')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}