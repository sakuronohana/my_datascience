{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "natural_language_processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%207%20-%20Natural%20Language%20Processing/Section%2036%20-%20Natural%20Language%20Processing/Python/natural_language_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwK5-9FIB-lu"
      },
      "source": [
        "# Natural Language Processing\n",
        "\n",
        "NLP beschreibt Techniken und Methoden zur maschinellen Verarbeitung natürlicher Sprache. Ziel ist eine direkte Kommunikation zwischen Mensch und Computer auf Basis der natürlichen Sprache. Natural Language Processing (NLP) versucht, natürliche Sprache zu erfassen und mithilfe von Regeln und Algorithmen computerbasiert zu verarbeiten. NLP verwendet hierfür verschiedene Methoden und Ergebnisse aus den Sprachwissenschaften und kombiniert sie mit moderner Informatik und künstlicher Intelligenz. Ziel ist es, eine möglichst weitreichende Kommunikation zwischen Mensch und Computer per Sprache zu schaffen. Dadurch sollen sich sowohl Maschinen als auch Anwendungen per Sprache steuern und bedienen lassen.\n",
        "Quelle: [bigdata-insider.de](https://www.bigdata-insider.de/was-ist-natural-language-processing-a-590102/)\n",
        "\n",
        "An dieser Stelle ist es wichtig zu erwähnen, dass NLP nicht zum Bereich des Deep Learnings gehört, sondern Deep Learning Techniken verwendet. Diese Kompination wird als Deep Natural Language Processing (DNLP) bezeichnet. Eines der bekanntesten Bereiche im DNLP ist Seq2Seq.\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%207%20-%20Natural%20Language%20Processing/Section%2036%20-%20Natural%20Language%20Processing/Python/NLP_DL.jpg?raw=true' width='500'>\n",
        "\n",
        "\n",
        "Nachfolgend ein paar Beispiel wie NLP ausserhalb von ML durchgeführt wird:\n",
        "\n",
        "* **If / Else Rules (Chatbot)** ist eine sehr klassische ausschliesslich auf programmierten Routinen basierende Methode wie Chatbots früher entwickelt wurden. Man kann sich leicht vorstellen, dass diese Methode in Bezug auf die interaktion mit Menschen sehr limitiert war.\n",
        "* **Audio frequency components analysis** (Speech Recognition). Mit dieser Methode werden Audioaufnahmen mit früheren Audioaufnahmen verglichen und somit das gesprochene Wort oder Satz erkannt und bspw. in Text niedergeschrieben.\n",
        "* **Bag-of-words Modell (Klassifikation)**. Bag of Words ist eine natürliche Sprachverarbeitungstechnik der Textmodellierung. In technischer Hinsicht können wir sagen, dass es sich um eine Methode zur Merkmalsextraktion mit Textdaten handelt. Dieser Ansatz ist eine einfache und flexible Methode zum Extrahieren von Features aus Dokumenten.\n",
        "\n",
        "DNLP kann mittels Neuronalen Netzwerken umgesetzt werden.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1kiO9kACE6s"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdpPFvjX7R4_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTfaCIzdCLPA"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywK64zW47k0K"
      },
      "source": [
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%207%20-%20Natural%20Language%20Processing/Section%2036%20-%20Natural%20Language%20Processing/Python/Restaurant_Reviews.tsv'\n",
        "dataset = pd.read_csv(datloc, sep='\\t', quoting = 3) # Die Daten sind mit Tab getrennt und wir ignorieren ebenfalls die Quotes (Anführungszeichen)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q22FSFqj9kO-"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qekztq71CixT"
      },
      "source": [
        "## Cleaning the texts\n",
        "\n",
        "In NLP ist es oft notwendig die verwendeten Texte zu bereinigen. Zu diesem Zweck können die folgenden Python Libraries verwendet werden:\n",
        "\n",
        "**RegEX (re)**\n",
        "\n",
        "Ein RegEx, oder Regulärer Ausdruck (regular expression), ist eine Folge von Zeichen, die ein Suchmuster bildet. RegEx kann verwendet werden, um zu prüfen, ob eine Zeichenfolge das angegebene Suchmuster enthält. Das Re-Modul bietet eine Reihe von Funktionen, die es uns ermöglichen, eine Zeichenfolge nach einer Übereinstimmung zu suchen.\n",
        "\n",
        "**Natural Language Toolkit (nltk)**\n",
        "\n",
        "NLTK ist eine führende Plattform für den Aufbau von Python-Programmen, die mit Daten in menschlicher Sprache arbeiten. Es bietet benutzerfreundliche Schnittstellen zu über 50 Korpora und lexikalischen Ressourcen wie WordNet sowie eine Reihe von Textverarbeitungsbibliotheken für Klassifizierung, Tokenisierung, Stemming, Tagging, Parsing und semantische Argumentation, Wrapper für NLP-Bibliotheken in Industriequalität und ein aktives Diskussionsforum.\n",
        "\n",
        "Mehr dazu auf [NLTK Webseite](https://www.nltk.org/)\n",
        "\n",
        "Im Zusammenhang mit NLKT werden oft die Begriffe Stemming und Stopwords verwendet. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgp8aRnuFxpx",
        "outputId": "4c7a8f1e-1bc4-44ce-e0d8-da6831fbf8d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAwPkeXIIB19",
        "outputId": "e6f9c534-3fa6-4dce-f56c-c8ac4cbfce21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "txt = \"The rain in Spain\"\n",
        "x = re.search(\"^The.*Spain$\", txt)\n",
        "x"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 17), match='The rain in Spain'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLqmAkANCp1-"
      },
      "source": [
        "## Creating the Bag of Words model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH_VjgPzC2cd"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkIq23vEDIPt"
      },
      "source": [
        "## Training the Naive Bayes model on the Training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JaRM7zXDWUy"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoMltea5Dir1"
      },
      "source": [
        "## Making the Confusion Matrix"
      ]
    }
  ]
}