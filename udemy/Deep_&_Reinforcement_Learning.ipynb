{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KI mit Deep & Reinforcement Learning",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuronohana/my_datascience/blob/master/udemy/Deep_%26_Reinforcement_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyxBmxgRxnMS"
      },
      "source": [
        "# KI mit Deep Learning & Reinforcement Learning\n",
        "\n",
        "Im Zusammenhang mit dem Aufbau einer Künstlichen Intelligenz (KI) kommt man an den Themen Deep Learning und Reinforcement Learning nicht vorbei. In diesen Notebook wird das erforderliche Wissen mittels Erklärungen und Beispielen vermittelt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OMRqL-5eaqu"
      },
      "source": [
        "## **Was ist Deep Learning?**\n",
        "\n",
        "Deep Learning ist ein Teilgebiet des Machine Learning und unterscheidet sich vom „klassischen“ maschinellen Lernen, indem es Maschinen in die Lage versetzt, über die verfügbaren Daten hinaus zu lernen. Das beinhaltet die Fähigkeit, Informationen zu analysieren und zu bewerten, um logische Schlüsse zu ziehen, Lösungswege auszuwählen und aus Fehlern zu lernen. Je mehr Daten eine Maschine also empfängt, desto grösser ist ihre Lernfähigkeit und desto \"intelligenter\" kann sie werden. Obwohl es die künstlichen neuronalen Netze, die die Grundlage dieser Technologien bilden, bereits seit den 1950er Jahren gibt, haben erst die bahnbrechenden Entwicklungen des letzten Jahrzehnts die Lernkurve stark verbessert. Die am meisten verbreiteten modernen Applikationen sind Stimm- und Bilderkennung. Das Niveau der Datenanalyse ermöglicht jedoch viele vorausschauende Applikationen, wie enorme Verbesserungen in der vorausschauenden Wartung, sicherere autonome Fahrzeuge, die Vorhersage von Krankheiten oder Rückfällen. Künstliche neuronale Netzwerke können sowohl für Klassifikation (Binary/Mulit-Class) wie auch Regression verwendet werden. \n",
        "\n",
        "Einer der Pioniere in diesem Gebiet ist [Geoffrey Hinton](https://de.wikipedia.org/wiki/Geoffrey_Hinton). Hinton ist ein britischer Informatiker und Kognitionspsychologe der als Professor an der Universität Toronto und bei Google arbeitet. Er hat massgeblich den Begriff Deep Learning kreiert.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzVwJdUyh8zn"
      },
      "source": [
        "## Was sind Künstlich Neuronale Netzwerke (KNN)?\n",
        "\n",
        "Ein künstliches neuronales Netzwerk (KNN), im englischen Artificial neural networks (ANN) genannt,  ist einen Art Abbildung des menschlichen neuronalen Netzwerks. Diese Netzwerk besteht aus vernetzten Neuronen. In einem KNN ist ein Neuron nichts anderes als eine Element welche eine Nummer zwischen 0 - 1, speichert. In einem KNN gibt es drei Arten von Neuronen - Input Neuron, Hidden Neuron und Output Neuron.\n",
        "\n",
        "Beispiel ein Bild mit einer handschriftlichen Zahl 9 besteht aus 28 x 28 Pixel was somit 784 Neuronen darstellt. Jeder dieser Neuronen enthält einen Graustufenwert von 0.01 (Schwarz) zu 1.00 (Weiss). Diese Werte werden „Activation“ genannt. Dies 784 Neuronen stellen die erste Schicht unsere Netzwerks dar. Die letze Schicht wird nur noch aus 10 Neuronen welche die Nummern 0 - 9 darstellen. Die Schichten dazwischen werden „Hidden Layers“ genannt. Sämtliche Neuronen in den verschiedenen Layers sind miteinander verbunden. Die Verbindungen zwischen den Neuronen haben eigene Gewichtungen. Diese Gewichtung wird mit dem Input-Wert multipliziert. Hat also beispielsweise ein Input-Neuron einen Wert von 0,7 und die Gewichtung der Verbindung einen Wert von 2 werden diese zwei Werte multipliziert und ergeben einen Wert von 1.4, welcher an das nächste Neuron weitergegeben werden. Würden wir aber nun immer so rechnen, würde das Resultat immer durch null gehen. Damit wir das verhindern können benutzen wir den **Bias**. Der Bias ist nichts anderes als der y-Intercept in der linearen Algebra mit dem Unterschied, dass er nur 1 sein kann. Nehmen wir nun also den Bias noch dazu dann bekommen wir folgenden Formel f(x) = mx + b. Im Zusammenhang mit eine künstlichen Neuron kann bestimmt man mit den Bias wie stark der kumulierte Reiz sein muss, um das Neuron überhaupt anzuregen. Er verschiebt also das Grundniveau (0) der Aktivierung. Man kann sich den Bias als Empfindlichkeit des Neurons vorstellen.\n",
        "\n",
        "In einem künstlich neuronalen Netzwerk bestimmen die Aktivitäten in einem Layer die Aktivitäten im nächsten Layer. Die grosse Frage ist dabei WIE Aktivitäten in einem Layer die des nächsten beeinflusst. Grundsätzlich funktioniert es in der gleichen Art wie das biologische Vorbild. Feuert ein Neuron beeinflusst es ein anderes Neuron.\n",
        "\n",
        "Hier eine Abbildung eines typischen KNN:\n",
        "\n",
        "<img src='https://www.researchgate.net/publication/329216193/figure/fig3/AS:697582816870406@1543328112943/Architecture-of-multilayer-artificial-neural-network-with-error-backpropagation.png' width=450>\n",
        "\n",
        "Quelle: [ResearchGate](https://www.researchgate.net/publication/329216193_Predicting_Roof_Pressures_on_a_Low-Rise_Structure_From_Freestream_Turbulence_Using_Artificial_Neural_Networks)\n",
        "\n",
        "\n",
        "Hier noch eine sehr empfehlenswerte Lektüre von Superdatascience.com \n",
        "\n",
        "[The Ultimate Guide to Artificial Neural Networks (ANN)](https://www.superdatascience.com/blogs/the-ultimate-guide-to-artificial-neural-networks-ann)\n",
        "oder [Deep Learning A-Z](https://www.superdatascience.com/pages/deep-learning)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLA0iCN7kHVC"
      },
      "source": [
        "### Anatomie eines KNN\n",
        "\n",
        "Nachfolgenden werden wir die verschiedenen Bestandteile (inkl. Math) eines KNN erläutern"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9C6y4I-skn8"
      },
      "source": [
        "#### Künstliches Neuron (Unit)\n",
        "\n",
        "Ein künstliche Neuron stellt ein vereinfachtes Modell eines biologischen Neurons dar.  Ein künstliches Neuron wird auch oft McCulloch-Pittsburgh-Zelle genannt. \n",
        "Bei der Definition des künstlichen Neurons wurden die wesentlichen Eigenschaften eines biologischen Neurons erhalten:\n",
        "\n",
        "Synapsen der Nervenzellen = Addition gewichteter EIngaben\n",
        "Aktivierung Zellkerns = Aktivierungsfunktion mit Schwellwerten\n",
        "\n",
        "Ein künstliches Neuron (j) wird durch folgende Bestandteile beschrieben:\n",
        "\n",
        "1. Wichtung (wij) - Die Gewichtung den Einfluss der die Eingabe des Neurons in die Berechnung der Aktivierung einnimmt. D.h. Je höher die Gewichtung desto erregender (exzitatorisch) ist der Input. Je geringer desto hemmender (inhibitorisch) ist die Verbindung zwischen zwei Knoten (0 = nicht existent). \n",
        "2. Übertragungsfunktion - Diese Funktion (∑) berechnet anhand der Wichtung der Eingabe die Netzeingabe des Neurons. Meist ist es die Summe der Eingaben. \n",
        "3. Aktivierungsfunktion (ρ) - Diese Funktion bestimmt die Ausgabe des Neurons. Sie wird durch die Netzeingabe und den Schwellwert beeinflusst. -> Siehe Activation Functions\n",
        "4. Schwellwert (θj) - Das Addieren eines Schwellwerts zur Netzeingabe verschiebt die gewichtete Eingabe.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oZb3hJ4YOIv"
      },
      "source": [
        "#### Perzeptron\n",
        "\n",
        "Ausgehen von dieser Idee hat Frank Rosenblatt 1957 das Perzepton entwickelt. Dieses Perzeptron stellt das einfachste KNN dar, da es aus einer Eingabeschicht (Input) und einer Ausgabeschicht (Output) besteht:\n",
        "\n",
        "<img src='https://images.deepai.org/glossary-terms/perceptron-6168423.jpg' width=450>\n",
        "\n",
        "Das Perzeptron besteht aus folgenden Teilen:\n",
        "\n",
        "* **Input-Layer**. Der Input-Layer beinhaltet einerseits die Daten (x) und eine Bias-Unit (1)\n",
        "* **Wichtung (w)**. Die Gewichtung wird pro Verbindung zwischen dem Input und Output dargestellt und beinhaltet irgend einen Wert. \n",
        "* **Output-Layer** Die Ausgabeschicht besteht im wesentlichen aus der **Linear Threshold Unit (LTU)** welche folgende Funktionen beinhaltet: \n",
        "* **Übertragungsfunktion**. Diese Funktion (∑) berechnet die Wichtung mal Input plus Bias:\n",
        " \n",
        " $\\displaystyle \\sum_{i=1}^{n} =  (w_1 * x_1 + w_2 * x_2 + w_n * x_n) + Bias$\n",
        "\n",
        "* **Aktivierungsfunktion (ρ)**. Diese Funktion bestimmt die Ausgabe des Neurons. Sie wird durch die Netzeingabe und den Schwellwert beeinflusst. -> Siehe Activation Functions\n",
        "* **Schwellwert (θj)**. Das Addieren eines Schwellwerts zur Netzeingabe verschiebt die gewichtete Eingabe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL3SY6Urqo9O"
      },
      "source": [
        "#### Input Layer\n",
        "\n",
        "Die Daten werden über den Input Layer in das KNN übergeben. Im ersten Layer finden somit noch keine eigentlichen mathematischen Operationen statt und es gibt dort auch keine eigentlichen Knoten wie es in manchen Darstellungen suggeriert wird. Die Daten werden mittels eines 1D-Arrays in die Input-Schicht "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzCYdyxQ0KHx"
      },
      "source": [
        "#### Aktivierungsfunktion (engl. activation function)\n",
        "\n",
        "Die Aktivierungsfunktion ist der Teil eines künstlichen Neurons, welche die Summe aus der Übertragungsfunktion mittels einer definierten mathematischen Funktion modifiziert. Im wesentlichen geht es bei der AF in einem herkömmlichen neuralen Netzwerk mit Perceptrons Neuronen nur darum zu sagen ob etwas 0 oder 1 ist. Es gibt so gesehen zwei verschiedene AF-Typen Lineare AF und Not-Lineare AF.  Wobei die lineare Aktivierungsfunktion beim Deep Learning so gut wie nicht zur Anwendung kommen. Der Grund dafür ist, dass die reale Welt nicht lineare ist. \n",
        "\n",
        "Bei der nicht-linearen Aktivierungsfunktion unterscheidet man in der Regel zwischen der Derivative - oder Differential- Funktion und der Monotonic- Funktion.\n",
        "\n",
        "Damit eine kleiner Change bei den Gewichtungen (w) und dem Schwellwerten (b=Bias) nicht eine zu starke Auswirkung auf das ganze Neuronale Netzwerk hat, werden Aktivierungsfunktionen verwende, welche Werte zwischen 0 und 1 zu lassen bsp. 0.6669.\n",
        "\n",
        "Meist kommen in eine neuronalen Netzwerk verschiedene AFs vor. So wird beispielsweise bei den Hidden Layers de ReLU und bei den Output Layer Sigmoid verwendet.\n",
        "\n",
        "Die bekanntesten solcher in einem KNN verwendeten Aktivierungsfunktionen sind:\n",
        "\n",
        "* **Threshold - f(x)=(1 if x >= 0)(0 if x < 0)**\n",
        "\n",
        "  Hierbei handelt es sich um die einfachste Aktivierungsfunktion, weil sie lediglich prüft, ob ein Wert grösser oder kleinen als 0 ist. Diese Fuktion wird dann verwendet, wenn der Input binär ist also nur 0 oder 1 annehmen kann.\n",
        "\n",
        "* **Sigmoid - f(x) = 1 / (1 + exp(-x))**\n",
        "\n",
        "  Mit der Sigmoid-Funktion wird eine für diese Funktion typische S-Grafik erstellt. Dabei wird nicht nur ein eindeutiger Wert (Bsp. 0 oder 1) ermittelt, sondern auch wie wahrscheinlich es ist den Wert 0 oder 1 zu erreichen. Diese Funktion ist somit Ideal, wenn es sich um binäre Werte handelt. Da diese Funktionen ihr Limiten hat bzw für das Deep Learning etwas zu langsam ist, wurden die folgenden Alternativen eingesetzt.\n",
        "\n",
        "* **Hyperbolic Tangent (tanh) - f(x) = sinh(x) / cosh(x)**\n",
        "\n",
        "  Die tanh-Funktion ist eine direkte Alternative zu Sigmoid bzw. arbeitet ebenfalls mit der S-Grafik. Der wesentliche Unterschied ist, dass tanh über einen Zahlenbereich von -1 bis 1 verfügt. \n",
        "\n",
        "  Die non-lineare AF Sigmoid und Hyperbolic Tangent werden bei Feed-forward KNNs eingesetzt. \n",
        "\n",
        "* **Rectified Linear Unit (ReLU) - f(x) = max(0,x)**\n",
        "\n",
        "  Diese Funktion gehört zu den am meisten angewendeten Aktivierungsfunktionen in einem KNN bzw. Deep Learning. Sie ersetzte die Sigmoid-Funktionen am besten. Bei der ReLU werden sämtliche Werte welche negativ sind nur als 0 bezeichnet und die Werte welche postiv sind werden als diese übernohmen.\n",
        "\n",
        "Nachfolgend alle bekanntesten Aktivierungsfunktionen auf einen Blick:\n",
        "\n",
        "<img src='https://miro.medium.com/max/875/1*ZafDv3VUm60Eh10OeJu1vw.png' width=600>\n",
        "\n",
        "Quelle: [Medium.com](https://medium.com/@shrutijadon10104776/survey-on-activation-functions-for-deep-learning-9689331ba092)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvaSu_Ivf9bf"
      },
      "source": [
        "## Wie lernt eine KNN?\n",
        "Im einem KNN gibt es zwei Hauptmechanismen das **Forward Propagation** (auch Feedforward genannt) und **Back Propagation**.\n",
        "\n",
        "### Forward Propagation (Feedforward)\n",
        "\n",
        "Beim FP werden die einzelnen Datenwerte ($x_1, x_2, x_3$ usw.) mit einer gewichteten Verbindung ($w_1,w_2;w_3$ usw.) je einzel multipliziert und miteinander mittels Addition aufsummiert. Dieser Summe wird noch ein Bias hinzuaddiert. Das daraus entstandene Resultat wird dann in die Aktivierungsfunktion überträgen welche darüber entscheidet ob das Neuron sich aktiviert bzw. essentiell für die weitere Verarbeitung ist oder nicht. Dieser Prozess wiederholt sich jenachdem wieviele Hidden layers verwendet werden. Am Ende werden die Resultate in den Output Layer überführt und mittels der Cost Function gegenüber dem korrekten Resultat verglichen.  \n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/KNN_Cost_function_1.png?raw=true' width=600>\n",
        "\n",
        "### Backward Propagation (Backpropagation)\n",
        "\n",
        "Backpropagation ist nichts anderes als der Prozess in welchem die Gewichtungen der einzelnen Verbindungen angepasst werden bzw. das KNN optimiert wird. In der Optimierung geht es im Grundsatz darum die Cost function bzw. die Fehler zu minimieren. Dieser Prozess wird auch **Gradient descent** genannt.\n",
        "\n",
        "In der folgenden Grafik sehen wir unten rechts die sogenannte **Cost function (C)**. Die Cost function zeigt uns nichts anderes als die Differenz zwischen dem Output-Werten und den korrekten Werten. Diese Differenz wird als Fehler (Error) bezeichnet. Auf Basis des Resultats (Error) fängt das KNN seine gewichteten Verbindungen zu aktualisieren d.h. das KNN fängt sich an zu optimieren.\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/KNN_Cost_function_2.png?raw=true' width=600>\n",
        "\n",
        "Die in der obigen Grafik dargestellen Input Values sind die von lediglicher einer Zeile eines Datensatzes d.h jedes Feature (unabhängige Variable) stellt einen Input dar. Ein Datensatz mit 15 Merkmalen (Features) würde also 15 Input values bedeutet. \n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/KNN_Cost_function_3.png?raw=true' width=600>\n",
        "\n",
        "#### Gradient Descent\n",
        "\n",
        "Der Gradient Descent (Gradientverfahren) stellt einer der elementarsten Bestandteile eines KNNs dar. Aus diesem Grund wollen wir uns dieses Verfahren mal etwas genauer ansehen.\n",
        "\n",
        "Quelle: [Wikipedia](https://de.wikipedia.org/wiki/Gradientenverfahren)\n",
        "\n",
        "Das Gradientenverfahren wird in der Numerik eingesetzt, um allgemeine Optimierungsprobleme zu lösen. Dabei schreitet man (am Beispiel eines Minimierungsproblems) von einem Startpunkt aus entlang einer Abstiegsrichtung, bis keine numerische Verbesserung mehr erzielt wird. Wählt man als Abstiegsrichtung den negativen Gradienten, also die Richtung des lokal steilsten Abstiegs, erhält man das Verfahren des steilsten Abstiegs. Manchmal werden die Begriffe Gradientenverfahren und Verfahren des steilsten Abstiegs synonym verwendet. Im Allgemeinen bezeichnet Gradientenverfahren eine Optimierungsmethode, bei der die Abstiegsrichtung durch Gradienteninformation gewonnen wird, also nicht notwendigerweise auf den negativen Gradienten beschränkt ist.\n",
        "\n",
        "Das Verfahren des steilsten Abstiegs konvergiert oftmals sehr langsam, da es sich dem stationären Punkt mit einem starken Zickzack-Kurs nähert. Andere Verfahren für die Berechnung der Abstiegsrichtung erreichen teils deutlich bessere Konvergenzgeschwindigkeiten, so bietet sich für die Lösung von symmetrisch positiv definiten linearen Gleichungssystemen beispielsweise das Verfahren der konjugierten Gradienten an. Der Gradientenabstieg ist mit dem Bergsteigeralgorithmus (hill climbing) verwandt.\n",
        "\n",
        "In einer 2D grafischen Darstellung sieht Gradient Descent wie folgt aus:\n",
        "\n",
        "<img src='https://cdn-images-1.medium.com/max/600/1*iNPHcCxIvcm7RwkRaMTx1g.jpeg' width=500>\n",
        "\n",
        "Quelle: [MC.AI](https://mc.ai/an-introduction-to-gradient-descent-2/)\n",
        "\n",
        "Und in 3D so:\n",
        "\n",
        "<img src='https://miro.medium.com/max/875/1*yasmQ5kvlmbYMe8eDkyl6w.png' width=500>\n",
        "\n",
        "Quelle: [Medium.com](https://medium.com/@DBCerigoon-why-gradient-descent-is-even-needed-25160197a635)\n",
        "\n",
        "##### **Batch Gradient Descent (BGD)**\n",
        "\n",
        "Ist ein Gradientverfahren in welchem die ganzen Daten in einem grossen oder mehreren kleinen Batches (Einheiten) in das KNN eingespiesen werden. \n",
        "\n",
        "##### **Stochastic Gradient Descent (SGD)**\n",
        "\n",
        "In der vorletzten Grafik sehen wir wie Gradient Descent in einer gleichmässig nach aussen gebeugte Kurve (auch Convex genannt) aussieht. Nun ist aber so, dass in der realen Welt eine solche Gleichmässigkeit eher selten ist. In Wahrheit haben wir es mit unterschiedlichen Kurven mit mehreren tiefen Stellen zu tun. Damit die Funktion nun nicht einfach das Beste lokale Minimum sondern das globale Minimum (Best) der Cost funkton findet, ist ein stochastischer Ansatz notwendig. \n",
        "\n",
        "<img src='https://www.mltut.com/wp-content/uploads/2020/04/Untitled-document-3.png' width=550>\n",
        "\n",
        "Quelle: [MLTUT](https://www.mltut.com/stochastic-gradient-descent-a-super-easy-complete-guide/)\n",
        "\n",
        "##### **Batch vs. Stochastic Gradient Descent**\n",
        "\n",
        "SGD hat gegenüber dem BGD Verfahren mehrere Vorteile. Nicht nur das SGD mit nicht konvexen Funktionen umgehen kann bzw. das lokale Minimum Problem verhindert. Es ist auch noch schneller als das BGD Verfahren. Was in Anbetracht der zeilenweisen Einfütterung in ein KNN erstaunen mag aber so ist es :-).\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/KNN_Diff_Gradient_Descent.png?raw=true' width=600>\n",
        "\n",
        "Mehr zum Thema Gradient Descent ist unter diesem [Link](https://iamtrask.github.io/2015/07/27/python-network-part2/) oder diesem [Link](https://www.mltut.com/stochastic-gradient-descent-a-super-easy-complete-guide/) zu finden.\n",
        "\n",
        "Abschliessen noch ein kurzer Ablauf, wie eine KNN mit SGD trainiert wird:\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/Section%2039%20-%20Artificial%20Neural%20Networks%20(ANN)/Stochastic_Gradient_Descent.png?raw=true' width=600>\n",
        "\n",
        "In einem von Google entwickelten Tool kann man eine KNN simulieren:\n",
        "\n",
        "https://playground.tensorflow.org/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBGpU5Zptkbk"
      },
      "source": [
        "### Vanishing & Exploding Gradient Problems\n",
        "\n",
        "Im Zusammenhang mit der Backpropagation muss noch ein wichtiges Thema belichtet werden, welches unter anderem den Siegenszug von DL gebremst hat. \n",
        "\n",
        "Ein Problem bei Trainingsnetzwerken mit vielen Layers besteht darin, dass der Gradient dramatisch abnimmt, wenn er sich rückwärts durch das Netzwerk ausbreitet. Der Fehler kann zu dem Zeitpunkt, zu dem er Ebenen nahe der Eingabe des Modells erreicht, so gering sein, dass er möglicherweise nur sehr geringe Auswirkungen hat. Einfach gesagt heisst das, dass geringe Anpassungen an den Gewichtungen der Verbindungen zu einer Art Stagnierung führt bzw. das NN verringert den Error nur sehr minimal und dass NN hat Mühe sich an den optimalen Fehlerminimierung anzunähern. \n",
        "\n",
        "Anstelle der verschwindenden Gradients gibt es aber auch das Gegenteil. Die Gewicht habe zu hohe Werte und dies wiederum führt zum Exploding Gradient Problem, was das NN ebenfalls daran hindert zu einer optimalen Fehlerminimierung zu kommen.\n",
        "\n",
        "<img src='https://www.analyticsindiamag.com/wp-content/uploads/2019/08/afrnn.png' width=600>\n",
        "\n",
        "Die oben beschriebenen zwei Probleme sind vor allem bei RNNs und im Zusammenhang mit der Sigmoid-Funktion zu finden. Es gibt verschiedene Lösungen um mit dem Vanishing & Exploding Gradient Problem umzugehen.\n",
        "\n",
        "1.   Anstelle von Sigmoid einfach die ReLu Aktivierungsfunktion verwenden.\n",
        "2.   Batch normalization im NN integrieren.\n",
        "\n",
        "\n",
        "\n",
        "Hier noch ein gutes [Video](https://www.youtube.com/watch?v=SKMpmAOUa2Q), welche diese Problem genauer erklärt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CodIfacZQtvA"
      },
      "source": [
        "## Supervised Deep Learning\n",
        "\n",
        "Nachfolgende werden Deep Learning Modelle vorgestellt, welche sich für das überwachte Lernen eignen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR8AqwrmRl_2"
      },
      "source": [
        "### Fully Connected Neural Network (FCNN) - Klassifikation\n",
        "\n",
        "Eines der klassischen KNNs ist das Fully Connected Neural Network. Es wird so genannt, weil alle Units miteinander verbunden sind. Damit sind wir auch schon beim Haupproblem dieser Art KNNs angekommen. Fully Connected hat einen Einfluss auf die Performance.\n",
        "\n",
        "<img src='https://cdn-images-1.medium.com/max/720/1*VHOUViL8dHGfvxCsswPv-Q.png' width=500>\n",
        "\n",
        "Im nachfolgenden Beispiel bauen wir ein solches KNN um ein Klassifikationsproblem zu lösen. Für den Aufbau verwenden wird das Framework Tensorflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o58FN6eCyTBN"
      },
      "source": [
        "#### Ausgangslage\n",
        "\n",
        "Eine Bank verliert innerhalb kurzer Zeit sehr viele Kunden. Sie möchte nun gerne Wissen, welche der noch bestehenden Kunden evtl. die Bank in den nächsten 6 Monaten abwandern (engl. churn) könnten. Für die Erstellung eins KNN-Regressionsmodells stellt sie einen Datensatz von 10000 Kunden zur Verfügung, welche noch bei der Bank sind oder diese bereits verlassen haben. Neben 13 Features (unabhängige Variablen) beinhaltet der Datensatz auch eine Spalte mit Labels (abhängige Variable).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7wEUUJrw0s_"
      },
      "source": [
        "#### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aMy3FaVWJJc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-dPtRXaL6aL",
        "outputId": "33684f52-0e70-4bb3-8f35-c42d9b13e51a"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrPhog7uxHYL"
      },
      "source": [
        "#### Teil 1 - Datenaufbereitung (Data Preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pRyhRL_1tzr"
      },
      "source": [
        "#### Datenimport\n",
        "\n",
        "Nach dem wir die Daten importiert haben, werden wir sie, wie immer im Supervised Learning, in einen Datensatz mit unabhängigen und abhängigen Variablen aufteilen. Bevor wir aber die Datenwerte (Values) in zwei Datensätze teilen, schauen wir uns mal den importierten Datensatz an. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INjwpXRYxOV9"
      },
      "source": [
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/Section%2039%20-%20Artificial%20Neural%20Networks%20(ANN)/Python/Churn_Modelling.csv'\n",
        "\n",
        "dataset = pd.read_csv(datloc)\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6HlzPOOU1gh"
      },
      "source": [
        "Prüfen wir doch auch noch gleich, ob wir fehlende Daten haben. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cerT8oa-TuMW"
      },
      "source": [
        "dataset.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCSy935pPKSW"
      },
      "source": [
        "Beim betrachten des Datensatzes müssen wir uns überlegen, welche Features für das Modell überhaupt relevant sind bzw. welche Features eine Einfluss auf das Label (abhängige Variable) haben. Wir könnten natürlich alle Spalten bestehen lassen aber dann müssten wir auch die nicht relevanten kategorischen Merkmale in nummerische Wert umwandeln. Diese Arbeit können wir uns sparen in dem wir eine Vorselektion machen.\n",
        "\n",
        "Wenn wir nun also den orginal Datensatz betrachten, dann können wir mit Sicherheit sagen, dass die Merkmale RowNumber, CustomerId und Surname keinen Einfluss auf das Label Exited haben werden. Somit müssen wir nur alle Features ab Spalte 4 (in Python 3, da es bei 0 anfängt) bis minus der letzen Spalte (Label) in X importieren."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu3WhSETPELd"
      },
      "source": [
        "X = dataset.iloc[:,3:-1].values\n",
        "y = dataset.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS9XOEOHQ8RM"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEb19jLOSW6Z"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2KjKpVX16O0"
      },
      "source": [
        "#### Encoding von kategorischen Daten\n",
        "\n",
        "Wie wir im Datensatz unschwer erkennen können, beinhaltet diese auch kategorische Daten wie Geography (Land) und Gender (Geschlecht). Mit diesen kann eine KNN nichts anfangen. \n",
        "Während Geography drei unterschiedliche Werte enthält sind beim Feature Gender nur zwei Zustände zu beaobachten Female oder Male. Auf Basis dieser Erkenntnisse setzen wir nun folgende Encoding ein:\n",
        "\n",
        "Geography = One Hot Encoding\n",
        "\n",
        "Gender = Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10FHtoB5cpxA"
      },
      "source": [
        "# Prüfen wir noch kurz wieviele Werte das Feature Geography hat.\n",
        "dataset.groupby(by=['Geography'], axis=0).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZSAHCIhXGOj"
      },
      "source": [
        "##### LabelEncoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_c5bgQ615eY"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "# Gender ist die Spalte 2\n",
        "X[:,2] = le.fit_transform(X[:,2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgRHovrDXRdu"
      },
      "source": [
        "##### OneHotEncoding\n",
        "\n",
        "Die Anwendung von Datentransformationen wie Skalierung oder Codierung kategorischer Variablen ist einfach, wenn alle Eingabevariablen vom gleichen Typ sind. Es kann eine Herausforderung sein, wenn man einen Datensatz mit gemischten Typen haben und man Datentransformationen selektiv auf einige, aber nicht alle Eingabefunktionen anwenden möchten.\n",
        "\n",
        "Dankenswerterweise stellt die Scikit-Learn-Bibliothek für maschinelles Lernen in Python den **ColumnTransformer** zur Verfügung, mit dem man Datentransformationen selektiv auf verschiedene Spalten in Ihrem Dataset anwenden können.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uF9_PVvWQm-"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "# Nun bauen wir uns die benötigte Funktion zusammen wobei wir der Funktion die \n",
        "# Encoding Methode und die Spaltennummer mitgeben.\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(),[1])], remainder='passthrough')\n",
        "# Jetzt können wir die erstellte Funktion nutzen. Wichtig dabei ist, dass wir die Daten nach dem\n",
        "# Encoding wieder in die richtige Form bzw. einen Array bringen.\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnKwNVPKcA50"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-fzWIkJKSRp"
      },
      "source": [
        "#### Splitting des Datensatzes (Training/Testing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6ms3BrOxbBo"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTjAkNEeKmnS"
      },
      "source": [
        "#### Feature Scaling\n",
        "\n",
        "Wen man ein KNN baut, dann ist das Scaling der Daten ein **MUSS**. Scaling ist im Zusammenhang mit DL so wichtig, dass wir jeweils alle Features, auch wenn sie nur Werte wie 0 oder 1 beinhalten skalieren. Kurz gesagt wir skalieren immer den ganzen Datensatz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlH9JEV11EUx"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6JoNPSljQ0e"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFXDsqqojZoh"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9Jgswm_K9ED"
      },
      "source": [
        "#### Teil 2 - Aufbau des KNN\n",
        "\n",
        "Kommen wir nun zum Aufbau unseres Fully connected neuronal networks. Wir werden das KNN mittels [TensorFlow](https://de.wikipedia.org/wiki/TensorFlow#2.0:_TensorFlow_2.0) bauen. Wobei wir strenggenommen das im TF 2.0 integierten Deep-Learning-Bibliothek [Keras](https://de.wikipedia.org/wiki/Keras) verwenden.\n",
        "\n",
        "Um es vielleicht etwas bildlich darzustellen ... wir bauen uns im Teil 2 das eigentliche Hirn unseres KNNs.\n",
        "\n",
        "<img src='https://www.simplyscience.ch/assets/images/5/Titelbild_Unser%20Gehirn-60f8bf65.jpg' width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtP4ouT1kkPl"
      },
      "source": [
        "#### KNN Initialisierung \n",
        "\n",
        "Der Aufbau eines KNN ist nichts anderes als die Aneinanderreihung (Sequenzierung) von Layers (Schichten). Wir müssen deshalb zuerst einmal das Rahmenkonstrukt unseres KNNs bauen und teilen diesem Konstrukt mit, dass es alles was wir darin einbauen sequenziell abarbeiten soll. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4hI7yCflQWe"
      },
      "source": [
        "knnk = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzr6xtYlkxMq"
      },
      "source": [
        "##### Hinzufügen des Input Layers und ersten Hidden Layers\n",
        "\n",
        "Nachfolgend bauen wir nun den ersten Hidden Layer. Den Input Layer müssen wir nicht explizit definieren, da dieser ja aus der Anzahl Features besteht, welche wir ins KNN einspeisen. \n",
        "\n",
        "Da wir das einfachste Basic KNN (FKNN) bauen benötigen wir lediglich die Keras- Klasse Dense. Dense (dt. dicht) definiert nichts anderes als, dass jede Unit mit jeder Unit in der nächsten Schicht verbunden ist (Fully connected).\n",
        "\n",
        "Ein wichtig Fragen im Zusammenhang mit dem Hidden Layers ist immer die Anzahl Units (Neuronen) die man in diesem Layer definiert. Um es kurz zu halten ... es gibt hier keine wirklich Richtwert ... hier gilt einfach Try and Error :-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLmhZ16ypfeX"
      },
      "source": [
        "# Unser Hidden Layer wird mit 6 Units definiert und die Aktivierungsfunktion wird \n",
        "# mit der ReLu Funktion gemacht. \n",
        "knnk.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0KBctYzk_YM"
      },
      "source": [
        "#### Hinzufügen des zweiten Hidden Layers\n",
        "\n",
        "Den zweiten Hidden Layer hinzuzufügen ist sehr einfach. Einfach die vorhergehende Codezeile kopieren :-). Es steht aber jedem frei in der zweiten Schicht die Anzahl der Units zu erhöhen. Dies kann aber während des Trainings immer noch gemacht werden, um eine verbesserte Performance zu erreichen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWdJFjjCrt25"
      },
      "source": [
        "knnk.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEeUA2EOlI9T"
      },
      "source": [
        "##### Hinzufügen des Output Layers\n",
        "\n",
        "Nun fügen wir noch einen Output Layer hinzu. Auch hier können wir natürlich die Codezeile von oben kopieren, müssen aber zwei Parameter anpassen.\n",
        "\n",
        "Die Anzahl der Units im Output Layer hängen davon ab, wieviele mögliche Werte wir predicten können. Bei diesem Datensatz haben wir es mit einem binären Resultat d.h. 0 oder 1 zu tun. Weshalb wir im Output also nur eine Unit definieren. Würden wir einen Klassifikator bauen mit welche wir handgeschiebene Zahlen von 0 - 9 erkennen wollten, dann würden wir also 10 Units (Pro Zahl eine Unit) definieren. \n",
        "\n",
        "Wir müssen auch noch die Aktivierungsfunktion im Output Layer ändern und zwar auf Sigmoid, Softmax, tanh usw. Der Grund ist ganz einfach. Das Ziel unseres KNNs ist es, die Wahscheinlichkeit (Probability) zu berechnen, mit der wir bei einem Kunden mit einer Abwanderung zu rechnen haben. Die Wahrscheinlichkeit kann uns eine Funktion wie ReLu nicht geben, da diese Funktion nur 0 oder nicht 0 kennt. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wfd1p1Ivegk"
      },
      "source": [
        "knnk.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJmuZXfNLHRr"
      },
      "source": [
        "#### Teil 3 - Training des KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIEf4j4d4kBB"
      },
      "source": [
        "##### Kompilierung des KNN\n",
        "\n",
        "Nachdem wir nun sozusagen das Hirn (KNN) gebaut haben, müssen wir noch definieren wie es funktionieren soll. Für ein funktionierendes KNN müssen wir noch folgenden Funktionen definieren:\n",
        "\n",
        "**Optimizer** \n",
        "\n",
        "Damit die gewichteten Verbindungen im KNN optimiert werden, benötigen wir ein Gradient descent Verfahren. Wie wir ja mittlerweilen Wissen, eigenet sich ein stochastischen Gradientverfahren am Besten um nicht nur ein lokales Minimum sondern das globale Minimum herauszufinden. Eines der bekanntesten SGD-Verfahren ist der Adam Optimisierungsalgoritmus. Mehr dazu unter dem folgenden [Link](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/). Es gibt aber noch eine Vielzahl weiterer Opimizer im Keras ([Link](https://keras.io/api/optimizers/))\n",
        "\n",
        "**Cost-Function**\n",
        "\n",
        "Mittels der Cost function (auch Loss function) genannt wird die Fehlerrate des Outputs ermittelt. Auf Basis des ermittelten Fehlers wird das KNN mittels Optimizer optimiert. Je nach dem welche Art von Problem man mit dem KNN lösen möchte wird eine andere Cost function verwendet. Nachfolgend eine Auflistung der im Keras verfügbaren Loss Functions:\n",
        "\n",
        "* **Regressions**\n",
        "  * Mean Squared Error Loss\n",
        "  * Mean Squared Logarithmic Error Loss\n",
        "  * Mean Absolute Error Loss\n",
        "* **Binary Classification**\n",
        "  * Binary Cross-Entropy\n",
        "  * Hinge Loss\n",
        "  * Squared Hinge Loss\n",
        "* **Multi-Class Classification**\n",
        "  * Multi-Class Cross-Entropy Loss\n",
        "  * Sparse Multiclass Cross-Entropy Loss\n",
        "  * Kullback Leibler Divergence Loss\n",
        "\n",
        "Da wir in unserem Beispiel eine binäre Klassifikation durchführen können wir unter drei verschiedenen Loss functions auswählen. Mehr darüber auf diesem [Link](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/).\n",
        "\n",
        "**Metriken**\n",
        "\n",
        "Um die Performance der KNN zu messen, bedienen wir uns verschiedener Metriken.\n",
        "Die verwendete Metrik ist ebenfalls davon abhängig, welches Problem wir mittels DL lösen wollen. Nachfolgend eine Auflistung der im Keras verfügbaren Metriken:\n",
        "\n",
        "* **Regression**\n",
        "  * Mean Squared Error: mean_squared_error, MSE or mse\n",
        "  * Mean Absolute Error: mean_absolute_error, MAE, mae\n",
        "  * Mean Absolute Percentage Error: mean_absolute_percentage_error, MAPE, mape\n",
        "  * Cosine Proximity: cosine_proximity, cosine\n",
        "* **Classification**\n",
        "  * Binary Accuracy: binary_accuracy, acc\n",
        "  * Categorical Accuracy: categorical_accuracy, acc\n",
        "  * Sparse Categorical Accuracy: sparse_categorical_accuracy\n",
        "  * Top k Categorical Accuracy: top_k_categorical_accuracy (requires you specify a k parameter)\n",
        "  * Sparse Top k Categorical Accuracy: sparse_top_k_categorical_accuracy (requires you specify a k parameter\n",
        "\n",
        "Mehr darüber auf diesem [Link](https://machinelearningmastery.com/custom-metrics-deep-learning-keras-python/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDnSuCLS4s_-"
      },
      "source": [
        "knnk.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZNdu51445FR"
      },
      "source": [
        "##### Training mit dem Trainingset\n",
        "\n",
        "Kommen wir nun eigentlichen Training des KNNs. Hier für benötigen wir neben der Fit-Funktion und den Trainingsdaten auch noch weitere Hyperparameter:\n",
        "\n",
        "**Batch Size** \n",
        "\n",
        "Im Grundsatz geht es bei der Batch Size lediglich darum, wieviele Samples (Zeilen) pro Durchgang ins KNN eingespiesen werden bevor das KNN optimiert wird.\n",
        "\n",
        "**Epoch**\n",
        "\n",
        "Epoch ist ein Hyperparameter, der die Anzahl der Druchgänge definiert, die der Lernalgorithmus den gesamten Trainingsdatensatz durcharbeitet. Eine Epoche bedeutet, dass jedes Sample im Trainingsdatensatz die Möglichkeit hatte, die internen Modellparameter zu aktualisieren. Eine Epoche besteht aus einem oder mehreren Batches. Zum Beispiel wird eine Epoche, die aus einer Batch besteht, wie oben beschrieben, als Batch Gradient Desent-Lernalgorithmus bezeichnet.\n",
        "\n",
        "Hier ein Beispiel:\n",
        "\n",
        "Angenommen, man hat einen Datensatz mit 200 Stichproben (Zeilen) und man wählen eine Batch-Grösse von 5 und 1000 Epochen.\n",
        "\n",
        "Dies bedeutet, dass der Datensatz in 40 Batches mit jeweils fünf Stichproben aufgeteilt wird. Die Modellgewichte werden nach jedem Batch mit fünf Stichproben aktualisiert.\n",
        "\n",
        "Das bedeutet auch, dass eine Epoche 40 Batches oder 40 Aktualisierungen des Modells umfasst.\n",
        "\n",
        "Bei 1000 Epochen wird das Modell den gesamten Datensatz 1000 Mal durchlaufen. Das sind insgesamt 40.000 Batches während des gesamten Trainings.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an2qoiUrSMqB"
      },
      "source": [
        "# Wir definieren hier eine Batch-Grösse von 32 Samples über 100 Epochen.\n",
        "# Das bedeutet, dass auf 8000 Samples (Zeilen) 250 Batches kommen welche bei jeder\n",
        "# Epoche durch das KNN geschleust werden. Während des ganzen Training wird das KNN somit\n",
        "# 250 Mal aktualisiert und es laufen 25000 Batches durch das KNN durchlaufen.\n",
        "knnk.fit(X_train, y_train, batch_size= 32, epochs = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHnGI-fZLS8P"
      },
      "source": [
        "#### Teil 4 - Durchführung der Prediction und evaluieren des Modells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JULHWzXeqm6"
      },
      "source": [
        "#### Vorhersagen eines Resultats einer einzelnen Beobachtung\n",
        "\n",
        "Anschliessend wollen wir mittels den folgenden Informationen eine Vorhersage tätigten, ob diese Kunde ebenfalls von der Bank abwandern wird.\n",
        "\n",
        "Geography: France\n",
        "\n",
        "Credit Score: 600\n",
        "\n",
        "Gender: Male\n",
        "\n",
        "Age: 40 years old\n",
        "\n",
        "Tenure: 3 years\n",
        "\n",
        "Balance: \\$ 60000\n",
        "\n",
        "Number of Products: 2\n",
        "\n",
        "Does this customer have a credit card ? Yes\n",
        "\n",
        "Is this customer an Active Member: Yes\n",
        "\n",
        "Estimated Salary: \\$ 50000\n",
        "\n",
        "Wichtig bei der Prediction eines einzelnen Resultats ist,\n",
        "\n",
        "1. Die Werte müssen in eine doppelten eckigen Klammer [[]] stehen, da wir die Daten in einem 2D Array ins KNN einfliessen lassen.\n",
        "2. Die Werte der Feartures, welche encodet wurden müssen auch in dieser Form eingegeben werden. Bspw. France hat codiert den Wert 1,0,0 \n",
        "3. Die Werte müssen mit der gleichen Skalierung transformiert werden wie die Wert im Trainings und Testdatensatz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGX61KuPf13X"
      },
      "source": [
        "print('Die Wahrscheinlichkeit, dass der Kunde die Bank verlassen wird liegt bei:', knnk.predict(sc.transform([[1,0,0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\n",
        "\n",
        "# Nachfolgend werden wir den Wert in eine True oder False umwandeln. Hier können wir den Wert > 0.5\n",
        "# definieren. Ist also der vorhergesagte Wert grösser als 0.5 (50%) besteht eine höhere Wahrscheinlichkeit\n",
        "# dass der Kunde bleiben wird. Wünscht das Management eine genauere Analyse kann der Wert auch erhöht werden.\n",
        "if (knnk.predict(sc.transform([[1,0,0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5) == False:\n",
        "  print ('Der Kunde wir die Bank nicht verlassen')\n",
        "else:\n",
        "  print ('Der Kunde wird die Bank verlassen')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4peSlDduo5MD"
      },
      "source": [
        "#### Vorhersage der Testdatenresultate\n",
        "\n",
        "Nun wollen wir mal schauen wie gut das Modell auf dem Testdatensatz funktioniert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL5gsY98idBD"
      },
      "source": [
        "y_pred = knnk.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjg5Lwf2qX4t"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_pred, y_test)\n",
        "print('True Positiv, heisst:',cm[0][0],'Kunden werden gemäss Vorhersage bleiben und sind in Wirklickeit auch geblieben.')\n",
        "print('True Negativ, heisst:',cm[1][1],'Kunden werden gemäss Vorhersage gehen und sind in Wirklichkeit auch gegangen.')\n",
        "print('False Negativ, heisst:',cm[0][1],'Kunden werden gemäss Vorhersage gehen, sind in Wirklichkeit aber geblieben.')\n",
        "print('False Positiv, heisst:',cm[1][0],'Kunden werden gemäss Vorhersage bleiben, sind in Wirklichkeit aber gegangen.')\n",
        "print()\n",
        "print('Das Modell machte in',accuracy_score(y_pred, y_test)*100,'Prozent der Fälle eine korrekte Vorhersagen d.h. bei 86 von 100 Kunden stimmte die Vorhersage.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO0-lJBK79y_"
      },
      "source": [
        "### Fully Connected Neural Network (FCNN) - Regression\n",
        "\n",
        "Nachfolgend werden wir noch ein Beispiel eines KNN für ein Regressionsprobleme erstelle. Es werden nicht mehr so detailierte Erklärungen wie beim vorherigen Beispiel folgen, da einiges gleich bleibt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1aC35WADci2"
      },
      "source": [
        "#### Ausgangslage\n",
        "\n",
        "Für dieses Beispiel werden wir einen Datensatz aus dem [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table) nehmen. Der Datensatz  beinhaltet Daten eines [Gas-und Dampf-Kombikraftwerks](https://de.wikipedia.org/wiki/Gas-und-Dampf-Kombikraftwerk) (engl. Combined Cycle Power Plant).\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/ISK_Knapsack_GuD_2007.jpg/1920px-ISK_Knapsack_GuD_2007.jpg' width=500>\n",
        "\n",
        "1.Bild: Gas- und Dampf-Kraftwerk Knapsack des Unternehmens Statkraft mit zwei Gasturbinen\n",
        "\n",
        "\n",
        "\n",
        "##### **Beschreibung des Datensatzes**\n",
        "\n",
        "Der [Datensatz](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant) beinhaltet 9568 Datenpunkte (Zeilen) welche über eine Zeitraum von 6 Jahren (2006-2011) gesammelt wurden. Der Datensatz verfügt über vier unabhängige Variablen und einer abhängigen Variable (Label).\n",
        "Die Merkmale bestehen aus stündlich gemittelten Umgebungsvariablen\n",
        "* Temperatur (T) im Bereich von 1,81°C und 37,11°C,\n",
        "* Umgebungsdruck (AP) im Bereich von 992,89-1033,30 milibar,\n",
        "* Relative Luftfeuchtigkeit (RH) im Bereich von 25,56% bis 100,16%\n",
        "* Auslass-Unterdruck (V) im Bereich 25,36-81,56 cm Hg (Zentimeter Quecksilbersäule)\n",
        "\n",
        "Das Label besteht aus der Netto-Stundenleistung an elektrischer Energie (EP) 420,26-495,76 MegaWatt (MW).\n",
        "\n",
        "Die Mittelwerte werden von verschiedenen Sensoren genommen, die sich um die Anlage herum befinden und die Umgebungsvariablen jede Sekunde aufzeichnen. Die Variablen werden ohne Normalisierung angegeben.\n",
        "\n",
        "Ein Kombikraftwerk (CCPP) besteht aus Gasturbinen (GT), Dampfturbinen (ST) und Dampferzeugern mit Wärmerückgewinnung. In einem GuD-Kraftwerk wird der Strom durch Gas- und Dampfturbinen erzeugt, die in einem Zyklus kombiniert und von einer Turbine auf eine andere übertragen werden. Während das Vakuum von der Dampfturbine gesammelt wird und sich auf die Dampfturbine auswirkt, beeinflussen die anderen drei Umgebungsvariablen die Leistung der GT.\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Prinzip_Gas-und-Dampf-Kombikraftwerk.svg/1920px-Prinzip_Gas-und-Dampf-Kombikraftwerk.svg.png' width=500>\n",
        "\n",
        "2.Bild: Funktionsweise eines GuD-Kraftwerks\n",
        "\n",
        "##### **Ziel**\n",
        "\n",
        "Es soll mittels Regression der stündliche Netto-Stundenertrag an elektrischer Energie (EP) welches das Kraftwerks erzeugt vorhergesagt werden.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHLB_-8oVr2N"
      },
      "source": [
        "#### Teil 1 - Datenaufbereitung (Data Preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gocbCIizJjnv"
      },
      "source": [
        "##### Datenimport"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKXzepZoWNb4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABML0Cs1KVcB",
        "outputId": "c2518312-90d2-46ec-fcd3-15bc593fbe2d"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSG9FAuSWXuE"
      },
      "source": [
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/Section%2039%20-%20Artificial%20Neural%20Networks%20(ANN)/Python/CCPP_Data_Set.xlsx'\n",
        "dataset = pd.read_excel(datloc)\n",
        "\n",
        "X = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPrwArjPJnPG"
      },
      "source": [
        "##### Datensatz in Trainings- und Testdaten aufteilen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl6R_kG0J2DX",
        "outputId": "bf8f57fd-110f-400d-ccf6-b5cc4bec72d0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=0)\n",
        "\n",
        "print('In unserem Trainingsdatenset befinden sich',X_train.shape[0],'Zeilen.')\n",
        "print('Im Testdatenset befinden sich',X_test.shape[0],'Zeilen')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In unserem Trainingsdatenset befinden sich 7654 Zeilen.\n",
            "Im Testdatenset befinden sich 1914 Zeilen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o05cyLEbhL_y"
      },
      "source": [
        "#### Skalierung der Daten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY_eYeNBhSFZ"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VdjISgghI73"
      },
      "source": [
        "#### Teil 2 - Aufbau des KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai7HAznEjklk"
      },
      "source": [
        "##### Initialisierung des KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC1OjIcihwIy"
      },
      "source": [
        "knnr = tf.keras.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YZPcX5ajrLp"
      },
      "source": [
        "##### Hinzufügen des Input Layers und des ersten Hidden Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sBT2599ky3t"
      },
      "source": [
        "knnr.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bYLmM1Tj3zT"
      },
      "source": [
        "##### Hinzufügen des zweiten Hidden Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97ZlrMTvlvvN"
      },
      "source": [
        "knnr.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YqxCrHFletX"
      },
      "source": [
        "##### Hinzufügen des Output Layer\n",
        "\n",
        "Im Gegensatz zu KNN für Klassifikation müssen wir bei der Regression keine Aktivierungsfunktion hinzufügen (Default activation = none), da wir ja den eigentlichen Wert möchten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLIkYQROlyfN"
      },
      "source": [
        "knnr.add(tf.keras.layers.Dense(units=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxZUVdsXjNcb"
      },
      "source": [
        "#### Teil 3 - Training des KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHDJ2tQqoF6e"
      },
      "source": [
        "#### Kompilierung des KNN\n",
        "\n",
        "Hier kommt noch eine Unterschied gegenüber einem KNN für Klassifikation. Die Cost function ist bei Regression natürlich die mittlere quadratische Abweichunng (Mean squared error)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU7qwzXkn83v"
      },
      "source": [
        "knnr.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYMlsWtrpaCn"
      },
      "source": [
        "#### Training des KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ajLY0EmpfG4",
        "outputId": "9ea0aca2-0f82-4433-d0de-29cda820640b"
      },
      "source": [
        "knnr.fit(X_train, y_train, batch_size=32, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 204587.6094\n",
            "Epoch 2/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 191595.4375\n",
            "Epoch 3/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 153640.0781\n",
            "Epoch 4/100\n",
            "240/240 [==============================] - 0s 989us/step - loss: 93902.4922\n",
            "Epoch 5/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 44891.5195\n",
            "Epoch 6/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25667.0605\n",
            "Epoch 7/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20528.8418\n",
            "Epoch 8/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 17263.1699\n",
            "Epoch 9/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 14014.3926\n",
            "Epoch 10/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 10809.6699\n",
            "Epoch 11/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 7899.3140\n",
            "Epoch 12/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 5543.3428\n",
            "Epoch 13/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 3764.4941\n",
            "Epoch 14/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 2460.3867\n",
            "Epoch 15/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 1561.5304\n",
            "Epoch 16/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 988.9929\n",
            "Epoch 17/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 635.4805\n",
            "Epoch 18/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 422.0427\n",
            "Epoch 19/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 289.6678\n",
            "Epoch 20/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 204.5656\n",
            "Epoch 21/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 146.7824\n",
            "Epoch 22/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 107.9543\n",
            "Epoch 23/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 82.3116\n",
            "Epoch 24/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 64.6839\n",
            "Epoch 25/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 52.3700\n",
            "Epoch 26/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 43.5312\n",
            "Epoch 27/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 37.1718\n",
            "Epoch 28/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 32.7967\n",
            "Epoch 29/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 29.6894\n",
            "Epoch 30/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 27.5946\n",
            "Epoch 31/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 25.8952\n",
            "Epoch 32/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 24.7997\n",
            "Epoch 33/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 23.9294\n",
            "Epoch 34/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 23.4062\n",
            "Epoch 35/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 22.8591\n",
            "Epoch 36/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 22.5169\n",
            "Epoch 37/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 22.3309\n",
            "Epoch 38/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 22.0014\n",
            "Epoch 39/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.8746\n",
            "Epoch 40/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.7364\n",
            "Epoch 41/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 21.6902\n",
            "Epoch 42/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.4845\n",
            "Epoch 43/100\n",
            "240/240 [==============================] - 0s 989us/step - loss: 21.3997\n",
            "Epoch 44/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.3631\n",
            "Epoch 45/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.3632\n",
            "Epoch 46/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.3386\n",
            "Epoch 47/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.2606\n",
            "Epoch 48/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 21.3292\n",
            "Epoch 49/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.3208\n",
            "Epoch 50/100\n",
            "240/240 [==============================] - 0s 972us/step - loss: 21.3516\n",
            "Epoch 51/100\n",
            "240/240 [==============================] - 0s 989us/step - loss: 21.1262\n",
            "Epoch 52/100\n",
            "240/240 [==============================] - 0s 981us/step - loss: 21.1598\n",
            "Epoch 53/100\n",
            "240/240 [==============================] - 0s 972us/step - loss: 21.1195\n",
            "Epoch 54/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.2343\n",
            "Epoch 55/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 21.1948\n",
            "Epoch 56/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 21.0269\n",
            "Epoch 57/100\n",
            "240/240 [==============================] - 0s 977us/step - loss: 20.9578\n",
            "Epoch 58/100\n",
            "240/240 [==============================] - 0s 972us/step - loss: 21.0652\n",
            "Epoch 59/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.9997\n",
            "Epoch 60/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 21.1095\n",
            "Epoch 61/100\n",
            "240/240 [==============================] - 0s 985us/step - loss: 21.1294\n",
            "Epoch 62/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 21.0450\n",
            "Epoch 63/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.8655\n",
            "Epoch 64/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.8956\n",
            "Epoch 65/100\n",
            "240/240 [==============================] - 0s 972us/step - loss: 21.0903\n",
            "Epoch 66/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.7834\n",
            "Epoch 67/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.8403\n",
            "Epoch 68/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.7892\n",
            "Epoch 69/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.8075\n",
            "Epoch 70/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.7897\n",
            "Epoch 71/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.7009\n",
            "Epoch 72/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.8499\n",
            "Epoch 73/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.7484\n",
            "Epoch 74/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.6743\n",
            "Epoch 75/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.6382\n",
            "Epoch 76/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.7297\n",
            "Epoch 77/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.8052\n",
            "Epoch 78/100\n",
            "240/240 [==============================] - 0s 985us/step - loss: 20.6867\n",
            "Epoch 79/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.8579\n",
            "Epoch 80/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.8045\n",
            "Epoch 81/100\n",
            "240/240 [==============================] - 0s 985us/step - loss: 20.7920\n",
            "Epoch 82/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.7600\n",
            "Epoch 83/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.6023\n",
            "Epoch 84/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.7738\n",
            "Epoch 85/100\n",
            "240/240 [==============================] - 0s 968us/step - loss: 20.8130\n",
            "Epoch 86/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.5807\n",
            "Epoch 87/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.6797\n",
            "Epoch 88/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.5995\n",
            "Epoch 89/100\n",
            "240/240 [==============================] - 0s 981us/step - loss: 20.7089\n",
            "Epoch 90/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.7518\n",
            "Epoch 91/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.5908\n",
            "Epoch 92/100\n",
            "240/240 [==============================] - 0s 985us/step - loss: 20.7109\n",
            "Epoch 93/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.6903\n",
            "Epoch 94/100\n",
            "240/240 [==============================] - 0s 987us/step - loss: 20.7018\n",
            "Epoch 95/100\n",
            "240/240 [==============================] - 0s 997us/step - loss: 20.6662\n",
            "Epoch 96/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.5568\n",
            "Epoch 97/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.8178\n",
            "Epoch 98/100\n",
            "240/240 [==============================] - 0s 989us/step - loss: 20.6235\n",
            "Epoch 99/100\n",
            "240/240 [==============================] - 0s 1ms/step - loss: 20.6174\n",
            "Epoch 100/100\n",
            "240/240 [==============================] - 0s 993us/step - loss: 20.6274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x258264dc070>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrHNTLRLjO88"
      },
      "source": [
        "#### Teil 4 - Durchführung der Prediction und evaluieren des Modells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWJRIgL1rq9K",
        "outputId": "0298bbdb-8e8f-4bc0-f717-26c5919680c8"
      },
      "source": [
        "y_pred = knnr.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[432.4  431.23]\n",
            " [457.71 460.01]\n",
            " [461.35 461.14]\n",
            " ...\n",
            " [468.24 473.26]\n",
            " [442.72 438.  ]\n",
            " [461.18 463.28]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF7_tN87uBgx",
        "outputId": "df6e8110-3fe6-44d1-e21b-17fedbb25a43"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "score = r2_score(y_test,y_pred, multioutput='variance_weighted')\n",
        "print('Der r2 Score ohne Skalierung ist 0.9159165151046462')\n",
        "print('Der r2 Score mit Skalierung ist',score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Der r2 Score ohne Skalierung ist 0.9159165151046462\n",
            "Der r2 Score mit Skalierung ist 0.9320946784214379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX-ICYbywWLH"
      },
      "source": [
        "Wir sehen mittels des Bestimmtheitsmaß (r2 Scores), dass das Resultat mit Skalierung der Daten um 0.02 Prozent besser ausfällt als ohne Skalierung. Es lohnt sich also in einen KNN die Daten zu skalieren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq9MIqn4Rlnn"
      },
      "source": [
        "### Convolutional Neural Networks (CNN)\n",
        "\n",
        "Quelle: [Wikipedia](https://de.wikipedia.org/wiki/Convolutional_Neural_Network)\n",
        "\n",
        "Ein Convolutional Neural Network (CNN oder ConvNet), zu Deutsch \"faltendes neuronales Netzwerk“, ist ein künstliches neuronales Netz. Es handelt sich um ein von biologischen Prozessen inspiriertes Konzept im Bereich des maschinellen Lernens[1]. Convolutional Neural Networks finden Anwendung in zahlreichen Technologien der künstlichen Intelligenz, vornehmlich bei der maschinellen Verarbeitung von Bild- oder Audiodaten.\n",
        "\n",
        "Grundsätzlich besteht die Struktur eines klassischen Convolutional Neural Networks aus einem oder mehreren **Convolutional Layer**, gefolgt von einem **Pooling Layer**. Diese Einheit kann sich prinzipiell beliebig oft wiederholen, bei ausreichend Wiederholungen spricht man dann von Deep Convolutional Neural Networks, die in den Bereich Deep Learning fallen. Nach den genannten Layers folgt ein **Flattening** und danach werden die Resultate aus dem Conv-Net in ein **Fully-Connected Neural Network** übertragen in welchem die eigentliche Klassifkation stattfindet.\n",
        "\n",
        "<img src='https://miro.medium.com/max/758/1*-Bo5d1RCDWu9MeHluC5hfw.png' \n",
        "width=600>\n",
        "\n",
        "Die Daten durchlaufen das CNN in folgenden Schritten:\n",
        "\n",
        "<img src='https://miro.medium.com/max/411/1*XFLitGL4Q54PjXqx2pFztg.png' width=200>\n",
        "\n",
        "Innerhalb der Conv- und Polling-Layer besteht ein **Feature Detector** (auch Kernel oder Filter genannt) der Schrittweise durch die Matrix ders Input Images schreitet und seine Resultate in eine sogenannte **Feature Map** schreibt. \n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%208%20-%20Deep%20Learning/CNN_function_1.jpg?raw=true' width=500>\n",
        "\n",
        "Wichtig ist hierbei noch zu erwähnen, dass es noch einen **ReLu Layer** gibt.\n",
        "ReLU wird mit einer elementweise Operation (pro Pixel angewendet) und ersetzt alle negativen Pixelwerte in der Feature Map durch Null. Der Zweck von ReLU besteht darin, Nichtlinearität in unser ConvNet einzuführen, da die meisten Daten der realen Welt, die unser ConvNet lernen soll, nichtlinear sind (Faltung ist eine lineare Operation - elementweise Matrixmultiplikation und -addition, so dass wir die Nichtlinearität durch Einführung einer nichtlinearen Funktion wie ReLU berücksichtigen).\n",
        "\n",
        "**Pooling**\n",
        "\n",
        "Im folgenden Schritt, dem Pooling, werden überflüssige Informationen verworfen. Zur Objekterkennung in Bildern etwa ist die exakte Position einer Kante im Bild von vernachlässigbarem Interesse – die ungefähre Lokalisierung eines Features ist hinreichend. Es gibt verschiedene Arten des Poolings. Mit Abstand am stärksten verbreitet ist das Max-Pooling, wobei aus jedem 2 × 2 Quadrat aus Neuronen des Convolutional Layers nur die Aktivität des aktivsten (daher \"Max\") Neurons für die weiteren Berechnungsschritte beibehalten wird; die Aktivität der übrigen Neuronen wird verworfen. Trotz der Datenreduktion (im Beispiel 75 %) verringert sich in der Regel die Performance des Netzwerks nicht durch das Pooling. Im Gegenteil, es bietet einige signifikante Vorteile:\n",
        "\n",
        "* Verringerter Platzbedarf und erhöhte Berechnungsgeschwindigkeit\n",
        "* Daraus resultierende Möglichkeit zur Erzeugung tieferer Netzwerke, die komplexere Aufgaben lösen können\n",
        "* Automatisches Wachstum der Größe der rezeptiven Felder in tieferen Convolutional Layers (ohne dass dafür explizit die Größe der Faltungsmatrizen erhöht werden müsste)\n",
        "* Präventionsmaßnahme gegen Overfitting\n",
        "\n",
        "Das nachfolgende Bild zeigt ein Max pooling mit 2x2 Filter und Schrittgrösse = 2. Die Schrittgrösse gibt an, wie viele Pixel der Filter pro Operation verschiebt.\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png' width=450>\n",
        "\n",
        "Wir können bei obigen Beispiel gut erkennen, dass der Filter lediglich die grösste Pixelzahl überträgt. Nachfolgenden eine kurze Animation dieser Operation:\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/1/19/2D_Convolution_Animation.gif'>\n",
        "\n",
        "**Flattening**\n",
        "\n",
        "Ist die Operation, welche durchgeführt werden muss um die Resultate aus dem Conv-Net ins FKNN zu übertragen. Beim Flattening werden die Resultate aus der Pooling Feature Map ins einen 1D-Array übertragen.\n",
        "\n",
        "<img src='https://miro.medium.com/max/758/1*oJSpK_KcHUTIZxniOQ_vOQ.png' width=500>\n",
        "\n",
        "Die genaue Funktionsweise eines CNN kann aus einem sehr empfehlenswerten Medium Artikel von Amir Ali entnommen werden.\n",
        "\n",
        "https://medium.com/machine-learning-researcher/convlutional-neural-network-cnn-2fc4faa7bb63"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "831ESsONXslF"
      },
      "source": [
        "#### Funktionsweise eines CNN\n",
        "\n",
        "Um es schon einmal vorweg zu nehmen. Das CNN arbeitet in etwa gleich wie Menschen Bilder wahrnehmen. Schauen wir uns mal folgende Zeichnung an:\n",
        "\n",
        "<img src='https://image.freepik.com/vektoren-kostenlos/pferd-koepfe-konturen_23-2147501777.jpg' width=200>\n",
        "\n",
        "Unser Hirn regestriert auf den ersten Blick, dass es sich dabei um Pferdeköpfe handelt. Obwohl wir nur Striche sehen kann unser Hirn die Konturen sofort zuordnen. Nachchfolgend noch ein weiteres Bild:\n",
        "\n",
        "<img src='https://images.derstandard.at/img/2012/10/22/1350285669783.jpg?w=600&s=b6d88952196b9cc5f92b0c5df03bece9' width=300>\n",
        "\n",
        "Auch wenn wir nur das linke sehr unscharfe Bild betrachten würden, würde unser Hirn sofort ein Gebäude identifizieren. Diese Beispiele zeigen ungefähr wie unser Hirn bei der Erkennung von Bildern vorgeht. Anstelle sich auf Details zu fokussieren beschränkt es sich auf die Wahrnehmung der Konturen. So ähnlich arbeitet der CNN-Algorithmus auch. \n",
        "\n",
        "Eine Maschine betrachtet ein Bild nur mittels Zahlenwerte.\n",
        "\n",
        "\n",
        "Ein wirklich coole Art ein CNN zu verstehen ist mittels des Tools auf der folgenden Seite:\n",
        "\n",
        "https://www.cs.ryerson.ca/~aharley/vis/conv/flat.html\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oKCtgli493R"
      },
      "source": [
        "#### Teil 1 - Datenaufbereitung (Data-Preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gdpDGRR-Lst"
      },
      "source": [
        "#### Datenimport"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCYW6BKF-Qv8"
      },
      "source": [
        "import tensorflow as tf\n",
        "# ImageDataGenerator wird für Aufbereitung der Bilder benötigt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mq_D2tra_oJU",
        "scrolled": true,
        "outputId": "89b51bcf-5d28-4167-b1bf-969b944dfca9"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVqRBbq7-urJ"
      },
      "source": [
        "#### GPU Support im Tensorflow\n",
        "\n",
        "Wenn man über eine Grafikkarte von NVIDIA verfügt, dann kann diese im Rahmen des Trainings eingesetzt werden. \n",
        "Im nachfolgenden Link sind die erforderlichen Schritte um die GPU für Tensorflow zu nutzen:\n",
        "\n",
        "https://www.tensorflow.org/install/gpu\n",
        "\n",
        "https://www.tensorflow.org/guide/gpu\n",
        "\n",
        "Sehr zu empfehlen ist dieser Link:\n",
        "\n",
        "https://shawnhymel.com/1961/how-to-install-tensorflow-with-gpu-support-on-windows/\n",
        "\n",
        "Hinweis: Auch noch conda install pillow durchführen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQgcyWnL-urJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49dc4795-9a32-4087-b4da-63c4e4f4c897"
      },
      "source": [
        "# Prüfen ob eine GPU verfügbar ist\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4BWNjez__gx"
      },
      "source": [
        "#### Aufbereitung Trainingdatensatz\n",
        "\n",
        "Damit wir ein Overfitting verhindern können, müssen wir die Bilder des Trainingsdatensatzes etwas transformieren. Das Ziel einer solchen Transformation ist es die Bilder etwas zu manipulieren um es dem Algorithmus nicht allzu leicht zu machen. So werden Bilder beispielweise verpixelt, verdreht, verzerrt usw. Diese Transformation wird auch **Image Augmentation** genannt. Eines der besten Tools um eine Image Augmentation durchzuführen ist das Keras Modul **ImageDataGenerator**.\n",
        "\n",
        "Ein guter Überblick über die Image Augmentation mittels ImageDataGenerator (Keras) findet man auf dem Blog [Yumi's](https://fairyonice.github.io/Learn-about-ImageDataGenerator.html).\n",
        "\n",
        "**Wichtig!** Wir führen die Transformierung nur auf den Trainingsdatensatz nicht auf dem Testdatensatz aus. Der Grund dafür ist sehr einfach. Der Testdatensatz repräsentiert die richitge Welt und in der richtigen Welt kommen die Bilder nicht immer im gleichen Format daher.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSGdRJOw-urJ"
      },
      "source": [
        "# Default Laufwerk definieren\n",
        "import os\n",
        "os.chdir('D:\\\\GithubReps\\my_datascience\\\\udemy\\mlaz\\\\Part 8 - Deep Learning\\\\')\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7haMMFk-v7xc"
      },
      "source": [
        "train_datagen = ImageDataGenerator( #Wir erstellen eine Funktion mit IDG\n",
        "        # Die Pixelwerte jedes einzelnen Bilds wird durch 255 geteilt bzw. zwischen 0 und 1 skaliert.\n",
        "        rescale=1./255,  \n",
        "        # Die nachfolgenden Attribute haben mit der Image Augmentation zu tun.\n",
        "        shear_range=0.2, # Verzehrt die Bilder\n",
        "        zoom_range=0.2, # Zoomed in die Bilder\n",
        "        horizontal_flip=True) # Dreht Bilder\n",
        "\n",
        "# Diese Klasse verbindet train_datagen mit dem Datensatz.\n",
        "training_set = train_datagen.flow_from_directory( \n",
        "        'Section 40 - Convolutional Neural Networks (CNN)/Python/dataset/training_set',\n",
        "        target_size=(64, 64), # Grösse der Bilder welche ins CNN gefeedet werden\n",
        "        batch_size=32,\n",
        "        class_mode='binary') # Wir haben nur zwei Werte Dog oder Cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gz0IuR8AKuZ"
      },
      "source": [
        "##### Aufbereitung Testdatensatz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR58g62-votp"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        'Section 40 - Convolutional Neural Networks (CNN)/Python/dataset/test_set',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PmR1sBrAQAR"
      },
      "source": [
        "#### Teil 2 - Aufbau des CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_SQuvOiAXzV"
      },
      "source": [
        "#### Initialisierung des CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SVvjEpuw_Kz"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZx1moJaAg1h"
      },
      "source": [
        "##### Schritt 1 - Convolution (Falten)\n",
        "\n",
        "Wir bauen in diese Schritt den ersten ConvLayer aus dem gleichen Keras Objekt Layers. Diese Klasse heisst Conv2D und lässt grundsätzlich bereits erwähnen welche Art von Input in diesen CNN verarbeitet werden. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHain8J7xUcS"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(\n",
        "    filters=32, # Output Filters im CNN bzw. Anzhal Feature Detectors\n",
        "    kernel_size=3, # Hier definieren wir die Grösse des Feature Detectors 3x3\n",
        "    activation='relu', # Wie auch bereits im KNN verwenden wir auch hier ReLu\n",
        "    # Input Format wie oben spezifiziert. Da es sich um Farbfotos handelt definieren wir 3 (RGB)\n",
        "    # bei Schwarz-Weiss Fotos wären es 1\n",
        "    input_shape=[64,64,3])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXGTHgQAAvlm"
      },
      "source": [
        "##### Schritt 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlrsLvk1yjKk"
      },
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(\n",
        "    pool_size=2, # Die Pooling Grösse ist 2 x 2\n",
        "    strides=2)) # Hier definieren wir wieviel Slides das Pooling-Frame nach rechts macht."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkjLoIaYAyuq"
      },
      "source": [
        "###### Hinzufügen eines zweiten Conv-Layers\n",
        "\n",
        "Im zweiten Layer definieren wir die gleichen Attribute wie auch schon im Ersten mit Ausnahme mit dem Input-Shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xJdWxCpzhCQ"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R02CHTewBBqi"
      },
      "source": [
        "##### Schritt 3 - Flattening\n",
        "\n",
        "Hier transponieren wird die Resultate aus den Conv- und Polling Schichten in einen 1D Array, damit wir ihn dem NN übergeben können"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt_094D6zw70"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5AgKuBDBJzp"
      },
      "source": [
        "##### Schritt 4 - Full Connection\n",
        "\n",
        "Hier definieren wir das FKNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mba-ZvwO0AsM"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(\n",
        "    units=128, # Da wir eine Input Shape von 64x64 haben nehmen wir 128 \n",
        "    activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VMmHy6ZBS6n"
      },
      "source": [
        "##### Schritt 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8DiQy5Z0uH4"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(\n",
        "    units=1, # In einem Binary Classifier benötigen wir nur ein Output\n",
        "    activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDz5-aUVBaTl"
      },
      "source": [
        "#### Teil 3 - Trainieren des CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ_ob8VgBrDl"
      },
      "source": [
        "#### Kompilieren des CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij7cD_-X1eHZ"
      },
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9bh8SbJBzB0"
      },
      "source": [
        "#### Trainieren des CNN und Evaluation mittels Testdatensatzes\n",
        "\n",
        "Im Unterschied zum KNN trainieren wir hier zuerst den Trainingsdatensatz und validieren diesen direkt gegenüber den Testdatensatz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxT9MNUO1xzZ",
        "scrolled": true
      },
      "source": [
        "cnn.fit(\n",
        "    x = training_set, \n",
        "    validation_data=test_set, \n",
        "    epochs = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvKTgCpACR5g"
      },
      "source": [
        "#### Teil 4 - Erstellung einer Vorhersage auf Basis einer einzelnen Beobachtung"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmfXWTz22lAd"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "test_image = image.load_img('Section 40 - Convolutional Neural Networks (CNN)/Python/dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64,64))\n",
        "test_image = image.img_to_array(test_image) # Hier wandeln wir das Bild in einen Array um\n",
        "test_image = np.expand_dims(test_image, axis=0) # Wir müssen das Image noch in die richtige Dimension bringen.\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices \n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvrA5-cI6LEk"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvQvBZWMo2g3"
      },
      "source": [
        "### Recurrent Neural Networks (RNN)\n",
        "\n",
        "Quelle: [Wikipedia](https://de.wikipedia.org/wiki/Rekurrentes_neuronales_Netz)\n",
        "\n",
        "Als rekurrente bzw. rückgekoppelte neuronale Netze bezeichnet man neuronale Netze, die sich im Gegensatz zu den Feedforward-Netzen durch Verbindungen von Neuronen einer Schicht zu Neuronen derselben oder einer vorangegangenen Schicht auszeichnen. Im Gehirn ist dies die bevorzugte Verschaltungsweise neuronaler Netze, insbesondere im Neocortex. In künstlichen neuronalen Netzen wird die rekurrente Verschaltung von Modellneuronen benutzt, um zeitlich codierte Informationen in den Daten zu entdecken. Beispiele für solche rekurrenten neuronalen Netze sind das Elman-Netz, das Jordan-Netz, das Hopfield-Netz sowie das vollständig verschaltete neuronale Netz.\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/4/4c/Neuronal-Networks-Feedback.png' width=400>\n",
        "\n",
        "Rekurrente Netze lassen sich folgendermaßen unterteilen:\n",
        "\n",
        "* Bei einer direkten Rückkopplung (englisch direct feedback) wird der eigene Ausgang eines Neurons als weiterer Eingang genutzt.\n",
        "* Die indirekte Rückkopplung (englisch indirect feedback) verbindet den Ausgang eines Neurons mit einem Neuron der vorhergehenden Schichten.\n",
        "* Die seitliche Rückkopplung (englisch lateral feedback) verbindet den Ausgang eines Neurons mit einem anderen Neuron derselben Schicht.\n",
        "* Bei einer vollständigen Verbindung hat jeder Neuronenausgang eine Verbindung zu jedem anderen Neuron\n",
        "\n",
        "#### Long Short Term Memory (LSTM) \n",
        "\n",
        "Eine der bekanntesten RNN Architekturen ist das Long Short Term Memory (LSTM) Netzwerk. Hierbei werden zusätzliche Parameter darauf trainiert, den Input und Output des Netzes für die nächste Iteration zu speichern oder zu verwerfen, um auf diese Weise zusätzliche Informationen zur Vorhersage für den nächsten Sequenzabschnitt zur Verfügung zu stellen. So können zuvor aufgetretene Signale über die zeitliche Dimension der Daten gespeichert und später verwendet werden. LSTMs werden aktuell sehr erfolgreich im NLP (Natural Language Processing) angewendet, um Übersetzungen von Texten anzufertigen oder Chat-Bots zu trainieren. Weiterhin eignen sich RNNs für die Modellierung von Sequenzen im Allgemeinen, bspw. bei der Zeitreihenprognose oder aber auch für Next Best Action Empfehlungen.\n",
        "\n",
        "Empfehlenswerte Beiträge zur Vertiefung von LSTM sind auf [Cola's Blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) und [Andrej Karpathy blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) zu finden.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWpOQYXg6Qol"
      },
      "source": [
        "#### Teil 1 - Datenaufbereitung (Data-Preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axkozIG67ITT"
      },
      "source": [
        "##### Import der Python Libs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4R7Vq5J7TjT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1y2SWHz73VS"
      },
      "source": [
        "##### Datenimport"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_3YODYU7iTr"
      },
      "source": [
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%201%20-%20Supervised%20Deep%20Learning/Part%203%20-%20Recurrent%20Neural%20Networks/Google_Stock_Price_Train.csv'\n",
        "dataset_train = pd.read_csv (datloc)\n",
        "training_set = dataset_train.iloc[:,1:2].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "QwCF5C488M6H",
        "outputId": "686ac389-d2ed-4218-aeb0-512ee2de3405"
      },
      "source": [
        "dataset_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/3/2012</td>\n",
              "      <td>325.25</td>\n",
              "      <td>332.83</td>\n",
              "      <td>324.97</td>\n",
              "      <td>663.59</td>\n",
              "      <td>7,380,500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/4/2012</td>\n",
              "      <td>331.27</td>\n",
              "      <td>333.87</td>\n",
              "      <td>329.08</td>\n",
              "      <td>666.45</td>\n",
              "      <td>5,749,400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/5/2012</td>\n",
              "      <td>329.83</td>\n",
              "      <td>330.75</td>\n",
              "      <td>326.89</td>\n",
              "      <td>657.21</td>\n",
              "      <td>6,590,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/6/2012</td>\n",
              "      <td>328.34</td>\n",
              "      <td>328.77</td>\n",
              "      <td>323.68</td>\n",
              "      <td>648.24</td>\n",
              "      <td>5,405,900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/9/2012</td>\n",
              "      <td>322.04</td>\n",
              "      <td>322.29</td>\n",
              "      <td>309.46</td>\n",
              "      <td>620.76</td>\n",
              "      <td>11,688,800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>12/23/2016</td>\n",
              "      <td>790.90</td>\n",
              "      <td>792.74</td>\n",
              "      <td>787.28</td>\n",
              "      <td>789.91</td>\n",
              "      <td>623,400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>12/27/2016</td>\n",
              "      <td>790.68</td>\n",
              "      <td>797.86</td>\n",
              "      <td>787.66</td>\n",
              "      <td>791.55</td>\n",
              "      <td>789,100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>12/28/2016</td>\n",
              "      <td>793.70</td>\n",
              "      <td>794.23</td>\n",
              "      <td>783.20</td>\n",
              "      <td>785.05</td>\n",
              "      <td>1,153,800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>12/29/2016</td>\n",
              "      <td>783.33</td>\n",
              "      <td>785.93</td>\n",
              "      <td>778.92</td>\n",
              "      <td>782.79</td>\n",
              "      <td>744,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>12/30/2016</td>\n",
              "      <td>782.75</td>\n",
              "      <td>782.78</td>\n",
              "      <td>770.41</td>\n",
              "      <td>771.82</td>\n",
              "      <td>1,770,000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1258 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date    Open    High     Low   Close      Volume\n",
              "0       1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
              "1       1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
              "2       1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
              "3       1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
              "4       1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n",
              "...          ...     ...     ...     ...     ...         ...\n",
              "1253  12/23/2016  790.90  792.74  787.28  789.91     623,400\n",
              "1254  12/27/2016  790.68  797.86  787.66  791.55     789,100\n",
              "1255  12/28/2016  793.70  794.23  783.20  785.05   1,153,800\n",
              "1256  12/29/2016  783.33  785.93  778.92  782.79     744,300\n",
              "1257  12/30/2016  782.75  782.78  770.41  771.82   1,770,000\n",
              "\n",
              "[1258 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cohLCZ_49c_h"
      },
      "source": [
        "##### Skaliering der Features\n",
        "\n",
        "Der Datensatz den wir in diesem Beispiel verwenden beinhaltet den Google Aktienkurs von 2012 - 2016 genauer gesagt der jeweilige Kurs bei Eröffnung des Börsentags. Das Feature \"Open\" verfügt über einen minimalen und maximalen Wert. Nun stellt sich die Frage welche Skalierung wir für unser RNN verwendet sollen:\n",
        "\n",
        "**MinMax Scaling**\n",
        "\n",
        "<img src='https://chrisalbon.com/images/machine_learning_flashcards/MinMax_Scaling_print.png' width='500'>\n",
        "\n",
        "Quelle: Chris Albon\n",
        "\n",
        "**Standard Scaling**\n",
        "\n",
        "<img src='https://chrisalbon.com/images/machine_learning_flashcards/Standardization_print.png' width='500'>\n",
        "\n",
        "Quelle: Chris Albon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e4PEYdg9kzN"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sc = MinMaxScaler(feature_range = (0,1)) \n",
        "training_set_scaled = sc.fit_transform(training_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2gPT8Ts_78d"
      },
      "source": [
        "# Erstellung einer Datenstruktur mit 60 Zeitschritten und 1 Output\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "# Wir wollen die 60 Aktienkurse der letzen 60 Tag voraussagen, weshalb wir erst bei 60 Anfangen \n",
        "for i in range (60, 1258):\n",
        "  X_train.append(training_set_scaled[i-60:i, 0])\n",
        "  y_train.append(training_set_scaled[i, 0])\n",
        "\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl_LR8EqCdYF"
      },
      "source": [
        "# RNN erwartet eine 3D Shape der Daten\n",
        "# Reshaping die Daten\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzS_YSuXH603",
        "outputId": "e0e9dc81-4e44-412e-b590-3cd005c8d89e"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1198, 60, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDE7L3tq6T1O"
      },
      "source": [
        "#### Teil 2 - Aufbau des RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax5H8MqyIXAX"
      },
      "source": [
        "# Initialisierung RNN\n",
        "regressor = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4ZhVctiKcWM"
      },
      "source": [
        "# Hinzufügen des ersten LSTM layers mit Dropout regularisation\n",
        "regressor.add(tf.keras.layers.LSTM(units = 50, return_sequences=True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(tf.keras.layers.Dropout(0.2)) # 20% der Neuronen werden ignoriert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOec_i7IN426"
      },
      "source": [
        "# Hinzufügen des zweiten LSTM layers mit Dropout regularisation\n",
        "regressor.add(tf.keras.layers.LSTM(units = 50, return_sequences=True)) # Wir brauchen hier die Input Form nicht mehr zu definieren.\n",
        "regressor.add(tf.keras.layers.Dropout(0.2)) # 20% der Neuronen werden ignoriert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bl8A8KPO9aG"
      },
      "source": [
        "# Hinzufügen des dritten LSTM layers mit Dropout regularisation\n",
        "regressor.add(tf.keras.layers.LSTM(units = 50, return_sequences=True)) # Wir brauchen hier die Input Form nicht mehr zu definieren.\n",
        "regressor.add(tf.keras.layers.Dropout(0.2)) # 20% der Neuronen werden ignoriert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BH-aREGPAoK"
      },
      "source": [
        "# Hinzufügen des vierten LSTM layers mit Dropout regularisation\n",
        "regressor.add(tf.keras.layers.LSTM(units = 50)) # Wir brauchen hier die Input Form nicht mehr zu definieren.\n",
        "regressor.add(tf.keras.layers.Dropout(0.2)) # 20% der Neuronen werden ignoriert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIwPU0sRPmk-"
      },
      "source": [
        "# Hinzufügen des Output Layers\n",
        "regressor.add(tf.keras.layers.Dense(units=1)) # Wir haben nur ein Wert der ausgegeben werden kann deshalb nur ein Unit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFIo50vLQgnZ"
      },
      "source": [
        "# Kompilierung des RNNs\n",
        "regressor.compile(optimizer='adam', loss='mean_squared_error') # Für RNNs kann auch RMSprop verwendet werden\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UBNn1stRzJP"
      },
      "source": [
        "# Fitting RNN zum Trainigssatz\n",
        "regressor.fit(X_train,y_train, epochs = 100, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_av3gBbs6hYg"
      },
      "source": [
        "#### Teil 3 - Predictions erstellen und Visualisierung der Resultate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xU1UV_UV6hJ"
      },
      "source": [
        "# Download des echten Google Aktienkurses 2017\n",
        "\n",
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%201%20-%20Supervised%20Deep%20Learning/Part%203%20-%20Recurrent%20Neural%20Networks/Google_Stock_Price_Test.csv'\n",
        "dataset_test = pd.read_csv (datloc)\n",
        "real_stock_price = dataset_test.iloc[:,1:2].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gEL1qIfW3fF"
      },
      "source": [
        "# Getting the predicted stock price of 2017\n",
        "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']),axis=0)\n",
        "inputs = dataset_total[len(dataset_total)-len(dataset_test)-60:].values\n",
        "inputs = inputs.reshape(-1,1)\n",
        "inputs = sc.transform(inputs)\n",
        "\n",
        "# Erstellung einer Datenstruktur mit 60 Zeitschritten und 1 Output\n",
        "X_test = []\n",
        "\n",
        "# Wir wollen die 60 Aktienkurse der letzen 60 Tag voraussagen, weshalb wir erst bei 60 Anfangen \n",
        "for i in range (60, 80):\n",
        "  X_test.append(inputs[i-60:i, 0])\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# RNN erwartet eine 3D Shape der Daten\n",
        "# Reshaping die Daten\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "predicted_stock_price = regressor.predict(X_test)\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Yjp-dIpx9OiZ",
        "outputId": "fc913356-86cf-4e62-d53d-edd3183b5f90"
      },
      "source": [
        "# Visualisieurung der Resultate\n",
        "\n",
        "plt.plot(real_stock_price, color='red', label = 'Real Google Stock Price')\n",
        "plt.plot(predicted_stock_price, color='blue', label = 'Predicted Google Stock Price')\n",
        "plt.title('Google Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Google Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nozBHIZJRahA"
      },
      "source": [
        "## Unsupervised Deep Learning\n",
        "\n",
        "Nachfolgende werden Deep Learning Modelle vorgestellt, welche sich für das unüberwachte Lernen eignen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEM6FSu3T-7c"
      },
      "source": [
        "### Self Organizing Maps (SOM)\n",
        "\n",
        "Bei SOM geht es in erster Linie darum Merkmale (Features) zu reduzieren bzw. die wesentlichsten Features zu extrahieren. SOM wird oft im Bereich Data-Mining verwendet. Das Vorgehen dabei ist vergleichbar mit der uns bereits bekannten Clustering-Methode [K-Means](https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%204%20-%20Clustering/Section%2024%20-%20K-Means%20Clustering/Python/k_means_clustering.ipynb). \n",
        "\n",
        "#### Wie funktionieren SOMs\n",
        "\n",
        "In nachfolgenden Bild wird ein SOM-Architektur repräsentiert. Auch wenn diese wie eine KNN aussieht gibt es doch den einen oder anderen grösseren Unterschied.\n",
        "\n",
        "<img src='https://image.slidesharecdn.com/nigqtyw5qqgzmjqtkbnc-signature-a8b8daa82312c33588e8ca91d8c4fc770e891e421c440e8374323d4726539ed0-poli-180817161347/95/deep-learning-az-self-organizing-maps-som-how-do-soms-learn-part-1-2-638.jpg?cb=1534525134' width=500>\n",
        "\n",
        "Eine der Unterschiede ist einerseits, dass die Neuronen über keine Aktivierungsfunktion ($\\sigma$) verfügen und die Gewichtungen ($w^x$) als Koordinaten für den Input-Space (Nodes) agieren, welche die Distanz zwischen den einzelnen Daten (Rows) berechnen. \n",
        "\n",
        "<img src='https://image.slidesharecdn.com/nigqtyw5qqgzmjqtkbnc-signature-a8b8daa82312c33588e8ca91d8c4fc770e891e421c440e8374323d4726539ed0-poli-180817161347/95/deep-learning-az-self-organizing-maps-som-how-do-soms-learn-part-1-13-638.jpg?cb=1534525134' width=500>\n",
        "\n",
        "Das Training einer SOM besteht aus folgenden Schritten:\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/dlaz/Volume%202%20-%20Unsupervised%20Deep%20Learning/Self_Organizing_Maps/Trainingsteps_SOM.jpeg?raw=true' width=600>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpuPiYuHIT8P"
      },
      "source": [
        "#### Beispiel SOM-Modell\n",
        "\n",
        "Nachfolgend bauen wir ein SOM-Modell mit Hilfe dessen wir Kartenbetrugsfälle entdecken können. Dabei wird uns SOM helfen die Kreditkartenkunden zu identfizieren, welche womöglich betrogen haben. SOM wird dabei ein Muster (Outliers/Ausreisser) in den Daten erkennen und die Kunden bestimmten Segementen zuteilen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XXOq4zBJLFm"
      },
      "source": [
        "# Import Python-Libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9DSEn7HJm_5"
      },
      "source": [
        "# Import Datensatz\n",
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%202%20-%20Unsupervised%20Deep%20Learning/Self_Organizing_Maps/Credit_Card_Applications.csv'\n",
        "dataset = pd.read_csv(datloc)\n",
        "\n",
        "X = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWaGaOpQLI_A"
      },
      "source": [
        "Die einzelnen Zeilen (Rows) stellen ein Set an Gewichtungen innerhalb der SOM dar. D.h. jedes der 14 Features des Vektor CustomerID hat ein Gewicht. \n",
        "\n",
        "Das letzte Feature Class zeigt, ob der Kreditantrag genehmigt (1) oder abgelehnt (0) wurde. Wir trennen oben zwar das Feature Class vom Rest der Daten aber Vorsicht es handelt sich dabei nicht um ein eigendliches Label (unabhängige Variable) bzw. wir befinden uns nicht im Supervised Learning. Wir tun das nur um die Kunden welche über einen genehmigten Kreditantrag verfügen von den Restlichen zu trennen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "j1m3lDlLJ7fo",
        "outputId": "9901d982-0d81-4654-a327-4eabaefb7f4d"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>A9</th>\n",
              "      <th>A10</th>\n",
              "      <th>A11</th>\n",
              "      <th>A12</th>\n",
              "      <th>A13</th>\n",
              "      <th>A14</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15776156</td>\n",
              "      <td>1</td>\n",
              "      <td>22.08</td>\n",
              "      <td>11.46</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.585</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>1213</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15739548</td>\n",
              "      <td>0</td>\n",
              "      <td>22.67</td>\n",
              "      <td>7.00</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.165</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15662854</td>\n",
              "      <td>0</td>\n",
              "      <td>29.58</td>\n",
              "      <td>1.75</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>280</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15687688</td>\n",
              "      <td>0</td>\n",
              "      <td>21.67</td>\n",
              "      <td>11.50</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15715750</td>\n",
              "      <td>1</td>\n",
              "      <td>20.17</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>1.960</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>60</td>\n",
              "      <td>159</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CustomerID  A1     A2     A3  A4  A5  ...  A10  A11  A12  A13   A14  Class\n",
              "0    15776156   1  22.08  11.46   2   4  ...    0    1    2  100  1213      0\n",
              "1    15739548   0  22.67   7.00   2   8  ...    0    0    2  160     1      0\n",
              "2    15662854   0  29.58   1.75   1   4  ...    0    1    2  280     1      0\n",
              "3    15687688   0  21.67  11.50   1   5  ...   11    1    2    0     1      1\n",
              "4    15715750   1  20.17   8.17   2   6  ...   14    0    2   60   159      1\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMjzjScR2jun"
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "X = sc.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCVn_ywy36eX",
        "outputId": "ec8076cb-9a59-4fde-b3d0-35a000d07b8e"
      },
      "source": [
        "# Für das Training einer SOM benötigen wir noch ein neues Python Modul\n",
        "!pip install minisom"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: minisom in /usr/local/lib/python3.6/dist-packages (2.2.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIs-Rhp13Eqe"
      },
      "source": [
        "# Training the SOM\n",
        "from minisom import MiniSom\n",
        "som = MiniSom(x = 10, y = 10, input_len= 15, sigma=1.0, learning_rate=0.5)\n",
        "som.random_weights_init(X)\n",
        "som.train_random(data = X, num_iteration= 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "g1Qe_Y_-9VCA",
        "outputId": "ffbb40f2-c6ef-48e7-8279-ae390bc0934e"
      },
      "source": [
        "# Visualizing the results\n",
        "from pylab import bone, pcolor, colorbar, plot, show\n",
        "bone()\n",
        "pcolor(som.distance_map().T)\n",
        "colorbar()\n",
        "markers = ['o','s']\n",
        "colors = ['r', 'g']\n",
        "for i,x in enumerate(X): # i = Index, x = Vektoren\n",
        "  w = som.winner(x) # Hiermit ziehen wir die Gewinnner aus der SOM\n",
        "  plot(w[0] + 0.5,\n",
        "       w[1] + 0.5,\n",
        "       markers[y[i]],\n",
        "       markeredgecolor = colors[y[i]],\n",
        "       markerfacecolor = 'None',\n",
        "       markersize = 10,\n",
        "       markeredgewidth = 2) \n",
        "show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hWLMLgCKR1V"
      },
      "source": [
        "# Finden der Betrugsfälle\n",
        "mappings = som.win_map(X)\n",
        "frauds = np.concatenate((mappings[(6,8)], mappings[(8,8)]),axis=0)\n",
        "#frauds = mappings[3,3] # Bei einzel Beobachtungen\n",
        "frauds = sc.inverse_transform(frauds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juZ8CUW-6v0B",
        "outputId": "0e2db834-ee2a-4628-bad7-32857d3645aa"
      },
      "source": [
        "print('Kunden.IDs unter Betrugsverdacht')\n",
        "for i in frauds[:, 0]:\n",
        "  print(int(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kunden.IDs unter Betrugsverdacht\n",
            "15593694\n",
            "15781574\n",
            "15766183\n",
            "15808662\n",
            "15684722\n",
            "15772329\n",
            "15734649\n",
            "15646082\n",
            "15717629\n",
            "15757188\n",
            "15604536\n",
            "15635598\n",
            "15647191\n",
            "15776545\n",
            "15792107\n",
            "15623369\n",
            "15667588\n",
            "15793896\n",
            "15650591\n",
            "15813192\n",
            "15633608\n",
            "15675450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4-oikffpoA-"
      },
      "source": [
        "##### Von Unsupervised zu Supervised-Learning\n",
        "\n",
        "Da wir nun mittels Unsupervised-Learning eine Muster bzw. eine abhänginge Variabele gefunden haben, können wir es nun in das Supervised-Learning übertragen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsDQ-EipKo5f"
      },
      "source": [
        "# Erstellung eine Matrix mit Merkmalen (Features)\n",
        "customers = dataset.iloc[:,1:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7WCM9t_2V_2"
      },
      "source": [
        "# Erstellen des Labels (Abhängige Variable)\n",
        "is_fraud = np.zeros(len(dataset))\n",
        "for i in range(len(dataset)):\n",
        "  if dataset.iloc[i,0] in frauds:\n",
        "    is_fraud[i] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWTO38YR5vkZ"
      },
      "source": [
        "Da wir nun die abhänigen Variablen haben, können wir diese für unser KNN verwenden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9buKnxgI7Qth",
        "outputId": "13cce447-24e4-4105-df15-ae9108a9a748"
      },
      "source": [
        "### Feature Scaling\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "customers = sc.fit_transform(customers)\n",
        "\n",
        "\"\"\"## Building the ANN\n",
        "##Import Tensorflow\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "## Initializing the ANN\n",
        "\n",
        "ann = tf.keras.models.Sequential()\n",
        "\n",
        "##Adding the input layer and the first hidden layer\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=2, kernel_initializer='uniform', activation='relu', input_dim = 15))\n",
        "\n",
        "## Adding the output layer\"\"\"\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=1, kernel_initializer='uniform',activation='sigmoid'))\n",
        "\n",
        "## Training the ANN\n",
        "## Compiling the ANN\n",
        "\n",
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "## Training the ANN on the Training set\"\"\"\n",
        "\n",
        "ann.fit(customers, is_fraud, batch_size = 1, epochs = 2)\n",
        "\n",
        "## Predicting test set results\"\"\"\n",
        "\n",
        "y_pred = ann.predict(customers)\n",
        "y_pred = np.concatenate((dataset.iloc[:, 0:1].values, y_pred), axis = 1)\n",
        "y_pred = y_pred[y_pred[:, 1].argsort()]\n",
        "\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "690/690 [==============================] - 1s 851us/step - loss: 0.5822 - accuracy: 0.9616\n",
            "Epoch 2/2\n",
            "690/690 [==============================] - 1s 905us/step - loss: 0.2017 - accuracy: 0.9672\n",
            "[[1.57442730e+07 1.22229159e-02]\n",
            " [1.55837240e+07 1.28696859e-02]\n",
            " [1.55709900e+07 1.31408870e-02]\n",
            " ...\n",
            " [1.55988020e+07 3.39036584e-01]\n",
            " [1.57723290e+07 3.39036584e-01]\n",
            " [1.57627160e+07 3.39036584e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "XHSa2v9YUd_c",
        "outputId": "c860e785-483b-435e-8f85-9f21fa0da10a"
      },
      "source": [
        "y_pred = pd.DataFrame(y_pred)\n",
        "y_pred.head(len(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15744273.0</td>\n",
              "      <td>0.012223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15583724.0</td>\n",
              "      <td>0.012870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15570990.0</td>\n",
              "      <td>0.013141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15810716.0</td>\n",
              "      <td>0.013305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15711635.0</td>\n",
              "      <td>0.013872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685</th>\n",
              "      <td>15790113.0</td>\n",
              "      <td>0.339037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>686</th>\n",
              "      <td>15708714.0</td>\n",
              "      <td>0.339037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>687</th>\n",
              "      <td>15598802.0</td>\n",
              "      <td>0.339037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688</th>\n",
              "      <td>15772329.0</td>\n",
              "      <td>0.339037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>15762716.0</td>\n",
              "      <td>0.339037</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>690 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1\n",
              "0    15744273.0  0.012223\n",
              "1    15583724.0  0.012870\n",
              "2    15570990.0  0.013141\n",
              "3    15810716.0  0.013305\n",
              "4    15711635.0  0.013872\n",
              "..          ...       ...\n",
              "685  15790113.0  0.339037\n",
              "686  15708714.0  0.339037\n",
              "687  15598802.0  0.339037\n",
              "688  15772329.0  0.339037\n",
              "689  15762716.0  0.339037\n",
              "\n",
              "[690 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oaIazJiUU5D"
      },
      "source": [
        "### Boltzmann Machines (BM)\n",
        "\n",
        "Eine Boltzmann-Maschine ist ein stochastisches künstliches neuronales Netz, das von Geoffrey Hinton und Terrence J. Sejnowski 1985 entwickelt wurde. Benannt sind diese Netze nach der [Boltzmann-Verteilung](https://de.wikipedia.org/wiki/Boltzmann-Statistik#:~:text=Mathematisch%20ist%20die%20Boltzmann%2DVerteilung,neuronale%20Netz%20der%20Boltzmann%2DMaschine). Boltzmann-Maschinen ohne Beschränkung der Verbindungen lassen sich nur sehr schwer trainieren. Beschränkt man die Verbindungen zwischen den Neuronen jedoch, lässt sich der Lernvorgang stark vereinfachen, wodurch Beschränkte Boltzmann-Maschinen sich zur Lösung praktischer Probleme einsetzen lassen.\n",
        "\n",
        "Im Gegensatz zu anderen Modellen wie KNN, CNN, RNN oder SOM gibt es bei der Boltzmann-Maschine erstens keine Richtung (bspw. Feedforward), in welcher die Daten prozessiert werden und zweites kein Output-Layer. Eine BM kann deshalb grafisch wie folgt dargestellt werden:\n",
        "\n",
        "<img src='https://miro.medium.com/max/864/1*Ere0a83PN-Rj7DF5_IVZdg.png' width=700>\n",
        "\n",
        "* Boltzmann-Maschinen verwenden neuronale Netze mit Neuronen, die nicht nur mit anderen Neuronen in anderen Schichten, sondern auch mit Neuronen innerhalb derselben Schicht verbunden sind. \n",
        "* Alles ist mit allem verbunden. Verbindungen sind bidirektionale, sichtbare Neuronen, die miteinander verbunden sind, und versteckte Neuronen, die ebenfalls miteinander verbunden sind. \n",
        "* Boltzmann Machine erwartet keine Eingabedaten, sondern generiert Daten. Neuronen erzeugen Informationen, unabhängig davon, ob sie versteckt oder sichtbar sind. \n",
        "* Bei Boltzmann Machine sind alle Neuronen gleich, es wird nicht zwischen versteckten und sichtbaren Neuronen unterschieden. Für Boltzmann Machine ist das Ganze das System und sein Erzeugungszustand des Systems.\n",
        "\n",
        "#### **Vergleichbar mit Atomkraftwerk**\n",
        "\n",
        "Geoffrey Hinton (einer der Erfinder der BM), verglich die BM mal mit einem Atomkraftwerk:\n",
        "\n",
        "<img src='https://miro.medium.com/max/1400/1*DtFQJ4e7QTtqlEStFkNruA.png' width = 600>\n",
        "\n",
        "* Nehmen wir zum Beispiel an, wir haben ein Kernkraftwerk und es gibt bestimmte Dinge, die wir im Kernkraftwerk messen können, wie die Temperatur des Sicherheitsgebäudes, wie schnell sich die Turbine dreht, der Druck in der Pumpe usw. \n",
        "* Es gibt viele Dinge, die wir nicht messen, wie die Geschwindigkeit Wind, die Feuchtigkeit des Bodens an diesem bestimmten Ort, sein sonniger Tag oder Regentag usw. Alle diese Parameter bilden zusammen ein System, sie arbeiten alle zusammen. \n",
        "* Alle diese Parameter sind binär. Wir erhalten also eine ganze Reihe von Binärzahlen, die uns etwas über den Zustand des Kraftwerks erzählen. \n",
        "* Was wir tun möchten, ist, dass wir das bemerken wollen, wenn es in einem ungewöhnlichen Zustand sein wird. Ein Zustand, der **nicht wie ein normaler Zustand** ist, den wir zuvor gesehen hatten. Und dafür möchten wir kein überwachtes Lernen verwenden. Weil wir keine Beispiele für Zustände haben, die dazu führen, dass es explodiert. \n",
        "* Wir wären eher in der Lage, dies zu erkennen, wenn es in einen solchen Zustand übergeht, ohne zuvor einen solchen Zustand gesehen zu haben. Und wir könnten dies tun, indem wir ein Modell eines normalen Zustands erstellen und feststellen, dass sich dieser Zustand von den normalen Zuständen unterscheidet. Das repräsentiert die Boltzmann-Maschine. \n",
        "* Bei der Funktionsweise dieses Systems verwenden wir unsere Trainingsdaten und geben sie als Eingabe in die Boltzmann-Maschine ein, um das System bei der Anpassung seiner Gewichte zu unterstützen. \n",
        "* Es lernt aus der Eingabe, welche Verbindungen zwischen all diesen Parametern möglich sind, wie sie sich gegenseitig beeinflussen, und wird so zu einer Maschine, die unser System repräsentiert. Mit dieser Boltzmann-Maschine können wir unser System überwachen. Die Boltzmann-Maschine lernt anhand eines guten Beispiels, wie das System im Normalzustand funktioniert.\n",
        "\n",
        "Die Boltzmann-Maschine besteht aus einem neuronalen Netzwerk mit einer Eingangsschicht und einer oder mehreren verborgenen Schichten. Die Neuronen im neuronalen Netzwerk treffen stochastische Entscheidungen darüber, ob sie ein- oder ausgeschaltet werden sollen, basierend auf den Daten, die wir während des Trainings eingeben, und der Kostenfunktion, die die Boltzmann-Maschine zu minimieren versucht. Auf diese Weise entdeckt die Boltzmann-Maschine interessante Merkmale der Daten, mit deren Hilfe die komplexen zugrunde liegenden Beziehungen und Muster in den Daten modelliert werden können. Diese Boltzmann-Maschinen verwenden neuronale Netze mit Neuronen, die nicht nur mit anderen Neuronen in anderen Schichten, sondern auch mit Neuronen innerhalb derselben Schicht verbunden sind. Das macht das Training einer unrestricted Boltzmann-Maschine sehr ineffizient. Dies ist mitunter ein Grund weshalb Boltzmann-Maschine einen nur sehr geringen kommerziellen Erfolg hat.\n",
        "\n",
        "Empfohlener Artikel: \n",
        "\n",
        "https://medium.com/datadriveninvestor/an-intuitive-introduction-of-boltzmann-machine-8ec54980d789"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUaueMeGfGcJ"
      },
      "source": [
        "#### Restricted Boltzmann Machine (RBM)\n",
        "\n",
        "Wie oben bereits erwähnt, stellt die dichte Konnektivität auch ein Problem dar. Um dieses zu Umgehen wurde BM dahingehen eingeschränkt, dass weder die Hidden noch die Visible Nodes untereinander verbunden sind. Daraus entsteht die Restricted Bolzmann Machine (RBM).\n",
        "\n",
        "<img src='https://miro.medium.com/max/1163/1*LoeBW9Stm6HjK57yBp45sQ.png' width = 500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLQjN9mVhv85"
      },
      "source": [
        "#### Beispiel Boltzmann Machine\n",
        "\n",
        "Nachfolgenden bauen wir auf Basis einer BM ein Recommender System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEFsZ1uPiOzw"
      },
      "source": [
        "# Loading Python Libraries \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_gR-4sijON0"
      },
      "source": [
        "# Loading Datasets\n",
        "\n",
        "datlocmov = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%202%20-%20Unsupervised%20Deep%20Learning/AutoEncoders/ml-1m/movies.dat'\n",
        "datlocuser = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%202%20-%20Unsupervised%20Deep%20Learning/AutoEncoders/ml-1m/users.dat'\n",
        "datlocrate = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%202%20-%20Unsupervised%20Deep%20Learning/AutoEncoders/ml-1m/ratings.dat'\n",
        "datloctrainset = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%202%20-%20Unsupervised%20Deep%20Learning/AutoEncoders/ml-100k/u1.base'\n",
        "datloctestset = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%202%20-%20Unsupervised%20Deep%20Learning/AutoEncoders/ml-100k/u1.test'\n",
        "\n",
        "movies = pd.read_csv(datlocmov, sep='::', header=None, engine='python', encoding='latin-1')\n",
        "users = pd.read_csv(datlocuser, sep='::', header=None, engine='python', encoding='latin-1')\n",
        "ratings = pd.read_csv(datlocrate, sep='::', header=None, engine='python', encoding='latin-1')\n",
        "training_set = pd.read_csv(datloctrainset, sep='\\t')\n",
        "test_set = pd.read_csv(datloctestset, sep='\\t')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkgyOzJVofQr"
      },
      "source": [
        "# Vorbereitung der Trainings- und Testdaten\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = np.array(test_set, dtype = 'int')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJrpYY_zt_J7"
      },
      "source": [
        "# Extrahierung der Anzahl von Benutzern und Filme\n",
        "nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vNNluCjvETE"
      },
      "source": [
        "# Konvertierung der Daten in einen Array mit Benutzers (Zeilen) und Movies (Spalten)\n",
        "# Hierfür erstellen wir eine Funktion\n",
        "\n",
        "def convert(data):\n",
        "  new_data = []\n",
        "  for id_users in range(1, nb_users + 1):\n",
        "    id_movies = data[:, 1] [data[:, 0] == id_users]\n",
        "    id_ratings = data[:, 2] [data[:, 0] == id_users]\n",
        "    ratings = np.zeros(nb_movies)\n",
        "    ratings[id_movies - 1] = id_ratings\n",
        "    new_data.append(list(ratings))\n",
        "  return new_data\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7MjWUdNzMFE"
      },
      "source": [
        "# Konvertierung die Daten in PyTorch Tensors\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WfJAGTfz3HE"
      },
      "source": [
        "# Konvertierung die Ratings in Binary Ratings 1 (Liked) or 0 (Not Liked)\n",
        "training_set[training_set == 0] = -1\n",
        "training_set[training_set == 1] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set >= 3] = 1\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set >= 3] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQM6mkNr3qO1"
      },
      "source": [
        "# Erstellung der Architektur des Neural Network\n",
        "class RBM():\n",
        "  def __init__(self, nv, nh):\n",
        "    self.W = torch.randn(nh, nv)\n",
        "    self.a = torch.randn(1, nh)\n",
        "    self.b = torch.randn(1, nv)\n",
        "  def sample_h(self, x):\n",
        "    wx = torch.mm(x, self.W.t())\n",
        "    activation = wx + self.a.expand_as(wx)\n",
        "    p_h_given_v = torch.sigmoid(activation)\n",
        "    return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "  def sample_v(self, y):\n",
        "    wy = torch.mm(y, self.W)\n",
        "    activation = wy + self.b.expand_as(wy)\n",
        "    p_v_given_h = torch.sigmoid(activation)\n",
        "    return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "  def train(self, v0, vk, ph0, phk):\n",
        "    self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
        "    self.b += torch.sum((v0 - vk), 0)\n",
        "    self.a += torch.sum((ph0 - phk), 0)\n",
        "nv = len(training_set[0])\n",
        "nh = 100\n",
        "batch_size = 100\n",
        "rbm = RBM(nv, nh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZllcONlIRZ1",
        "outputId": "ee3d53d4-14de-42f4-c25c-0f79f4f8ee79"
      },
      "source": [
        "# Training RBM\n",
        "nb_epoch = 10\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "  train_loss = 0\n",
        "  s = 0.\n",
        "  for id_user in range(0, nb_users - batch_size, batch_size):\n",
        "    vk = training_set[id_user : id_user + batch_size]\n",
        "    v0 = training_set[id_user : id_user + batch_size]\n",
        "    ph0,_ = rbm.sample_h(v0)\n",
        "    for k in range(10):\n",
        "      _,hk = rbm.sample_h(vk)\n",
        "      _,vk = rbm.sample_v(hk)\n",
        "      vk[v0<0] = v0[v0<0]\n",
        "    phk,_ = rbm.sample_h(vk)\n",
        "    rbm.train(v0, vk, ph0, phk)\n",
        "    train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n",
        "    s += 1.\n",
        "  print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss: tensor(0.3573)\n",
            "epoch: 2 loss: tensor(0.2523)\n",
            "epoch: 3 loss: tensor(0.2509)\n",
            "epoch: 4 loss: tensor(0.2471)\n",
            "epoch: 5 loss: tensor(0.2503)\n",
            "epoch: 6 loss: tensor(0.2482)\n",
            "epoch: 7 loss: tensor(0.2478)\n",
            "epoch: 8 loss: tensor(0.2493)\n",
            "epoch: 9 loss: tensor(0.2501)\n",
            "epoch: 10 loss: tensor(0.2478)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3Oj-KG2Ky0q",
        "outputId": "38e62bca-7e1f-455d-d047-9310b0ef9afb"
      },
      "source": [
        "# Testing RBM\n",
        "\n",
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    v = training_set[id_user:id_user+1]\n",
        "    vt = test_set[id_user:id_user+1]\n",
        "    if len(vt[vt>=0]) > 0:\n",
        "        _,h = rbm.sample_h(v)\n",
        "        _,v = rbm.sample_v(h)\n",
        "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
        "        s += 1.\n",
        "print('test loss: '+str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test loss: tensor(0.2437)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu9II-gMUbp7"
      },
      "source": [
        "### AutoEncoders\n",
        "\n",
        "Autoencoder sind künstliche neuronale Netze, die mittels der Eingabedaten ohne jegliche Überwachung (Unsupervised), für die Erkennung von Mustern eingesetzt werden können. Korrekterweise müsste man AutoEncoder als Self-Supervised Learning Algorthimus bezeichnen, da sie sich selber kontrollieren, aber hierzu kommen wir später. Autoencoder sind vor allem bei der Merkmalserkennung sehr mächtig. Mittels dieser Algorithmen können so zufällige neue Daten generieren werden, die den Trainingsdaten sehr ähnlich sind; dies nennt man ein generatives Modell. Beispielsweise\n",
        "kann ein Autoencoder mit Bildern von Gesichtern trainieren werden, und er würde daraufhin neue Gesichter generieren können. Diese Technik wird hat vor allem mit dem Begriff \"Deepfake\" einen unrühmlichen Bekanntheitsgrad erlangt ([Artikel](https://www.scip.ch/?labs.20181004)).\n",
        "\n",
        "Autoencoder tun in wesentlichen nichts weiter, als zu lernen, ihre Eingaben zu den Ausgaben zu kopieren. Was sich hier so einfach anhört wird jedoch durch zusätzliche Einschränkungen des Netzes absichtlich erschwert. Beispielsweise\n",
        "können Sie die Größe der internen Repräsentation begrenzen oder den Eingabedaten zusätzliches Rauschen (Bias) beimischen und dann das Netz so trainieren, dass es die ursprünglichen Eingaben wiederherstellt. Dies verhindert, dass das Modell die Eingaben einfach direkt in die Ausgabe kopiert und zwingt es dazu\n",
        "effiziente Wege zur Repräsentation der Daten zu finden.\n",
        "\n",
        "Das erstaunliche an Autoencoder ist die verhältnismässig einfach Architektur. So besteht ein Autoencoder aus zwei wesentlichen Bestandteilen, einem **Encoder** (Recognition Network), der die Eingabedaten in eine interne Repräsentation überführt und eine **Decoder** (Generative Network), der die interne Repräsentation in eine Ausgabe umwandelt. Die Ausgabe eines Autoencoders wird oft auch als *Rekonstruktionen* bezeichnet. Ein wichtiges Element dieser Architektur ist die zentrale verborgenen Schicht oder auch die codierende Schicht genannt.\n",
        "\n",
        "<img src='https://cdn-images-1.medium.com/max/1600/1*ZEvDcg1LP7xvrTSHt0B5-Q@2x.png' width=500>\n",
        "\n",
        "*Quelle: Towards Data Science*\n",
        "\n",
        "Wie in der vorhergehend Abbildung erkennbar besitzt ein Autoencoder die gleiche Architektur wie ein mehrschichtiges Perzeptron (MLP),  jedoch in der Ausgabeschicht die gleiche Anzahl Units (Neuronen) wie in der Eingabeschicht verfügbar.\n",
        "\n",
        "Durch die oben beschriebene Eigenschaft lassen sich Autoencoder auf verschiede Weise einsetzen. Sei es zur **Dimensionsreduktion**, zur **Merkmalserkennung**, zum unüberwachten Vortrainieren oder als generatives Modell (z.B. für Deepfake-Anwendungen). Im Zusammenhang mit der Dimensionsreduktion arbeiten Autoencoder besser als Modelle für die Hauptkomponentenanalyse (PCA).\n",
        "\n",
        "Nachfolgend die Schritte wie ein AutoEncoder trainiert:\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/dlaz/Volume%202%20-%20Unsupervised%20Deep%20Learning/AutoEncoders/Training_Autoencoder.png?raw=true' width=600>\n",
        "\n",
        "Es gibt mittlerweile verschiedene Arten von AutoEncoders (Aufzählung nicht abschliessend):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgP8Ybv7_hqR"
      },
      "source": [
        "#### Stacked Autoencoder\n",
        "\n",
        "Wie wir in der Kurzeinführung zur den Autoencoder gesehen habe, besteht ein klassischer Autoencoder meist aus einer verborgenen Schicht (Hidden Layer). Diese Architektur hat sich jedoch bei komplexeren Eingabedaten nur bedingt bewährt, weshalb auch mehrere Hidden Layers hinzugefügt werden können. Hierbei spricht man von sogenannten *Stacked Autoencoder*. Dabei werden weitere Schichten symmentrisch um die zentrale Codierungsschicht herum aufgebaut. Symmetrisch deshalb, weil die weiteren Schichten immer in gespiegelter Weise über die gleiche Anzahl an Units verfügen.\n",
        "\n",
        "<img src='https://cdn-images-1.medium.com/max/1600/1*7H9VQlN94-wv7Ianqt6GZg.png' width=500>\n",
        "\n",
        "*Quelle: Medium Corporation*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLHycqyxABL1"
      },
      "source": [
        "#### Denoising Autoencoder\n",
        "\n",
        "Im wesentlichen unterscheidet sich der Denosing Autoencoder vom Stacked Autoencoder dardurch, dass hier noch ein sogenannte \"Rauschen\" hinzugefügt wird. Mit diesem \"Rauschen\" verhindert man, dass der Autoencoder den Input einfach in den Output kopiert und stattessen ein Muster in den Daten findet. \n",
        "\n",
        "Entweder wird ein normalverteiltes Rauschen dazu addiert oder wie bei der [Drop-out](https://de.wikipedia.org/wiki/Dropout_(k%C3%BCnstliches_neuronales_Netz)) Methode zufällig Eingabewerte deaktiviert. \n",
        "\n",
        "<img src='https://lilianweng.github.io/lil-log/assets/images/denoising-autoencoder-architecture.png' width=500>\n",
        "\n",
        "*Quelle: [Lilian Weng](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKf2y9iEAtMt"
      },
      "source": [
        "#### Variational Autoencoder\n",
        "\n",
        "Dieser Typ Autoencoder untscheidet sich zu den oben beschriebenen Autoencoder dahingehen, dass es sich hierbei einerseits um einen probabilistischen Ansatz handelt bzw. auch nach dem Training wird die Ausgabe zufällig festgelegt, nicht wie beim Denoising Autocoder, welcher nur während des Trainigs Zufallselemente enthält. Andererseits handelt es sich dabei um einen generativen Autoencoder, der neue Daten generiert die so aussehen als ob sie aus dem ursprünglichen Trainingsdatensatz kommen würden.\n",
        "\n",
        "<img src='https://miro.medium.com/max/1314/1*CiVcrrPmpcB1YGMkTF7hzA.png' width=400>\n",
        "\n",
        "*Quelle: [Towards Data Science](https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf)*\n",
        "\n",
        "Wie in der Grafik oben ersichtlich, sieht der Variational Autoencoder in der Grundstruktur weitgehend aus wie die bereits beschriebenen Autoencoder. Der wesentliche Unterschied wird im mittleren Teil ersichtlich. Statt aus der Eingabe des 2. Hidden Layers ein Coding herzustellen, berechnet der Encoder ein mittleres Coding μ und dessen Standardabweichung σ. Das tatsächliche Coding wird zufällig Stichprobe einer Normalverteilung entnommen. Nach dem beschriebenen Schritt wird fährt der Decoder wie gewohnt weiter.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ukrFoh2yYru"
      },
      "source": [
        "#### Beispiel Autoencoder\n",
        "\n",
        "Nachfolgenden bauen wir auf Basis einer BM ein Recommender System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FTTgmnzygIx"
      },
      "source": [
        "# Python Libraries importieren\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD8pV-b9zzb0"
      },
      "source": [
        "# Datensatz importieren\n",
        "datlocmov = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%202%20-%20Unsupervised%20Deep%20Learning/AutoEncoders/ml-1m/movies.dat'\n",
        "datlocuser = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%202%20-%20Unsupervised%20Deep%20Learning/AutoEncoders/ml-1m/users.dat'\n",
        "datlocrate = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%202%20-%20Unsupervised%20Deep%20Learning/AutoEncoders/ml-1m/ratings.dat'\n",
        "datloctrainset = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%202%20-%20Unsupervised%20Deep%20Learning/AutoEncoders/ml-100k/u1.base'\n",
        "datloctestset = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/dlaz/Volume%202%20-%20Unsupervised%20Deep%20Learning/AutoEncoders/ml-100k/u1.test'\n",
        "\n",
        "movies = pd.read_csv(datlocmov, sep='::', header=None, engine='python', encoding='latin-1')\n",
        "users = pd.read_csv(datlocuser, sep='::', header=None, engine='python', encoding='latin-1')\n",
        "ratings = pd.read_csv(datlocrate, sep='::', header=None, engine='python', encoding='latin-1')\n",
        "training_set = pd.read_csv(datloctrainset, sep='\\t')\n",
        "test_set = pd.read_csv(datloctestset, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hupJAThg157G"
      },
      "source": [
        "# Vorbereitung der Trainings- und Testdaten\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eittLSZE2bb4"
      },
      "source": [
        "# Extrahierung der Anzahl von Benutzern und Filme\n",
        "nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COpY5QsRwMfo"
      },
      "source": [
        "# Konvetierung der Daten in Array mit Users (Zeilen) und Movies (Spalte)\n",
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_users in range(1, nb_users + 1):\n",
        "      id_movies = data[:,1][data[:,0] == id_users]\n",
        "      id_ratings = data[:,2][data[:,0] == id_users]\n",
        "      ratings = np.zeros(nb_movies)\n",
        "      ratings[id_movies - 1] = id_ratings\n",
        "      new_data.append(list(ratings))\n",
        "    return new_data\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTHxUAJG7UDx"
      },
      "source": [
        "# Konvertierung der Daten in einen Torch Tensor\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atrw5MDa7-jJ"
      },
      "source": [
        "# Erstellung der Autoencoder Architektur\n",
        "class SAE(nn.Module):\n",
        "  # Die erste Funktion definiert die Architektur unsere AE\n",
        "  def __init__(self, ): \n",
        "    super(SAE, self).__init__()\n",
        "    self.fc1 = nn.Linear(nb_movies, 20) # Input-Layer, fc = fullconnection\n",
        "    self.fc2 = nn.Linear(20, 10) # 1. Hidden-Layer, Encoding\n",
        "    self.fc3 = nn.Linear(10, 20) # 2. Hidden-Layer, Decoding\n",
        "    self.fc4 = nn.Linear(20, nb_movies) # Output-Layer\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  # Die zweite Funkton definiert die Ausführung der Architektur\n",
        "  def forward(self,x): \n",
        "    x = self.activation(self.fc1(x))\n",
        "    x = self.activation(self.fc2(x))\n",
        "    x = self.activation(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x\n",
        "\n",
        "sae = SAE()\n",
        "criterion = nn.MSELoss() # Definition des Mean Square Erros \n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxT9zOODD9dr"
      },
      "source": [
        "# Training des Autoencoders\n",
        "nb_epoch = 200\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "  train_loss = 0\n",
        "  s = 0. # Der Punkt bedeutet ein Float\n",
        "  for id_user in range(nb_users):\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    target = input.clone()\n",
        "    if torch.sum(target.data > 0) > 0:\n",
        "      output = sae(input)\n",
        "      target.require_grad = False\n",
        "      output[target == 0] = 0\n",
        "      loss = criterion(output, target)\n",
        "      mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "      loss.backward()\n",
        "      train_loss += np.sqrt(loss.data*mean_corrector)\n",
        "      s += 1.\n",
        "      optimizer.step()\n",
        "  print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS-9wVhuP0c8",
        "outputId": "3fcca640-9f08-4c42-d961-e8356ed63e8f"
      },
      "source": [
        "# Testing das AE\n",
        "test_loss = 0\n",
        "s = 0. # Der Punkt bedeutet ein Float\n",
        "for id_user in range(nb_users):\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
        "    if torch.sum(target.data > 0) > 0:\n",
        "      output = sae(input)\n",
        "      target.require_grad = False\n",
        "      output[target == 0] = 0\n",
        "      loss = criterion(output, target)\n",
        "      mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "      test_loss += np.sqrt(loss.data*mean_corrector)\n",
        "      s += 1.\n",
        "print(' loss: '+str(test_loss/s))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " loss: tensor(0.9490)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX37ifm3TZHw"
      },
      "source": [
        "### Auswahlverfahren Deep Learning Modelle\n",
        "\n",
        "Spätestens wenn es darum geht ein eigenes AI Projekt in Angriff zu nehmen, kommmt die Frage nach der richtigen Modellwahl. Aber was ist die richtige Wahl und von was ist diese Abhängig?\n",
        "\n",
        "### Daten\n",
        "In Bezug auf die Abhängigkeit, ist die Frage relativ schnell beantwortete. Die Wahl ist in erster Line von den bestehenden Daten abhängig. Nachfolgenden eine kurze Checkliste:\n",
        "\n",
        "* Daten **mit** Label  -> **Supervised Learning**\n",
        "* Daten **ohne** Label -> **Unsupervised Learning**\n",
        "* **Keine** Daten -> **Reinforcement Learning** -> gehört nicht zum DL\n",
        "\n",
        "Aufbauend auf der vorherigen Checkliste können wir nun die Auswahl weiter einschänken:\n",
        "\n",
        "#### Supervised Learning\n",
        "\n",
        "##### **Classification**\n",
        "* Natural Language Processing (NLP) -> **Recurrent Neural Network (RNN)**\n",
        "* Bildererkennung (Image Recognition) -> **Convolutional Neural Networks (CNN)**\n",
        "* Objekteerkennung (Object Recognition) -> **RNN** oder **CNN**\n",
        "* Spracherkennung (Speech Recognition) -> **RNN**\n",
        "\n",
        "##### **Regression**\n",
        "* Zeitreihenanalyse (Time Series Analysis) -> **RNN**\n",
        "\n",
        "#### Unsupervised Learning\n",
        "* Extraktion von Merkmalen (Features) -> **Restricted Boltsman Machine**\n",
        "* Muster in Daten erkennen -> **Autoencoder**\n",
        "\n",
        "#### Reinforcement Learning -> Gehört nicht zum Thema Deep Learning\n",
        "* Business Strategie Planung  \n",
        "* Robotics\n",
        "* Gaming "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gmMP2-yt2BD"
      },
      "source": [
        "## **Reinforcement Learning**\n",
        "\n",
        "Reinforcement Learning (RL) bildet neben Supervised und Unsupervised Learning die dritte große Gruppe von Machine Learning Verfahren. RL ist eine am natürlichen Lernverhalten des Menschen orientierte Methode. Menschliches Lernen erfolgt, insbesondere in frühen Stadien des Lernens, häufig über eine einfache Exploration der Umwelt. Dabei sind unsere Handlungen im Rahmen des Lernproblems durch einen gewissen Aktionsraum definiert. Über \"Trial and Error\" werden die Auswirkungen verschiedener Handlungen auf unsere Umwelt beobachtet und bewertet. Als Reaktion auf unsere Handlungen erhalten wir von unserer Umgebung ein Feedback, abstrakt dargestellt in Form einer Belohnung oder Bestrafung. Dabei ist das Konzept der Belohnung bzw. Bestrafung nur in den allerwenigsten Fällen monetär zu verstehen. In vielen Fällen wird die Belohnung in Form von sozialer Akzeptanz, Lob anderer Menschen aber auch durch persönliches Wohlbefinden oder Erfolgserlebnisse ausgezahlt. Vielfach zeigt sich auch eine zeitliche Latenz zwischen Handlung und Belohnung. Hierbei versucht der Mensch häufig, durch sein Handeln die erwartete \"Gesamtbelohnung\" im Zeitverlauf zu maximieren und nicht nur unmittelbare Belohnungen zu generieren.\n",
        "\n",
        "Ein Beispiel: Wenn wir lernen Gitarre zu spielen, umfasst unser Aktionsraum das Zupfen der Seiten sowie das Greifen am Bund. Über eine zunächst zufällige Exploration des Handlungsraums erhalten wir in Form von Tönen der Gitarre ein Feedback der Umwelt. Dabei werden wir belohnt, wenn die Töne \"gerade\" sind bzw. bestraft, wenn die Nachbarn mit dem Besen von unten gegen die Decke klopfen. Wir versuchen, die erwartete Gesamtbelohnung in Form von richtig gespielten Noten und Akkorden im für uns relevanten Zeithorizont zu maximieren. Dies geschieht nicht dadurch, dass wir aufhören zu lernen sobald wir einen Akkord sauber spielen können, sondern manifestiert sich durch ein stetiges Training und immer wieder neue Belohnungen und Erfolge, die uns im Zeitverlauf erwarten. Natürlich kann die Dauer der Exploration der möglichen Handlungen und Belohnungen der Umwelt durch die Hinzunahme eines externen Trainers verbessert werden. Dieses Beispiel ist natürlich sehr vereinfacht, stellt aber das Grundprinzip im Kern gut dar.\n",
        "\n",
        "Reinforcement Learning besteht formal betrachtet aus den folgenden fünf wichtigen Komponenten:\n",
        "\n",
        "* **Agent**: Ein RL-Agent ist die Entität, die wir trainieren, um korrekte Entscheidungen zu treffen (z. B. ein Roboter, der trainiert wird, sich in einem Haus zu bewegen, ohne abzustürzen).\n",
        "* **Environment** (dt. Umgebung): Die Umgebung ist die Umgebung, mit der der Agent interagiert (z. B. das Haus, in dem sich der Roboter bewegt). Der Agent kann die Umgebung nicht manipulieren; er kann nur seine eigenen Aktionen steuern (z. B.: der Roboter kann nicht steuern, wo ein Tisch im Haus steht, aber er kann um ihn herumgehen, um einen Absturz zu vermeiden).\n",
        "* **State** (dt. Zustand): Der State definiert die aktuelle Situation des Agenten (z. B.: es kann die genaue Position des Roboters im Haus sein, oder die Ausrichtung seiner beiden Beine, oder seine aktuelle Körperhaltung; es hängt davon ab, wie Sie das Problem angehen).\n",
        "* **Action** (dt. Aktion): Die Entscheidung, die der Agent im aktuellen Zeitschritt trifft (z. B.: er kann sein rechtes oder linkes Bein bewegen oder seinen Arm heben oder ein Objekt anheben, sich nach rechts oder links drehen usw.). Wir kennen die Menge der Aktionen (Entscheidungen), die der Agent im Voraus ausführen kann.\n",
        "* **Reward** (dt. Belohnung): Je nach dem welche Aktion der Agent auswählt bekommt er eine Belohnung oder nicht.\n",
        "* **Policy** (dt. Richtlinie): Eine Policy ist der Denkprozess, der hinter der Auswahl einer Aktion steht, welche auf Basis eine State ausgelöst wird . In der Praxis ist es eine Wahrscheinlichkeitsverteilung, die der Menge der Aktionen zugeordnet ist. Aktionen mit hoher Belohnung haben eine hohe Wahrscheinlichkeit und umgekehrt.\n",
        "Beachten Sie, dass eine niedrige Wahrscheinlichkeit für eine Aktion nicht bedeutet, dass sie überhaupt nicht ausgewählt wird. Es bedeutet nur, dass es weniger wahrscheinlich ist, dass sie ausgewählt wird.\n",
        "\n",
        "Grundsätzlich lässt sich der Ablauf wie folgt beschreiben: Der Agent führt in einer Umgebung zu einem bestimmten Status ($s_t$) eine Aktion ($a_t$) aus dem zur Verfügung stehenden Aktionsraum A durch, die zu einer Reaktion der Umgebung in Form einer Belohnungen ($r_t$) führt.\n",
        "\n",
        "<img src='https://www.statworx.com/wp-content/uploads/reinforcement-learning.png' width='600'>\n",
        "\n",
        "Die Reaktion der Umgebung auf die Aktion des Agenten beeinflusst nun wiederum die Wahl der Aktion des Agenten im nächsten Status ($s_{t+1}$). Über mehrere tausend, hunderttausend oder sogar millionen von Iterationen ist der Agent in der Lage, einen Zusammenhang zwischen seinen Aktionen und dem künftig zu erwartenden Nutzen in jedem Status zu approximieren und sich somit entsprechend optimal zu verhalten. Dabei befindet sich der Agent immer in einem Dilemma zwischen der Nutzung seiner bisher erworbenen Erfahrung auf der einen und der Exploration neuer Strategien zur Erhöhung der Belohnung auf der anderen Seite. Dies wird als \"Exploration-Exploitation Dilemma\" bezeichnet.\n",
        "\n",
        "Die Approximation des Nutzens kann dabei modellfrei (**model-free**), also über reine Exploration der Umgebung erfolgen oder durch die Anwendung von Machine Learning Modellen (**model-based**), die den Nutzen einer Aktion versuchen zu approximieren. Letztere Variante wird insbesondere dann angewendet, wenn der Status- und/oder Aktionsraum von hoher Dimensionalität ist bzw. eine komplexe Umgebung besteht. Das ist bspw. der Fall bei selbstfahrenden Autos, Strategiespielen etc.\n",
        "\n",
        "Quelle: [Statworx.com](https://www.statworx.com/ch/blog/einfuehrung-in-reinforcement-learning-wenn-maschinen-wie-menschen-lernen/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flc78xwp-19M"
      },
      "source": [
        "### Multi-Armed Bandit Problem\n",
        "\n",
        "Das Dilemma zwischen Exploration (Erkundung) und Exploitation (Ausbeutung) besteht in vielen Aspekten unseres Lebens. Sagen wir, dein Lieblingsrestaurant ist gleich um die Ecke. Wenn du jeden Tag dorthin gehst dann weisst du, was du für dein Geld bekommen wirst. Aber vielleicht verpasst du damit die Chance, eine noch bessere Option (Preis/Qualität) zu entdecken. Wenn du aber ständig neue Orte ausprobierst, wirst du wahrscheinlich von Zeit zu Zeit auch qualitativ schlechteres Essen bekommen. In ähnlicher Weise versuchen Online-Anzeigen, ein Gleichgewicht zwischen den bekanntermaßen attraktivsten Werbungen (Ads) und den neuen Werbungen zu finden, die vielleicht sogar noch erfolgreicher sind.\n",
        "\n",
        "Wenn wir alle Informationen über die Umwelt gelernt haben, sind wir in der Lage, die beste Strategie zu finden, indem wir auch nur Brute-Force simulieren, ganz zu schweigen von vielen anderen intelligenten Ansätzen. Das Dilemma ergibt sich aus den unvollständigen Informationen: Wir müssen genügend Informationen sammeln, um die besten Gesamtentscheidungen zu treffen und gleichzeitig das Risiko unter Kontrolle zu halten. Mit Ausbeutung nutzen wir die beste Option, die wir kennen. Bei der Exploration gehen wir ein gewisses Risiko ein, um Informationen über unbekannte Optionen zu sammeln. Die beste langfristige Strategie kann mit kurzfristigen Opfern verbunden sein. Zum Beispiel könnte ein Explorationsversuch ein totaler Fehlschlag sein, aber das warnt uns davor, diese Maßnahme in Zukunft nicht zu oft zu ergreifen.\n",
        "\n",
        "Das Problem der **mehrarmigen Banditen (Multi-Armed Bandit)** ist ein klassisches Problem, das das Dilemma Exploration vs. Ausbeutung deutlich macht. Stellen Sie sich vor, Sie befinden sich in einem Casino und stehen mehreren Spielautomaten gegenüber, von denen jeder mit einer unbekannten Wahrscheinlichkeit konfiguriert ist, wie wahrscheinlich es ist, dass Sie bei einem Spiel eine Belohnung erhalten können. Die Frage ist: Was ist die beste Strategie, um langfristig die höchsten Belohnungen zu erzielen?\n",
        "\n",
        "<img src='https://user-images.githubusercontent.com/22970879/41629289-ec662a58-73e5-11e8-9f41-40c6d7ba5a36.jpg'>\n",
        "\n",
        "\n",
        "Die Beschränkung auf eine endliche Anzahl von Versuchen führt zu einer neue Art von Explorationsproblem. Wenn z.B. die Anzahl der Versuche kleiner ist als die Anzahl der Spielautomaten, können wir nicht einmal jeden Automaten ausprobieren, um die Belohnungswahrscheinlichkeit (!) abzuschätzen, und müssen uns daher mit einer begrenzten Menge an Wissen und Ressourcen (d.h. Zeit) klug verhalten.\n",
        "\n",
        "Ein naiver Ansatz kann darin bestehen, dass man mit einem Automaten sehr viele Runden lang weiterspielt, um schließlich die \"wahre\" Belohnungswahrscheinlichkeit nach dem Gesetz der großen Zahlen zu schätzen. Dies ist jedoch ziemlich verschwenderisch und garantiert sicherlich nicht die beste langfristige Belohnung.\n",
        "\n",
        "Je nachdem, wie wir Exploration betreiben, gibt es mehrere Möglichkeiten, das Problem der mehrarmigen Banditen zu lösen.\n",
        "\n",
        "* Keine Erkundung: der naivste Ansatz und ein schlechter.\n",
        "* Exploration nach dem Zufallsprinzip\n",
        "* Exploration klug mit Vorzug vor Unsicherheit\n",
        "\n",
        "\n",
        "Quelle: [Lil Log](https://lilianweng.github.io/lil-log/2018/01/23/the-multi-armed-bandit-problem-and-its-solutions.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJdrJJQUv3-k"
      },
      "source": [
        "### Upper Confidence Bound (UCB)\n",
        "\n",
        "Ein Weg um das Multi-Armed-Bandit Problem zu lösen ist der UCB-Algorithmus.\n",
        "Der UCB-Algorithmus (Upper Confidence Bound) wird oft als \"Optimismus angesichts der Unsicherheit\" formuliert. Um zu verstehen, warum, bedenken Sie in einer bestimmten Runde, dass die Belohnungsfunktion jedes Arms als eine Punktschätzung auf der Grundlage der beobachteten durchschnittlichen Belohnungsrate wahrgenommen werden kann. Indem wir die Intuition aus [Konfidenzintervallen](https://www.statistik-nachhilfe.de/ratgeber/statistik/induktive-statistik/konfidenzintervall-fuer-erwartungswert-varianz-und-median) ableiten, können wir für jede Punktschätzung auch eine Form der Unsicherheitsgrenze um die Punktschätzung herum einbeziehen. In diesem Sinne haben wir sowohl eine untere Grenze als auch eine obere Grenze für jeden Arm.\n",
        "Der UCB-Algorithmus hat einen treffenden Namen, weil wir uns nur mit der oberen Grenze befassen, da wir versuchen, den Arm mit der höchsten Belohnungsrate zu finden.\n",
        "\n",
        "Der UCB-Algorithmus gehört zu den am meist verwendesten RL-Algorithmen im Zusammenhang mit Online Advertisements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XCjepjJwEv-"
      },
      "source": [
        "#### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_mBkG3YwNTt"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npqlXjaNwYTv"
      },
      "source": [
        "#### Importing the dataset\n",
        "\n",
        "Dieser Datensatz bernötigen wir zu Simulation einer Webseite, auf welcher 10 verschiedene Werbungen eines Autos aufgeschaltet werden. Die Webseite wird von 10000 Benutzern besucht. Jeder der Benutzer klickt auf die Ads welche ihn am meisten ansprechen. In einem realen Business-Case würde der Reenforcement Learning Algorithmus mittels realtime Daten mit minimalen Aufwand lernen, welche Ads am meisten angeklickt bzw. am meisten gezeigt werden sollten. Wichtig ist es dabei zu wissen, dass jedes Advertisment welches aufgeschaltet wird je nach Plazierung viel Geld kostet. Das Marketing des Autoherstellers möchte somit so schnell wie möglich den am \"gewinnbringensten\" Ad ermitteln."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMJfUVLVwcFc"
      },
      "source": [
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%206%20-%20Reinforcement%20Learning/Section%2032%20-%20Upper%20Confidence%20Bound%20(UCB)/Python/Ads_CTR_Optimisation.csv'\n",
        "dataset = pd.read_csv(datloc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66I-mZM1ryF5"
      },
      "source": [
        "print(dataset.shape)\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaSbots_wfoB"
      },
      "source": [
        "#### Implementing UCB\n",
        "\n",
        "Anschliessend werden wir die folgende Schritte mittels Python implementieren:\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%206%20-%20Reinforcement%20Learning/Section%2032%20-%20Upper%20Confidence%20Bound%20(UCB)/UCB-Steps.jpg?raw=true' width='600'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnvZKJ5UqIFA"
      },
      "source": [
        "import math\n",
        "# Step 1 \n",
        "N = 10000 # Anzahl Runden bzw. Benutzer welche auf Ads klicken\n",
        "d = 10 # Anzahl Ads\n",
        "ads_selected = [] # Leere Liste für die angeklickten Ads\n",
        "numbers_of_selections = [0] * d # Leere Liste für die Anzahl der gewählten Ads\n",
        "sums_of_rewards = [0] * d # Liste für die Summe aller Belohnungen\n",
        "total_reward = 0 # \n",
        "\n",
        "# Step 2 \n",
        "for n in range(0,N): # 1. Iteration für die Runden (0 bis 10000)\n",
        "  ad = 0 # Started jede Iteration mit Ad 1\n",
        "  max_upper_bound = 0 # Started am Anfang mit der obersten Vertrauensgrenze von 0 welche jedes Runde aktualisiert wird.\n",
        "\n",
        "  for i in range(0,d): # 2. Iteration für Ads (0 bis 9)\n",
        "    if (numbers_of_selections[i] > 0): # Falls ausgewählte Ad ist grösser als 0\n",
        "      # Computing average reward\n",
        "      average_reward = sums_of_rewards[i] / numbers_of_selections[i]\n",
        "      # Computing confidence interval\n",
        "      delta_i = math.sqrt(3/2 * math.log(n + 1) / numbers_of_selections[i])\n",
        "      upper_bound = average_reward + delta_i\n",
        "   \n",
        "    else:\n",
        "      # Step 3 \n",
        "      upper_bound = 1e400 # Trick um eine Zahl fast auf endlos zu setzen\n",
        "    if (upper_bound > max_upper_bound):\n",
        "      max_upper_bound = upper_bound\n",
        "      ad = i\n",
        "\n",
        "  ads_selected.append(ad)\n",
        "  numbers_of_selections[ad] = numbers_of_selections[ad] + 1 # += 1 ist das gleiche wie numbers_of_selections[ad] + 1\n",
        "  reward = dataset.values[n, ad]\n",
        "  sums_of_rewards[ad] = sums_of_rewards[ad] + reward\n",
        "  total_reward = total_reward + reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozQRDby7BRh1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "72561bd0-75b5-454f-b43e-eee1ad402208"
      },
      "source": [
        "(3/2 * math.log(n + 1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.815510557964275"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXftWcjDwsYj"
      },
      "source": [
        "#### Visualising the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uV3N9Mo9PGE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "32ab16a0-9a4e-4ac8-a314-5b8bceb5f257"
      },
      "source": [
        "plt.hist(ads_selected)\n",
        "plt.title('Histogramm of ads selections')\n",
        "plt.xlabel('Ads')\n",
        "plt.ylabel('Number of times each ad was selected')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p92KenfABSR4"
      },
      "source": [
        "Wir können anhand des Histogramms erkennen, dass der UCB-Algoritmus einen klaren Favoriten erkoren hat. Ads Nummer 4 scheint mit Abstand am beliebtesten zu sein. Was wir hier auch klar erkennen können ist, dass UCB auch mit weniger Runden auskommen würde, was natürlich unser Ziel wäre.\n",
        "Wie es scheint könnten wir es wagen, die Rudenzahl auf 1000 zu reduzieren, was zu folgendem Resultat geführt hat:\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%206%20-%20Reinforcement%20Learning/Section%2032%20-%20Upper%20Confidence%20Bound%20(UCB)/UCB_Hist_Result.jpg?raw=true' width='400'>\n",
        "\n",
        "Wir könnten jetzt sicher noch etwas optimieren, jedoch spätenstens bei einer Rundenanzahl von 500 ist Schluss:\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%206%20-%20Reinforcement%20Learning/Section%2032%20-%20Upper%20Confidence%20Bound%20(UCB)/UCB_Hist_Result_2.png?raw=true' width='400'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPKTIRAtx232"
      },
      "source": [
        "### Thompson Sampling\n",
        "\n",
        "Der Thompson Sampling-Algorithmus ist eine andere Art um das [Multi-Armed Bandit Problem](https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%206%20-%20Reinforcement%20Learning/Section%2032%20-%20Upper%20Confidence%20Bound%20(UCB)/Python/upper_confidence_bound.ipynb) zu lösen. \n",
        "\n",
        "Der wesentliche Unterschied zur Upper Confidence Bound Methode besteht darin, dass bei der Thompson Sampling Methode mit einer Verteilung (engl. Distribution) gearbeitet wird. Dabei wird eine Verteilung dort erstellt wo die tatsächlichen Werte liegen könnten. Der Thompson Sampling Algorithmus grenzt also mittels eines [probabilistische](https://www.werbewoche.ch/marketing/2017-01-04/daten-probabilistisch-vs-deterministischen) Vorgehens den Beispielsbereich ein. Ein weitere Unterschiede zwischen UCB und TS ist, dass bei UCB nach jeder Runde der Status updaten muss während bei der TS der Update erst nach mehreren Runden (bspw. 200, 500 usw.). Dieser Unterschied hat auch einen Einfluss auf die Rechenperformance, da jeder Update auch Rechenleistung benötigt.\n",
        "\n",
        "Die erwähnten Unterschiede machen den Thompson Sampling Algorithmus so beliebt, da er auch die besseren empirischen Beweise liefert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqPv9zpAx-EE"
      },
      "source": [
        "#### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHlI03QVlSYW"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqpVk5HhyGmO"
      },
      "source": [
        "#### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f3eypGRj4HT"
      },
      "source": [
        "datloc = 'https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/mlaz/Part%206%20-%20Reinforcement%20Learning/Section%2033%20-%20Thompson%20Sampling/Python/Ads_CTR_Optimisation.csv'\n",
        "\n",
        "dataset = pd.read_csv(datloc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqoXeWOYyQhB"
      },
      "source": [
        "#### Implementing Thompson Sampling\n",
        "\n",
        "Wie auch schon im UCB-Algorithmus gibt es auch in der Thompson Sampling Methode verschieden Schritte, welche implementiert werden müssen.\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%206%20-%20Reinforcement%20Learning/Section%2033%20-%20Thompson%20Sampling/Thompson_Sampling_Slide.png?raw=true' width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zTtsgmstfVB"
      },
      "source": [
        "import random\n",
        "\n",
        "# Step 1 \n",
        "N = 10000 # Anzahl Runden bzw. Benutzer welche auf Ads klicken\n",
        "d = 10 # Anzahl Ads\n",
        "ads_selected = []\n",
        "numbers_of_rewards_1 = [0] *d\n",
        "numbers_of_rewards_0 = [0] *d\n",
        "total_reward = 0\n",
        "\n",
        "for n in range(0,N): # Iteration durch Runden\n",
        "  ad = 0\n",
        "  max_random = 0\n",
        "  for i in range(0,d): # Iteration durch Ads\n",
        "    # Step 2\n",
        "    random_beta = random.betavariate(numbers_of_rewards_1[i] + 1, numbers_of_rewards_0[i] + 1)\n",
        "    # Step 3\n",
        "    if (random_beta > max_random):\n",
        "      max_random = random_beta\n",
        "      ad = i\n",
        "  ads_selected.append(ad)\n",
        "  reward = dataset.values[n, ad]\n",
        "  if reward == 1:\n",
        "    numbers_of_rewards_1[ad] = numbers_of_rewards_1[ad] + 1\n",
        "  else:\n",
        "    numbers_of_rewards_0[ad] = numbers_of_rewards_0[ad] + 1\n",
        "\n",
        "  total_reward = total_reward + reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tweWsgTHyXhv"
      },
      "source": [
        "#### Visualising the results - Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcpxpGowj8wb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "961362d8-bb15-4e2e-b560-848014e9b5b2"
      },
      "source": [
        "plt.hist(ads_selected)\n",
        "plt.title('Histogramm of ads selections')\n",
        "plt.xlabel('Ads')\n",
        "plt.ylabel('Number of times each ad was selected')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVr2kF0pkcn6"
      },
      "source": [
        "Wie auch schon beim UCB-Algorithmus hat auch Thompson Sampling den richtigen Ad Kandidaten (Nr. 4) erkoren. Zudem siehen wir auch in diesem Histogramm, dass der Algorithmus mit viel weniger Runde auskommen würde. Wir habe aus diesem Grund die Rundenzahl mutigerweise mal auf 100 gesetzt. Wie das nachfolgenden Histogramm zeigt, scheint der Thompson Sampling Algorithmus auch mit viel weniger Rund als UCB (min. 500) auszukommen. Wir konnten uns nun davon überzeugen, warum der TS beliebter ist als der UCB.\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/mlaz/Part%206%20-%20Reinforcement%20Learning/Section%2033%20-%20Thompson%20Sampling/Python/Thompson_Sampling_Resultat.png?raw=true' width='400' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1LcN0BqynLy"
      },
      "source": [
        "### Markov Decision Process (MDP)\n",
        "\n",
        "Bevor wir uns mit den am häufigsten angewendeten RL-Methoden (Q-Learning, Deep Q-Learning etc.) befassen, müssen wir zuerst eine kurzen Abstecher in eines der wichtigsten mathematische Frameworks in Bezug auf das Thema \"Entscheidungsprobleme\" tätigen ... den Markov Decision Process (MDP).\n",
        "\n",
        "Ein wichtiger Punkt, der zu beachten ist - jeder Zustand (State) innerhalb eines Environments ist eine Folge des vorherigen Zustands, der wiederum eine Folge des vorherigen Zustands ist. Die Speicherung all dieser Informationen wird jedoch, selbst bei Umgebungen mit kurzen Episoden, schnell unpraktikabel werden.\n",
        "\n",
        "Um dieses Problem zu lösen, nehmen wir an, dass jeder Zustand einer Markov-Eigenschaft folgt, d. h., jeder Zustand hängt nur vom vorherigen Zustand und dem Übergang von diesem Zustand zum aktuellen Zustand ab. Schauen Sie sich das folgende Labyrinth an, um besser zu verstehen, wie dies funktioniert:\n",
        "\n",
        "<img src='https://cdn.analyticsvidhya.com/wp-content/uploads/2019/04/Screenshot-2019-04-16-at-3.39.31-PM-850x332.png' width=600>\n",
        "\n",
        "Nun gibt es 2 Szenarien mit 2 verschiedenen Startpunkten und der Agent durchläuft verschiedene Pfade, um denselben vorletzten Zustand zu erreichen. Nun spielt es keine Rolle, welchen Weg der Agent nimmt, um den roten Zustand zu erreichen. Der nächste Schritt, um das Labyrinth zu verlassen und den letzten Zustand zu erreichen, ist, nach rechts zu gehen. Es ist klar, dass wir nur die Information über den roten/vorletzten Zustand benötigen, um die nächstbeste Aktion herauszufinden, was genau das ist, was die Markov-Eigenschaft impliziert.\n",
        "\n",
        "Nehmen wir an, wir kennen die erwartete Belohnung für jede Aktion bei jedem Schritt. Dies wäre im Wesentlichen wie ein Spickzettel für den Agenten! Unser Agent wird genau wissen, welche Aktion er ausführen muss.\n",
        "\n",
        "Er wird die Sequenz von Aktionen ausführen, die letztendlich die maximale Gesamtbelohnung generiert. Diese Gesamtbelohnung wird auch als Q-Wert bezeichnet, was uns zum Thema Q-Learning führt.\n",
        "\n",
        "Quelle: [AnalyticsVidhya.com](https://www.analyticsvidhya.com/blog/2019/04/introduction-deep-q-learning-python/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II9mmaaSqNBp"
      },
      "source": [
        "### **Q-Learning**\n",
        "\n",
        "Um Reinforcement Learning Systeme zu trainieren, wird häufig eine Methode verwendet, die als Q-Learning bekannt ist - wobei Q für Quality steht. Den Namen erhält Q-Learning von der sog. Q-Funktion $Q(s,a)$, die den erwarteten Nutzen $Q$ einer Aktion $a$ im Status $s$ beschreibt. Die Nutzenwerte werden in der sog. Q-Matrix $Q$ gespeichert, deren Dimensionalität sich über die Anzahl der möglichen Stati sowie Aktionen definiert. Während des Trainings versucht der Agent, die Q-Werte der Q-Matrix durch Exploration zu approximieren, um diese später als Entscheidungsregel zu nutzen. Die Belohnungsmatrix $R$ enthält, korrespondierend zu $Q$, die entsprechenden Belohnungen, die der Agent in jedem Status-Aktions-Paar erhält.\n",
        "\n",
        "Die Approximation der **Q-Values** (Q-Werte) funktioniert im einfachsten Falle wie folgt: Der Agent startet in einem zufällig initialisierten Status $s_t$. Anschließend selektiert der Agent zufällig eine Aktion $a_t$ aus $A$, beobachtet die entsprechende Belohnung $r_t$ und den darauf folgenden Status $s_{t+1}$. Die Update-Regel der Q-Matrix ist dabei wie folgt definiert:\n",
        "\n",
        "  $Q(s_t,a_t)=(1-\\alpha)Q(s_t, a_t)+\\alpha(r_t+\\gamma \\max Q(s_{t+1},a))$\n",
        "\n",
        "Der Q-Wert im Status $s_t$ bei Ausführung der Aktion $a_t$ ist eine Funktion des bereits gelernten Q-Wertes (erster Teil der Gleichung) sowie der Belohnung im aktuellen Status zzgl. des diskontierten maximalen Q-Wertes aller möglichen Aktionen a im folgenden Status $s_{t+1}$.\n",
        "\n",
        "Der Q-Wert im Status $s_t$ bei Ausführung der Aktion $a_t$ ist eine Funktion des bereits gelernten Q-Wertes (erster Teil der Gleichung) sowie der Belohnung im aktuellen Status zzgl. des diskontierten maximalen Q-Wertes aller möglichen Aktionen a im folgenden Status $s_{t+1}$.\n",
        "\n",
        "Der Parameter $\\alpha$ im ersten Teil der Gleichung wird als Lernrate (learning rate) bezeichnet und steuert, zu welchem Anteil eine neu beobachtete Information den Agenten in seiner Entscheidung eine bestimmte Aktion zu treffen beeinflusst.\n",
        "\n",
        "Der Parameter $\\gamma$ ist der sog. Diskontierungsfaktor (discount factor) und steuert den Trade-off zwischen der Präferenz von kurzfristigen oder zukünftigen Belohnungen in der Entscheidungsfindung des Agenten. Kleine Werte für $\\gamma$ lassen den Agenten eher Entscheidungen treffen, die näher liegende Belohnungen in der Entscheidungsfindung priorisieren, während höhere Werte für $\\gamma$ den Agenten langfristige Belohnungen in der Entscheidungsfindung priorisieren lassen.\n",
        "\n",
        "In modellbasierten Q-Learning Umgebungen findet die Exploration der Umgebung nicht rein zufällig statt. Die Q-Werte der Q-Matrix werden basierend auf dem aktuellen Status durch Machine Learning Modelle, in der Regel neuronale Netze und Deep Learning Modelle, approximiert. Häufig wird während des Trainings von modellbasierten RL Systemen noch eine zufällige Handlungskomponente implementiert, die der Agent mit einer gewissen Wahrscheinlichkeit $p < \\epsilon$ durchführt. Dieses Vorgehen wird als $\\epsilon$-greedy bezeichnet und soll verhindern, dass der Agent immer nur die gleichen Aktionen bei der Exploration der Umgebung durchführt.\n",
        "\n",
        "Nach Abschluss der Lernphase wählt der Agent in jedem Status diejenige Aktion mit dem höchsten Q-Wert aus, $\\max Q(s_t, a)$. Somit kann sich der Agent von Status zu Status bewegen und immer diejenige Aktion wählen, die den approximierten Nutzen maximiert.\n",
        "\n",
        "Auch wenn die vorhergehenden Erklärungen manchmal etwas schwierig nachzuvollziehen sind ist es ganz wichtig sich im Zusammenhang mit Q-Learning folgendes zu merken:\n",
        "\n",
        "**Der Agent versucht den höchsten Q-Value zu erhalten, denn je höher dieser Wert ist desto klarer ist es, dass der Agent sich im richtigen Status (State) befindet und die richtige Aktion ausführt um anschliessen die optimale Rückgabe (Return) zu erhalten**\n",
        "\n",
        "Q-Learning eignet sich insbesondere dann als Lernverfahren, wenn die Anzahl der möglichen Stati und Aktionen überschaubar ist. Andernfalls wird das Problem aufgrund der kombinatorischen Komplexität mit reinen Explorationsmechanismen nur schwer lösbar. Aus diesem Grund findet in extrem hochdimensionalen Status- und Aktionsräumen die Approximation der Q-Werte häufig über modellbasierte Ansätze statt.\n",
        "\n",
        "Eine weitere Schwierigkeit bei der Anwendung von Q-Learning zeigt sich, wenn die Belohnungen zeitlich sehr weit vom aktuellen Status- und Handlungsraum des Agenten entfernt liegen. Wenn in naheliegenden Stati keine Belohnungen vorhanden sind, kann der Agent erst nach einer lagen Explorationsphase weit in der Zukunft liegende Belohnungen in die naheliegenden Stati propagieren.\n",
        "\n",
        "Quelle: [Statworx.com](https://www.statworx.com/ch/blog/einfuehrung-in-reinforcement-learning-wenn-maschinen-wie-menschen-lernen/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMc1ACapuhwc"
      },
      "source": [
        "#### Minimalbeispiel für Q Learning\n",
        "\n",
        "Der neue, autonome Stabsaugerroboter \"Dusty3000\" der Firma STAUBWORX soll sich vollautomatisch in unbekannten Wohnungen zurecht finden. Dabei nutzt das Gerät einen Reinforcement Learning Ansatz, um herauszufinden, in welchen Räumen einer Wohnung sich Staubballen und Flusen anhäufen. Eine virtuelle Testwohnung, in der der Roboter kalibriert werden soll, hat den folgenden Grundriss:\n",
        "\n",
        "<img src='https://www.statworx.com/wp-content/uploads/grundriss-wohnung-1.png' width=400>\n",
        "\n",
        "Insgesamt verfügt die virtuelle Testwohnung über 5 Zimmer, wobei im Testszenario lediglich im Wohnzimmer Staub anzufinden ist. Findet der Roboter den Weg zum Staub, erhält er eine Belohnung von $r = 1$ andernfalls wird keine Belohnung angesetzt $r=0$. Räume, die der Roboter von seiner aktuellen Position aus nicht erreichen kann, werden in der Belohnungsmatrix mit $r=-1$ definiert. In Matrizenschreibweise stellen sich die Belohnungen sowie die möglichen Aktionen pro Raum wie folgt dar:\n",
        "\n",
        "<img src='https://www.statworx.com/wp-content/uploads/reward-matrix-1.png' width=500>\n",
        "\n",
        "Stellen wir uns vor, der Saugroboter startet seine Erkundung zufällig im Flur (Raum 0). Ausgehend vom aktuellen Raum (Status) s=0 bieten sich dem Roboter drei mögliche Aktionen: 1, 2 oder 4. Aktion 0 und 3 sind nicht möglich, da diese Räume vom Flur aus nicht erreichbar sind. Der Agent erhält keine Belohnung, wenn er Aktion a=1 wählt und sich vom Flur in Raum 1 (Bad) begibt. Das gleiche gilt für Aktion a=2 (Bewegung ins Schlafzimmer). Wählt der Roboter jedoch Aktion a=4 und fährt ins Wohnzimmer, so findet er dort den Staub und er erhält eine Belohnung von r=1. Für den externen Betrachter erscheint die Wahl der Aktion trivial, unser Roboter jedoch kennt seine Umgebung nicht und wählt zufällig aus den zur Verfügung stehenden Aktionen aus.\n",
        "\n",
        "Der Roboter startet die zufällige Erkundung der Wohnung. Die Lernrate wird auf $\\alpha=1$ und der Diskontierungsfaktor auf $\\gamma=0.95$ gesetzt. Basierend auf dem Startpunkt im Flur wählt er per Zufallsgenerator aus den zur Verfügung stehenden Aktionen $a=2$ aus. Somit initiiert der Roboter zunächst eine Bewegung ins Schlafzimmer. Im vereinfachten Fall von $\\alpha=0.8$ is der Q Value für die Bewegung vom Flur ins Schlafzimmer ist definiert durch:\n",
        "\n",
        "  $Q(0,2)=(1-\\alpha)Q(0,2)+\\alpha(r_t+\\gamma \\max Q(s_{t+1},a))$\n",
        "\n",
        "  $=(1-1)*0+1*(0+0.95\\max[Q(2,0),Q(2,4)])$\n",
        "\n",
        "  $=0+1*(0+0.95 \\max[0, 1])=0.95$\n",
        "\n",
        "Hier zeigt sich auch die Bedeutung des Diskontierungsfaktors: Bei einem Wert von $0$ würde die mögliche Bewegung vom Schlafzimmer aus ins Wohnzimmer bei der momentanen Bewegung vom Flur ins Schlafzimmer nicht berücksichtigt werden. Es ergäbe sich Q Value von $Q(0,2)=0$​. Da der Diskontierungsfaktor in unserem Beispiel aber größer $0$ ist, wird auch die mögliche, zukünftige Belohnung in $Q(0,2)$​ mit eingepreist.\n",
        "\n",
        "Im Schlafzimmer angekommen ergeben sich wiederum zwei mögliche Aktionen. Entweder der Roboter bewegt sich zurück in den Flur, $a=0$ oder er fährt weiter ins Wohnzimmer, $a=4$. Zufällig fällt die Wahl diesmal auf das Wohnzimmer, womit sich folgender Q Value ergibt\n",
        "\n",
        "  $Q(2,4)=(1-\\alpha)+\\alpha(r_t+\\gamma \\max Q(s_{t+1},a))$\n",
        "\n",
        "  $=(1-1)*0+1*(1+0.95\\max[Q(4,0),Q(4,3)$\n",
        "\n",
        "  $=0+1*(1+0.95\\max[0,0])=1$\n",
        "\n",
        "Der gesamte Vorgang der Exploration bis hin zur Belohnung wird als eine Episode bezeichnet. Da der Roboter nun am Ziel angekommen ist, wird die Episode beendet. Während dieses Durchlaufs konnte der Agent zwei Q-Werte berechnen. Diese werden in die Q-Matrix eingetragen, die sozusagen das Gedächtnis des Roboters abbildet.\n",
        "\n",
        "<img src='https://www.statworx.com/wp-content/uploads/q-matrix-1.png' width=500>\n",
        "\n",
        "Im weiteren Trainingsverlauf werden nun Schritt für Schritt die Werte der Q-Matrix durch den Algorithmus aktualisiert. Der Roboter entscheidet sicht in jedem Raum für diejenige Aktion, die den höchsten Q-Wert aufweist. Die Exploration der Umgebung endet dann, wenn der Agent eine Belohnung erhalten hat.\n",
        "\n",
        "Quelle: [Statworx.com](https://www.statworx.com/ch/blog/einfuehrung-in-reinforcement-learning-wenn-maschinen-wie-menschen-lernen/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHpMMUzGxyNY"
      },
      "source": [
        "### Deep Q-Learning (DQN)\n",
        "\n",
        "Q-Learning ist ein einfacher, aber sehr leistungsfähiger Algorithmus zur Erstellung eines Spickzettels für unseren Agenten. Dieser hilft dem Agenten, genau herauszufinden, welche Aktion er ausführen soll.\n",
        "\n",
        "Aber was ist, wenn dieser Spickzettel zu lang ist? Stellen Sie sich eine Umgebung mit 10.000 Zuständen und 1.000 Aktionen pro Zustand vor. Dies würde eine Tabelle mit 10 Millionen Zellen erzeugen. Die Dinge werden schnell außer Kontrolle geraten!\n",
        "\n",
        "Es ist ziemlich klar, dass wir den Q-Wert von neuen Zuständen nicht aus bereits erforschten Zuständen ableiten können. Dies stellt zwei Probleme dar:\n",
        "\n",
        "* Erstens würde der Speicherbedarf für das Speichern und Aktualisieren dieser Tabelle mit zunehmender Anzahl von Zuständen steigen\n",
        "* Zweitens wäre die Zeit, die benötigt wird, um jeden Zustand zu untersuchen, um die erforderliche Q-Tabelle zu erstellen, unrealistisch.\n",
        "\n",
        "Hier ist ein Gedanke - was wäre, wenn wir diese Q-Werte mit maschinellen Lernmodellen wie einem neuronalen Netzwerk approximieren? Das war die Idee hinter dem Algorithmus von [DeepMind](https://de.wikipedia.org/wiki/DeepMind). Dieser Ansatz nennt sich auch Deep Q-Learning.\n",
        "\n",
        "Beim Deep Q-Learning wird ein neuronales Netz verwendet, um die Q-Wert-Funktion zu approximieren. Der Zustand wird als Eingabe gegeben und der Q-Wert aller möglichen Aktionen wird als Ausgabe generiert. Nachfolgende eine Darstelung die den Unterschied zwischen Q-Learning und DQN verdeutlichen soll:\n",
        "\n",
        "<img src='https://cdn.analyticsvidhya.com/wp-content/uploads/2019/04/Screenshot-2019-04-16-at-5.46.01-PM.png' width=500>\n",
        "\n",
        "Nachfolgend die Schritte beim Reinforcement Learning mit DQN:\n",
        "\n",
        "1. Alle vergangenen Erfahrungen werden vom Benutzer im Speicher abgelegt\n",
        "2. Die nächste Aktion wird durch den maximalen Output des Q-Netzes bestimmt\n",
        "3. Die Verlustfunktion (Loss) ist hier der mittlere quadratische Fehler (mean squared error) des vorhergesagten Q-Wertes und des Ziel-Q-Wertes - Q*. Dies ist im Grunde ein Regressionsproblem. Allerdings kennen wir hier den Ziel- oder Istwert nicht, da wir es mit einem Reinforcement-Learning-Problem zu tun haben. Zurück zur Aktualisierungsgleichung für den Q-Wert, die aus der Bellman-Gleichung abgeleitet wurde, haben wir:\n",
        "\n",
        "  <img src='https://cdn.analyticsvidhya.com/wp-content/uploads/2019/04/Screenshot-2019-04-16-at-6.02.08-PM-768x79.png' width=500>\n",
        "\n",
        "  Der Abschnitt in Grün stellt das Ziel dar. Wir können argumentieren, dass es seinen eigenen Wert vorhersagt, aber da $R$ die unvoreingenommene wahre Belohnung ist, wird das Netzwerk seinen Gradienten mit Backpropagation aktualisieren, um schließlich zu konvergieren.\n",
        "\n",
        "Betrachten wir mal die Schritte im DQN im Zusammenhang mit dem Training eines einfachen Computerspiels:\n",
        "\n",
        "1. Vorverarbeitung und Einspeisung des Spielbildschirms (Zustand s) in unser DQN, das die Q-Werte aller möglichen Aktionen in diesem Zustand zurückgibt\n",
        "2. Wählen Sie eine Aktion unter Verwendung der $\\epsilon$-Greedy-Richtlinie. Mit der Wahrscheinlichkeit epsilon wählen wir eine zufällige Aktion a und mit der Wahrscheinlichkeit 1-epsilon wählen wir eine Aktion, die einen maximalen Q-Wert hat, z. B. $a = argmax(Q(s,a,w))$\n",
        "3. Führen Sie diese Aktion in einem Zustand s aus und wechseln Sie in einen neuen Zustand s', um eine Belohnung zu erhalten. Dieser Zustand $s'$ ist das vorverarbeitete Bild des nächsten Spielbildschirms. Wir speichern diese Transition in unserem Replay-Puffer als $<s,a,r,s'>$\n",
        "4. Als nächstes entnehmen wir einige zufällige Stapel von Übergängen aus dem Wiedergabepuffer und berechnen den Verlust\n",
        "5. Es ist bekannt, dass: \n",
        "\n",
        "    $Loss = (r+\\gamma max_a'Q(s^´,a^´) - Q(s,a))^2$\n",
        "\n",
        "  nur die quadratische Differenz zwischen dem Ziel Q und dem vorhergesagten Q ist.\n",
        "6. Führen Sie einen Gradientenabstieg in Bezug auf unsere aktuellen Netzwerkparameter durch, um diesen Verlust zu minimieren\n",
        "7. Kopieren Sie nach jeder C-Iteration unsere Ist-Netzwerkgewichte in die Ziel-Netzwerkgewichte\n",
        "8. Wiederholen Sie diese Schritte für $N$-Anzahl von Episoden.\n",
        "\n",
        "**Achtung**: DQN wird nur in einem diskreten Aktionsraum (discrete action space) verwendet. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_nkcjRam1gb"
      },
      "source": [
        "#### DQN-Beispiel Self Driving Car\n",
        "\n",
        "Nachfolgend bauen wir Modell für das Training eines selbstfahrenden Autos.\n",
        "\n",
        "**Hinweis**\n",
        "\n",
        "Der nachfolgende Code kann nicht im Colab ausgeführt werden. Ich empfehle Spyder dafür zu nutzen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gdw6m9Q6nujR"
      },
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "from random import random, randint\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP-5zJUqoMF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5652b7b9-6fae-4aca-f502-a9b1073ab223"
      },
      "source": [
        "# Installing Kivy Package\n",
        "!pip3 install Kivy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Kivy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/aa/4a99a6b9ce71e00170bc82eb21a4880adb77e4c691e31219b47f4b3cd47a/Kivy-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (19.3MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from Kivy) (2.6.1)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.6/dist-packages (from Kivy) (0.16)\n",
            "Collecting Kivy-Garden>=0.1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/68/decaee596ff8168a39432eb3949fc7c0be952ebb9467806823bffc165d48/kivy-garden-0.1.4.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from Kivy-Garden>=0.1.4->Kivy) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->Kivy-Garden>=0.1.4->Kivy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->Kivy-Garden>=0.1.4->Kivy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->Kivy-Garden>=0.1.4->Kivy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->Kivy-Garden>=0.1.4->Kivy) (2020.12.5)\n",
            "Building wheels for collected packages: Kivy-Garden\n",
            "  Building wheel for Kivy-Garden (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Kivy-Garden: filename=Kivy_Garden-0.1.4-cp36-none-any.whl size=4532 sha256=f2a0c19dd2b11d609d6d4f2063f34f4c70dd2e74365cc1a7a53651f2d27a4e9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/09/36/4bec048252175b6aa7ba75441cbeed8f31a0bea37abedcfed0\n",
            "Successfully built Kivy-Garden\n",
            "Installing collected packages: Kivy-Garden, Kivy\n",
            "Successfully installed Kivy-2.0.0 Kivy-Garden-0.1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7OG_NbfoHSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02522d9f-078d-4ce9-9e32-dd2902db6b55"
      },
      "source": [
        "# Importing the Kivy packages\n",
        "from kivy.app import App\n",
        "from kivy.uix.widget import Widget\n",
        "from kivy.uix.button import Button\n",
        "from kivy.graphics import Color, Ellipse, Line\n",
        "from kivy.config import Config\n",
        "from kivy.properties import NumericProperty, ReferenceListProperty, ObjectProperty\n",
        "from kivy.vector import Vector\n",
        "from kivy.clock import Clock"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [Config      ] Older configuration version detected (0 instead of 21)\n",
            "[WARNING] [Config      ] Upgrading configuration in progress.\n",
            "[INFO   ] [Logger      ] Record log in /root/.kivy/logs/kivy_21-02-04_0.txt\n",
            "[INFO   ] [Kivy        ] v2.0.0\n",
            "[INFO   ] [Kivy        ] Installed at \"/usr/local/lib/python3.6/dist-packages/kivy/__init__.py\"\n",
            "[INFO   ] [Python      ] v3.6.9 (default, Oct  8 2020, 12:12:24) \n",
            "[GCC 8.4.0]\n",
            "[INFO   ] [Python      ] Interpreter at \"/usr/bin/python3\"\n",
            "[INFO   ] [Logger      ] Purge log fired. Analysing...\n",
            "[INFO   ] [Logger      ] Purge finished!\n",
            "[INFO   ] [Factory     ] 186 symbols loaded\n",
            "[INFO   ] [Image       ] Providers: img_tex, img_dds, img_sdl2, img_pil (img_ffpyplayer ignored)\n",
            "[INFO   ] [Text        ] Provider: sdl2\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgfJwHWXoiFT"
      },
      "source": [
        "# Importing the Dqn object from our AI in ai.py\n",
        "# Für den nächsten Schritt muss das Script ai.py von der folgenden URL heruntergeladen werden:\n",
        "# https://raw.githubusercontent.com/sakuronohana/my_datascience/master/udemy/aiaz/self_driving_car/ai.py'\n",
        "\n",
        "from ai import Dqn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD7p6n8xr417"
      },
      "source": [
        "# Adding this line if we don't want the right click to put a red point\n",
        "Config.set('input', 'mouse', 'mouse,multitouch_on_demand')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pwajg5FsAQM"
      },
      "source": [
        "# Introducing last_x and last_y, used to keep the last point in memory when we draw the sand on the map\n",
        "last_x = 0\n",
        "last_y = 0\n",
        "n_points = 0\n",
        "length = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P98ITIysXj8"
      },
      "source": [
        "# Getting our AI, which we call \"brain\", and that contains our neural network that represents our Q-function\n",
        "brain = Dqn(5,3,0.9)\n",
        "action2rotation = [0,20,-20]\n",
        "last_reward = 0\n",
        "scores = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlHK1d4KseCP"
      },
      "source": [
        "# Initializing the map\n",
        "first_update = True\n",
        "def init():\n",
        "    global sand\n",
        "    global goal_x\n",
        "    global goal_y\n",
        "    global first_update\n",
        "    sand = np.zeros((longueur,largeur))\n",
        "    goal_x = 20\n",
        "    goal_y = largeur - 20\n",
        "    first_update = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5305VIOsj1T"
      },
      "source": [
        "# Initializing the last distance\n",
        "last_distance = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6Ta4OFcspWh"
      },
      "source": [
        "class Car(Widget):\n",
        "    \n",
        "    angle = NumericProperty(0)\n",
        "    rotation = NumericProperty(0)\n",
        "    velocity_x = NumericProperty(0)\n",
        "    velocity_y = NumericProperty(0)\n",
        "    velocity = ReferenceListProperty(velocity_x, velocity_y)\n",
        "    sensor1_x = NumericProperty(0)\n",
        "    sensor1_y = NumericProperty(0)\n",
        "    sensor1 = ReferenceListProperty(sensor1_x, sensor1_y)\n",
        "    sensor2_x = NumericProperty(0)\n",
        "    sensor2_y = NumericProperty(0)\n",
        "    sensor2 = ReferenceListProperty(sensor2_x, sensor2_y)\n",
        "    sensor3_x = NumericProperty(0)\n",
        "    sensor3_y = NumericProperty(0)\n",
        "    sensor3 = ReferenceListProperty(sensor3_x, sensor3_y)\n",
        "    signal1 = NumericProperty(0)\n",
        "    signal2 = NumericProperty(0)\n",
        "    signal3 = NumericProperty(0)\n",
        "\n",
        "    def move(self, rotation):\n",
        "        self.pos = Vector(*self.velocity) + self.pos\n",
        "        self.rotation = rotation\n",
        "        self.angle = self.angle + self.rotation\n",
        "        self.sensor1 = Vector(30, 0).rotate(self.angle) + self.pos\n",
        "        self.sensor2 = Vector(30, 0).rotate((self.angle+30)%360) + self.pos\n",
        "        self.sensor3 = Vector(30, 0).rotate((self.angle-30)%360) + self.pos\n",
        "        self.signal1 = int(np.sum(sand[int(self.sensor1_x)-10:int(self.sensor1_x)+10, int(self.sensor1_y)-10:int(self.sensor1_y)+10]))/400.\n",
        "        self.signal2 = int(np.sum(sand[int(self.sensor2_x)-10:int(self.sensor2_x)+10, int(self.sensor2_y)-10:int(self.sensor2_y)+10]))/400.\n",
        "        self.signal3 = int(np.sum(sand[int(self.sensor3_x)-10:int(self.sensor3_x)+10, int(self.sensor3_y)-10:int(self.sensor3_y)+10]))/400.\n",
        "        if self.sensor1_x>longueur-10 or self.sensor1_x<10 or self.sensor1_y>largeur-10 or self.sensor1_y<10:\n",
        "            self.signal1 = 1.\n",
        "        if self.sensor2_x>longueur-10 or self.sensor2_x<10 or self.sensor2_y>largeur-10 or self.sensor2_y<10:\n",
        "            self.signal2 = 1.\n",
        "        if self.sensor3_x>longueur-10 or self.sensor3_x<10 or self.sensor3_y>largeur-10 or self.sensor3_y<10:\n",
        "            self.signal3 = 1.\n",
        "\n",
        "class Ball1(Widget):\n",
        "    pass\n",
        "class Ball2(Widget):\n",
        "    pass\n",
        "class Ball3(Widget):\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kme-L6azssv7"
      },
      "source": [
        "# Creating the game class\n",
        "\n",
        "class Game(Widget):\n",
        "\n",
        "    car = ObjectProperty(None)\n",
        "    ball1 = ObjectProperty(None)\n",
        "    ball2 = ObjectProperty(None)\n",
        "    ball3 = ObjectProperty(None)\n",
        "\n",
        "    def serve_car(self):\n",
        "        self.car.center = self.center\n",
        "        self.car.velocity = Vector(6, 0)\n",
        "\n",
        "    def update(self, dt):\n",
        "\n",
        "        global brain\n",
        "        global last_reward\n",
        "        global scores\n",
        "        global last_distance\n",
        "        global goal_x\n",
        "        global goal_y\n",
        "        global longueur\n",
        "        global largeur\n",
        "\n",
        "        longueur = self.width\n",
        "        largeur = self.height\n",
        "        if first_update:\n",
        "            init()\n",
        "\n",
        "        xx = goal_x - self.car.x\n",
        "        yy = goal_y - self.car.y\n",
        "        orientation = Vector(*self.car.velocity).angle((xx,yy))/180.\n",
        "        last_signal = [self.car.signal1, self.car.signal2, self.car.signal3, orientation, -orientation]\n",
        "        action = brain.update(last_reward, last_signal)\n",
        "        scores.append(brain.score())\n",
        "        rotation = action2rotation[action]\n",
        "        self.car.move(rotation)\n",
        "        distance = np.sqrt((self.car.x - goal_x)**2 + (self.car.y - goal_y)**2)\n",
        "        self.ball1.pos = self.car.sensor1\n",
        "        self.ball2.pos = self.car.sensor2\n",
        "        self.ball3.pos = self.car.sensor3\n",
        "\n",
        "        if sand[int(self.car.x),int(self.car.y)] > 0:\n",
        "            self.car.velocity = Vector(1, 0).rotate(self.car.angle)\n",
        "            last_reward = -1\n",
        "        else: # otherwise\n",
        "            self.car.velocity = Vector(6, 0).rotate(self.car.angle)\n",
        "            last_reward = -0.2\n",
        "            if distance < last_distance:\n",
        "                last_reward = 0.1\n",
        "\n",
        "        if self.car.x < 10:\n",
        "            self.car.x = 10\n",
        "            last_reward = -1\n",
        "        if self.car.x > self.width - 10:\n",
        "            self.car.x = self.width - 10\n",
        "            last_reward = -1\n",
        "        if self.car.y < 10:\n",
        "            self.car.y = 10\n",
        "            last_reward = -1\n",
        "        if self.car.y > self.height - 10:\n",
        "            self.car.y = self.height - 10\n",
        "            last_reward = -1\n",
        "\n",
        "        if distance < 100:\n",
        "            goal_x = self.width-goal_x\n",
        "            goal_y = self.height-goal_y\n",
        "        last_distance = distance\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeyQdDgptK58"
      },
      "source": [
        "# Adding the painting tools\n",
        "\n",
        "class MyPaintWidget(Widget):\n",
        "\n",
        "    def on_touch_down(self, touch):\n",
        "        global length, n_points, last_x, last_y\n",
        "        with self.canvas:\n",
        "            Color(0.8,0.7,0)\n",
        "            d = 10.\n",
        "            touch.ud['line'] = Line(points = (touch.x, touch.y), width = 10)\n",
        "            last_x = int(touch.x)\n",
        "            last_y = int(touch.y)\n",
        "            n_points = 0\n",
        "            length = 0\n",
        "            sand[int(touch.x),int(touch.y)] = 1\n",
        "\n",
        "    def on_touch_move(self, touch):\n",
        "        global length, n_points, last_x, last_y\n",
        "        if touch.button == 'left':\n",
        "            touch.ud['line'].points += [touch.x, touch.y]\n",
        "            x = int(touch.x)\n",
        "            y = int(touch.y)\n",
        "            length += np.sqrt(max((x - last_x)**2 + (y - last_y)**2, 2))\n",
        "            n_points += 1.\n",
        "            density = n_points/(length)\n",
        "            touch.ud['line'].width = int(20 * density + 1)\n",
        "            sand[int(touch.x) - 10 : int(touch.x) + 10, int(touch.y) - 10 : int(touch.y) + 10] = 1\n",
        "            last_x = x\n",
        "            last_y = y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7DYvfMAtPBa"
      },
      "source": [
        "# Adding the API Buttons (clear, save and load)\n",
        "\n",
        "class CarApp(App):\n",
        "\n",
        "    def build(self):\n",
        "        parent = Game()\n",
        "        parent.serve_car()\n",
        "        Clock.schedule_interval(parent.update, 1.0/60.0)\n",
        "        self.painter = MyPaintWidget()\n",
        "        clearbtn = Button(text = 'clear')\n",
        "        savebtn = Button(text = 'save', pos = (parent.width, 0))\n",
        "        loadbtn = Button(text = 'load', pos = (2 * parent.width, 0))\n",
        "        clearbtn.bind(on_release = self.clear_canvas)\n",
        "        savebtn.bind(on_release = self.save)\n",
        "        loadbtn.bind(on_release = self.load)\n",
        "        parent.add_widget(self.painter)\n",
        "        parent.add_widget(clearbtn)\n",
        "        parent.add_widget(savebtn)\n",
        "        parent.add_widget(loadbtn)\n",
        "        return parent\n",
        "\n",
        "    def clear_canvas(self, obj):\n",
        "        global sand\n",
        "        self.painter.canvas.clear()\n",
        "        sand = np.zeros((longueur,largeur))\n",
        "\n",
        "    def save(self, obj):\n",
        "        print(\"saving brain...\")\n",
        "        brain.save()\n",
        "        plt.plot(scores)\n",
        "        plt.show()\n",
        "\n",
        "    def load(self, obj):\n",
        "        print(\"loading last saved brain...\")\n",
        "        brain.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k-z7ArStYx1"
      },
      "source": [
        "# Running the whole thing\n",
        "if __name__ == '__main__':\n",
        "    CarApp().run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmGxXFZmipmi"
      },
      "source": [
        "### Asynchronous Advantage Actor-Critic (A3C)\n",
        "\n",
        "Kommen wir nun zu einem der mächtigsten Algorithmen im Zusammenhang mit Deep Reinforcement Learning. Der A3C wurde das erste Mal in einem Research Paper von Google DeepMind erwähnt ([Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783.pdf)). Schauen wir uns zuerst einmal an, was sich hinter den drei A's verbirgt: (Quelle: [GeeksforGeeks](https://www.geeksforgeeks.org/asynchronous-advantage-actor-critic-a3c-algorithm/))\n",
        "\n",
        "**Asynchronous**\n",
        "\n",
        "Im Gegensatz zu anderen beliebten Deep Reinforcement Learning-Algorithmen wie Deep Q-Learning, die einen einzelnen Agenten und eine einzelne Umgebung verwenden, verwendet dieser Algorithmus **mehrere Agenten**, wobei jeder Agent seine eigenen Netzwerkparameter und eine Kopie der Umgebung hat. Diese Agenten interagieren mit ihren jeweiligen Umgebungen asynchron und lernen mit jeder Interaktion. Jeder Agent wird durch ein globales Netzwerk gesteuert. Wenn jeder Agent mehr Wissen erlangt, trägt er zum Gesamtwissen des globalen Netzwerks bei. Das Vorhandensein eines globalen Netzwerks ermöglicht es jedem Agenten, über vielfältigere Trainingsdaten zu verfügen. Dieser Aufbau ahmt die reale Umgebung nach, in der Menschen leben, da jeder Mensch Wissen aus den Erfahrungen eines anderen Menschen gewinnt, wodurch das gesamte \"globale Netzwerk\" besser werden kann.\n",
        "\n",
        "<img src='https://theaisummer.com/static/bac1621ae2cdc7375540d511b9191752/bdffb/a3c.jpg' width=400>\n",
        "\n",
        "Quelle ([A Brandom-ian view of Reinforcement Learning towards strong-AI](https://arxiv.org/pdf/1803.02912v1.pdf))\n",
        "\n",
        "**Advantage**\n",
        "\n",
        "Normalerweise wird bei der Implementierung von Policy Gradient der Wert von Discounted Returns ($\\gamma r$ ) verwendet, um dem Agenten mitzuteilen, welche seiner Aktionen belohnt und welche bestraft wurden. Indem er stattdessen den Wert von Advantage verwendet, lernt der Agent auch, wie viel besser die Belohnungen waren als seine Erwartung. Dies gibt dem Agenten einen neuen Einblick in die Umgebung und somit ist der Lernprozess besser. Die Advantage-Metrik ist durch den folgenden Ausdruck gegeben:- \n",
        "\n",
        "Vorteil: $A = Q(s, a) - V(s)$ \n",
        "\n",
        "**Actor-Critic**\n",
        "\n",
        "Im Gegensatz zu einigen einfacheren Techniken, die entweder auf Value-Iteration-Methoden oder Policy-Gradient-Methoden basieren, kombiniert der A3C-Algorithmus die besten Teile beider Methoden, d. h. der Algorithmus sagt sowohl die Wertfunktion V(s) als auch die optimale Policy-Funktion $\\pi$ (s) voraus. Der lernende Agent verwendet den Wert der Wertfunktion (Critic), um die optimale Policy-Funktion (Actor) zu aktualisieren. Beachten Sie, dass die Policy-Funktion hier die probabilistische Verteilung des Aktionsraums bedeutet. Um genau zu sein, bestimmt der lernende Agent die bedingte Wahrscheinlichkeit P(a|s ;$\\theta$ ), d. h. die parametrisierte Wahrscheinlichkeit, dass der Agent die Aktion a wählt, wenn er sich im Zustand s befindet.\n",
        "\n",
        "<img src = 'https://theaisummer.com/static/a4620c153553ad622c5dbae389367c90/8608d/ac.jpg' width=400>\n",
        "\n",
        "Quelle ([A Brandom-ian view of Reinforcement Learning towards strong-AI](https://arxiv.org/pdf/1803.02912v1.pdf))\n",
        "\n",
        "\n",
        "Empfehlenswerter Artikel: [The idea behind Actor-Critics and how A2C and A3C improve them](https://theaisummer.com/Actor_critics/) (Quelle: AI Summer)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvLmdORtw6iC"
      },
      "source": [
        "### Deep Deterministic Policy Gradients (DDPG)\n",
        "\n",
        "DDPG, oder Deep Deterministic Policy Gradient, ist ein actor-critic, modellfreier Algorithmus, der auf dem deterministischen Policy-Gradienten basiert und über kontinuierliche Aktionsräume (continuous action spaces) operieren kann. Er kombiniert den Actor-Critic-Ansatz mit Erkenntnissen aus DQNs: insbesondere die Erkenntnisse, dass 1) das Netz außerhalb der Policy mit Samples aus einem Replay-Buffer trainiert wird, um Korrelationen zwischen Samples zu minimieren, und 2) das Netz mit einem Target-Q-Netz trainiert wird, um konsistente Targets bei zeitlich unterschiedlichen Backups zu erhalten. DDPG nutzt dieselben Ideen zusammen mit der Batch-Normalisierung.\n",
        "\n",
        "DDPG wurde in der von Deepmind veröffentlichen Publikation [\"Continuous Control With Deep Reinforcement Learning\"](https://arxiv.org/abs/1509.02971) im 2015 erstmalig erklärt.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj-iZCoUy0Kj"
      },
      "source": [
        "#### Twin Delayed DDPG (TD3)\n",
        "\n",
        "<img src='https://github.com/sakuronohana/my_datascience/blob/master/udemy/drl2.0/td3.png?raw=true' width=600>\n",
        "\n",
        "Nachfolgend werden wir ein Beispiel einer Implementierung mit TD3 erstellen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSxSmmPanA0D"
      },
      "source": [
        "# Installation erforderlicher Python Packete\n",
        "!pip install pybullet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1D40iqGoSnG"
      },
      "source": [
        "# Erforderliche Biblitotheken installieren.\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pybullet_envs\n",
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from gym import wrappers\n",
        "from torch.autograd import Variable\n",
        "from collections import deque"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dCihTG_0i3j"
      },
      "source": [
        "# Schritt 1: Initialisierung des Experience Replay memory\n",
        "class ReplayBuffer(object):\n",
        "\n",
        "  def __init__(self, max_size= 1e6):\n",
        "    self.storage = []\n",
        "    self.max_size = max_size\n",
        "    self.ptr = 0\n",
        "\n",
        "  def add(self, transition):\n",
        "    if len(self.storage) == self.max_size:\n",
        "      self.storage[init(self.ptr)] = transition\n",
        "      self.ptr = (self.ptr + 1) % self.max_size\n",
        "    else:\n",
        "      self.storage.append(transition)\n",
        "\n",
        "  def sample(self, batch_size):\n",
        "    ind = np.random.randint(0, len(self.storage), batch_size)\n",
        "    batch_states, batch_next_states, batch_actions, batch_rewards, batch_dones = [], [], [], [], []\n",
        "    for i in ind:\n",
        "      state, next_state, action, reward, done = self.storage[i]\n",
        "      batch_states.append(np.array(state, copy=False))\n",
        "      batch_next_states.append(np.array(next_state, copy=False))\n",
        "      batch_actions.append(np.array(action, copy=False))\n",
        "      batch_rewards.append(np.array(reward, copy=False))\n",
        "      batch_doness.append(np.array(done, copy=False))\n",
        "    return np.array(batch_states), np.array(batch_next_states), np.array(batch_actions), np.array(batch_rewards).reshape(-1,1), np.array(batch_dones).reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wjlXQ8y6Iwk"
      },
      "source": [
        "# Schritt 2: Erstellen der Neuronalen Neztwerke für das Actor Modell und Actor Target\n",
        "class Actor(nn.Module):\n",
        "\n",
        "  def __init__(self, state_dim, action_dim, max_action):\n",
        "    super(Actor, self).__init__()\n",
        "    self.layer_1 = nn.Linear(state_dim, 400)\n",
        "    self.layer_2 = nn.Linear(400, 300)\n",
        "    self.layer_3 = nn.Linear(300, action_dim)\n",
        "    self.max_action = max_action\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.layer_1(x))\n",
        "    x = F.relu(self.layer_2(x))\n",
        "    x = self.max_action * F.tanh(self.layer_3(x))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHUGM2Z8-HyU"
      },
      "source": [
        "# Schritt 3: Erstellen der neuronalen Netzwerke für die zwei Critic Modelle und Critic Targets\n",
        "class Critic(nn.Module):\n",
        "\n",
        "  def __init__(self, state_dim, action_dim):\n",
        "    super(Critic, self).__init__()\n",
        "    # Erstes Critic neural Network\n",
        "    self.layer_1 = nn.Linear(state_dim + action_dim, 400)\n",
        "    self.layer_2 = nn.Linear(400, 300)\n",
        "    self.layer_3 = nn.Linear(300, 1)\n",
        "    # Zweites Critic Neural Network\n",
        "    self.layer_4 = nn.Linear(state_dim + action_dim, 400)\n",
        "    self.layer_5 = nn.Linear(400, 300)\n",
        "    self.layer_6 = nn.Linear(300, 1)\n",
        "\n",
        "  def forward(self, x, u):\n",
        "    xu = torch.cat([x, u], 1)\n",
        "    # Foward-propagatioin für das erste Critic NN\n",
        "    x1 = F.relu(self.layer_1(xu))\n",
        "    x1 = F.relu(self.layer_2(x1))\n",
        "    x1 = self.layer_3(x1)\n",
        "    # Foward-propagatioin für das zweite Critic NN\n",
        "    x2 = F.relu(self.layer_4(xu))\n",
        "    x2 = F.relu(self.layer_5(x1))\n",
        "    x2 = self.layer_6(x2)\n",
        "    return x1, x2\n",
        "\n",
        "  def Q1(self, x, u):\n",
        "    xu = torch.cat([x, u], 1)\n",
        "    x1 = F.relu(self.layer_1(xu))\n",
        "    x1 = F.relu(self.layer_2(x1))\n",
        "    x1 = self.layer_3(x1)\n",
        "    return x1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d61NFEmRB3XI"
      },
      "source": [
        "# Schritt 4 - 15: Trainingsprozess\n",
        "\n",
        "# Auswahl der Hardware (GPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Erstellen des ganzen Trainingprozesse in eine Klasse (Class)\n",
        "\n",
        "class TD3(object):\n",
        "\n",
        "  def __init__()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1479GPfVU0YZ"
      },
      "source": [
        "## **KI-Modellen**\n",
        "\n",
        "An dieser Stelle wollen wir uns einmal mit den verschiedenen Konzepten von KI-Modellen befassen. Die folgenden Taxonomie wird vermehrt im Zusammenhang mit KI-Modellen verwendet und gibt uns die Möglichkeit die im voherigen Kapitel **\"Reinforcement Learning\"** beschriebenen Techniken einzuordnen.\n",
        "\n",
        "### Modell-Free vs. Model-Based\n",
        "\n",
        "KI mit dem **Modell-Free**-Konzept wurden im eigentlichen Environment trainiert, d.h. in dem Environment, in welchem sie auch zum Einsatz kommen.  **Model-Based** KIs hingegen  ihr eigenes optimales Environment erschaffen um darin zu trainieren. \n",
        "\n",
        "### Value-Based vs. Policy-Based\n",
        "\n",
        "....\n",
        "\n",
        "### Off-Policy vs. On-Policy\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGXtjc0bIL6z"
      },
      "source": [
        "## **Explainable Artificial Intelligence (XAI)**$^*$\n",
        "\n",
        "$^*$Bis 2015 noch unter dem Begriff *Interpretable machine learning* bekannt\n",
        "\n",
        "Der Einsatz von KI-/ML-Modellen in Unternehmen, Behörden oder im Gesundheitswesen bringt neben effizienteren Prozessen und einem allfälligen Wettbewerbsvorteil natürlich auch vielVerantwortung mit sich. In vielen Ländern wird dem Kunden eines Unternehmens das Recht auf volle Transparenz im Zusammenhang mit Entscheidungen (bspw. Kreditvergabe) welche ihn betreffen zugesprochen. Während sich Entscheidungen, welche durch Menschen innerhalb eines strukturierten Prozesses getroffen wurden, meist gut nachvollziehen lassen sieht dieses Thema beim Einsatz von KI bzw. ML-Modelle meist ganz anders aus. Die meist sehr grosse Anzahl von Merkmalen (Features) welche ein Modell während eines Entscheidungsprozess berücksichtigt und die Komplexität (bspw. Deep Neural Networks) der Algorithmen machen es schwierig der Anforderung der vollen Entscheidungstransparenz nachzukommen. Die meisten Unternehmen sehen sich ausserstande die Entscheidungen ihrer KI zu erklären. Dies führt zu Misstrauen der Kunden und einem Vertrauensproblem gegenüber dem Unternehmen. Die Entwickler von KIs sind somit vermehrt gefordert die Entscheidungen ihrer Modelle transparenter und nachvollziehbarer zu machen. \n",
        "\n",
        "Dieses Problem hat Forscher schon in den 1990er Jahren beschäftigt und wurde im Jahr 2004 mit dem Konzept \"*An Explainable Artificial Intelligence System for Small-unit Tactical Behavior*\" ([Link](https://www.aaai.org/Papers/IAAI/2004/IAAI04-019.pdf)) das erste Mal formalisiert. Im Verlauf der letzten Jahre wurde auch in diesem Bereich des Themas KI viel geforscht und Techniken entwickelt, welche die Vertrauenswürdikeit in KI-Modelle erhöhen sollen. Auch die EU hat sich in verschiedenen Projekten mit diesem Thema auseinandergesetzt und durch eine unabhängige Expertengruppe eine Ethic-Guidelinies für vertrauenswürdige KI ([Link]( https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai)) erstellen lassen. Gemäss den Experten muss eine KI folgende Eigenschaften aufweisen um als vertrauenswürdig eingestuft zu werden:\n",
        "\n",
        "* Erklärbarkeit\n",
        "* Fairness\n",
        "* Prüffähigkeit\n",
        "* Genauigkeit\n",
        "* Haftbarkeit\n",
        "\n",
        "Im Zusammenhang mit der Erklärbarkeit von ML-Modellen ist noch zu erwähnen, dass nicht alle Modelle per se schwierig zu interpretieren sind. So können beispielsweise Lineare Modelle und Entscheidungsbäume - auch **White-Box Modelle** genannt - mittels einfacher grafischer Darstellung bereits einen guten Aufschluss über deren Entscheidungsfindung aufzeigen. Hierbei muss gesagt sein, dass auch bei Entscheidungsbäumen mit mehreren hunderten und tausenden von Ebenen die Erklärbarkeit schwierig wird. Schwierig zu interpretierende Modellen nennt man übrigens **Black-Box Modelle**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdBHrqrw5XNW"
      },
      "source": [
        "### Arten von XAI\n",
        "\n",
        "Grundsätzlich wird zwischen zwei Arten von Erklärbarkeit unterschieden:\n",
        "\n",
        "* **Modellerklärbarkeit (Global Interpretability)** - Hier wird erklärt wie ein bestimmtes Modell als Ganzes funktioniert.\n",
        "* **Datenerklärbarkeit (Local Interpretability)** - Hierbei geht es darum, weshalb bestimmte Eingaben $x$ zu einer bestimmten Ausgabe $y$ führt.\n",
        "\n",
        "In diesem  Artikel werden die Begriffe genaustens erklärt: \n",
        "[What is Explainable AI (XAI)?](https://towardsdatascience.com/what-is-explainable-ai-xai-afc56938d513)\n",
        "\n",
        "In den nachfolgenden Kapiteln werden wir uns mit verschiedenen Techniken zu den zwei Arten der Erklärbarkeit befassen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNXt0nUE7e5p"
      },
      "source": [
        "### Modellerklärbarkeit (Global Interpretability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFoSKNnR7ndF"
      },
      "source": [
        "### Datenerklärbarkeit (Local Interpretability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ-AX2vz9DiI"
      },
      "source": [
        "#### Local Interpretable Model-Agnostic Explanations (LIME)\n",
        "\n",
        "https://youtu.be/VwpdMXGssPY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TilEInxS_lCD"
      },
      "source": [
        "#### SHapley Additive exPlanations (SHAP)"
      ]
    }
  ]
}